---
title: "Visualize GWAS results"
output: html_document
---

# Explore and annotate GWAS results

This notebook is delivered "As-Is". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.

[MIT License](https://github.com/dnanexus/UKB_RAP/blob/main/LICENSE) applies to this notebook.


## Working with flat files on DNAnexus in R

Let's process and concatenate regenie output files before loading it into R.


#16.04 Started re-running everything and got up to recalculating diabetes vars etc, but actually realise all I have to do once have the Liu GRS is join it to exisitng old update_pp6 file

```{r}
library(tidyverse)
COX_update<-readRDS("COX_update.rds")
update_pp6<-readRDS("update_pp6.rds")
merged_df_Liu_wGRS2<-readRDS("merged_df_Liu_wGRS2.rds")

#22.04 change SNP names to VV for Liu_79, and then keep so can run MR egger on them later
#change SNP names to VV
names(merged_df_Liu_wGRS2)<-gsub("V", "VV", names(merged_df_Liu_wGRS2))
str_sort(names(merged_df_Liu_wGRS2))
colnames<-grep("^VV[0-9]+",names(merged_df_Liu_wGRS2))
GRS2df<-merged_df_Liu_wGRS2 %>% select(ID_1, GRS2,all_of(colnames)) #great!
str_sort(names(GRS2df))
GRS2df<-GRS2df %>% mutate(GRS_79=GRS2)
colnames<-grep("^VV[0-9]+",names(GRS2df))
GRS2df<-GRS2df %>% select(ID_1,GRS_79,all_of(colnames))

COX_update79<-COX_update %>% left_join(GRS2df, by="ID_1")
update_pp679<-update_pp6%>% left_join(GRS2df, by="ID_1")
saveRDS(update_pp679, file="update_pp679.rds")
saveRDS(COX_update79, file="COX_update79.rds")

COX_update79<-readRDS("COX_update79.rds") #resaved 22.04 #resaved 10.05 so that the survival object is already made
update_pp679<-readRDS("update_pp679.rds") #resaved 22.04 # resvaed 19.05 so that sex_F and array are already made

```


#08.08
#hmm annoying that the columns don't have more informative headers (fixed this with 08.08 csv)..., also now need to figure out how to get genotype (incl. imputed) data in -> even when I redid the data preview thing using field_title option and then reexported using table exporter, still doesn't given informative headers
#15.08 good news the downloaded csvs are still in the folder that I restored at the beginning of the session (now just need to read them into the environment again)

```{r}


library(tidyverse) #this won't work because there is a problem with 'cli'; updated manually in bottom right window; now getting that issue with dplyr
#packageVersion("dplyr")
#update.packages()
#install.packages("dplyr")
#library(dplyr) #not working - need to uninstall tidyr in system packages because this has dolyr 1.0.8 and can't have this loaded if want to lod the new version of dplyr in my user library of packages -> argh it will not delete (because of broom)
#realie 24.10 if havig these problems just restart the session and it should work

#str_order(names(main)) #can't get this working atm as str_order is pat of Kmisc package which comes with tidyverse (and can't seem to download Kmisc directly)
#names(main)
#head(main)
#main %>% glimpse()

primary_pheno<-read.csv("28.11_participant_current.csv")
```


#RV 18.11 checking mfi files for MAF and info scores for our 93 SNPs
```{r}
system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c1_b0_v3.mfi.txt"')
MFI_1<-read.delim("ukb22828_c1_b0_v3.mfi.txt",header=F)
head(MFI_1)

Liu<-read.csv("Liu_small_proper.csv")
Liu_split<-split(Liu, Liu$Chr)
Liu_split_2 <- lapply(Liu_split,function (Liu){ 
  bigSNPr_ids <- Liu$rsID
  }
) 

library(tidyverse)
MFI_1_F<-MFI_1 %>% filter(V2 %in% Liu_split_2[["1"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c2_b0_v3.mfi.txt"')
MFI_2<-read.delim("ukb22828_c2_b0_v3.mfi.txt",header=F)
MFI_2_F<-MFI_2 %>% filter(V2 %in% Liu_split_2[["2"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c3_b0_v3.mfi.txt"')
MFI_3<-read.delim("ukb22828_c3_b0_v3.mfi.txt",header=F)
MFI_3_F<-MFI_3 %>% filter(V2 %in% Liu_split_2[["3"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c4_b0_v3.mfi.txt"')
MFI_4<-read.delim("ukb22828_c4_b0_v3.mfi.txt",header=F)
MFI_4_F<-MFI_4 %>% filter(V2 %in% Liu_split_2[["4"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c5_b0_v3.mfi.txt"')
MFI_5<-read.delim("ukb22828_c5_b0_v3.mfi.txt",header=F)
MFI_5_F<-MFI_5 %>% filter(V2 %in% Liu_split_2[["5"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c6_b0_v3.mfi.txt"')
MFI_6<-read.delim("ukb22828_c6_b0_v3.mfi.txt",header=F)
MFI_6_F<-MFI_6 %>% filter(V2 %in% Liu_split_2[["6"]]) #no data - remember there were none from c6 in Liu

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c7_b0_v3.mfi.txt"')
MFI_7<-read.delim("ukb22828_c7_b0_v3.mfi.txt",header=F)
MFI_7_F<-MFI_7 %>% filter(V2 %in% Liu_split_2[["7"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c8_b0_v3.mfi.txt"')
MFI_8<-read.delim("ukb22828_c8_b0_v3.mfi.txt",header=F)
MFI_8_F<-MFI_8 %>% filter(V2 %in% Liu_split_2[["8"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c9_b0_v3.mfi.txt"')
MFI_9<-read.delim("ukb22828_c9_b0_v3.mfi.txt",header=F)
MFI_9_F<-MFI_9 %>% filter(V2 %in% Liu_split_2[["9"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c10_b0_v3.mfi.txt"')
MFI_10<-read.delim("ukb22828_c10_b0_v3.mfi.txt",header=F)
MFI_10_F<-MFI_10 %>% filter(V2 %in% Liu_split_2[["10"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c11_b0_v3.mfi.txt"')
MFI_11<-read.delim("ukb22828_c11_b0_v3.mfi.txt",header=F)
MFI_11_F<-MFI_11 %>% filter(V2 %in% Liu_split_2[["11"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c12_b0_v3.mfi.txt"')
MFI_12<-read.delim("ukb22828_c12_b0_v3.mfi.txt",header=F)
MFI_12_F<-MFI_12 %>% filter(V2 %in% Liu_split_2[["12"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c13_b0_v3.mfi.txt"')
MFI_13<-read.delim("ukb22828_c13_b0_v3.mfi.txt",header=F)
MFI_13_F<-MFI_13%>% filter(V2 %in% Liu_split_2[["13"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c14_b0_v3.mfi.txt"')
MFI_14<-read.delim("ukb22828_c14_b0_v3.mfi.txt",header=F)
MFI_14_F<-MFI_14 %>% filter(V2 %in% Liu_split_2[["14"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c15_b0_v3.mfi.txt"')
MFI_15<-read.delim("ukb22828_c15_b0_v3.mfi.txt",header=F)
MFI_15_F<-MFI_15%>% filter(V2 %in% Liu_split_2[["15"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c16_b0_v3.mfi.txt"')
MFI_16<-read.delim("ukb22828_c16_b0_v3.mfi.txt",header=F)
MFI_16_F<-MFI_16 %>% filter(V2 %in% Liu_split_2[["16"]])

MFI_17<-read.delim("ukb22828_c17_b0_v3.mfi.txt",header=F)
MFI_17_F<-MFI_17%>% filter(V2 %in% Liu_split_2[["17"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c18_b0_v3.mfi.txt"')
MFI_18<-read.delim("ukb22828_c18_b0_v3.mfi.txt",header=F)
MFI_18_F<-MFI_18%>% filter(V2 %in% Liu_split_2[["18"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c19_b0_v3.mfi.txt"')
MFI_19<-read.delim("ukb22828_c19_b0_v3.mfi.txt",header=F)
MFI_19_F<-MFI_19 %>% filter(V2 %in% Liu_split_2[["19"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c20_b0_v3.mfi.txt"')
MFI_20<-read.delim("ukb22828_c20_b0_v3.mfi.txt",header=F)
MFI_20_F<-MFI_20%>% filter(V2 %in% Liu_split_2[["20"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c22_b0_v3.mfi.txt"')
MFI_22<-read.delim("ukb22828_c22_b0_v3.mfi.txt",header=F)
MFI_22_F<-MFI_22 %>% filter(V2 %in% Liu_split_2[["22"]])


```




#17.10 - going to try using bigsnpr to join concatenate bgen files
#15.04 updating
```{r}
system('dx download "/ONESAMPfinal.Rda"')
Liu<-readRDS("ONESAMPfinal.Rda")
Liu_split<-split(Liu, Liu$Chr)

Liu_split_2 <- lapply(Liu_split,function (Liu){ 
  bigSNPr_ids <- paste(Liu$Chr, Liu$Position, Liu$Reference.Allele, Liu$Alternate.Allele, sep="_")
  }
) #GREAT THIS WORKED!


#now concatenate all the chromosomes
#Liu<-read.csv("ONESAMPfinal.csv")
#Liu_split<-split(Liu, Liu$Chr)
#Liu_split_2 <- lapply(Liu_split,function (Liu){ 
#  bigSNPr_ids <- paste(Liu$Chr, Liu$Position, Liu$Reference.Allele, Liu$Alternate.Allele, sep="_")
#  }
#) 

#can't include C6 and C21 because the Liu_split_2 list doesn't have them

  rdsLiu <- bigsnpr::snp_readBGEN(
    bgenfiles   = c("c1filtered.bgen","c2filtered.bgen", "c3filtered.bgen", "c4filtered.bgen", "c5filtered.bgen",  "c7filtered.bgen", "c8filtered.bgen", "c9filtered.bgen", "c10filtered.bgen", "c11filtered.bgen", "c12filtered.bgen", "c13filtered.bgen", "c14filtered.bgen", "c15filtered.bgen", "c16filtered.bgen", "c17filtered.bgen", "c18filtered.bgen", "c19filtered.bgen", "c20filtered.bgen", "c22filtered.bgen"),
    list_snp_id = Liu_split_2,
    backingfile = "...x", #note this has to be different every time otherwise it will error message saying you already have a .bk file with this name
  )
  #test <- bigsnpr::snp_attach(rds)
  #head(test[["genotypes"]])
#names(test[["genotypes"]])

  
```


#28.01 reading this RDS file back in
```{r}
rdsLiu<-readRDS("...x.rds")
test<-rdsLiu
  head(test[["genotypes"]])
names(test[["genotypes"]])

```




#EXCELLENT! so file with all genotype data in them is called test
#then need to double check that the sample files are all identical (ie only need to read one in)

```{r}
#system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c1_b0_v3.sample"')
#system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c2_b0_v3.sample"')

sample1 <- data.table::fread("ukb22828_c1_b0_v3.sample")
sample2 <- data.table::fread("ukb22828_c2_b0_v3.sample") #yes they are the same! has 487410 rows (not including col headers), first is meaningless symbols (ahhh https://www.well.ox.ac.uk/~gav/snptest/#input_file_formats explains that this row gives the details on the data types for each column); test[[genotype]] has 487409 rows
```


```{r}
#remove first row from sample file (which is what the bigsnpr person does here to the sample file by removing first row https://github.com/privefl/UKBiobank/blob/master/10-get-dosages.R; copy their method in line below)
head(sample1)
sample1<-sample1[-1,]
range(sample1$ID_1) #hmm why are there so many negative ID values here...  all the negative IDs have 0 for sex so they can't be used
library(tidyverse)
range(primary_pheno$Participant.ID)
#wait part of the problem is that old_pheno has way 15,000 extra observations than sample1/genotype file
ind.indiv <- setdiff(primary_pheno$Participant.ID, sample1$ID_1) #15207
ind.indiv <- setdiff(sample1$ID_1,primary_pheno$Participant.ID) #207 Ids in sample1 that don't exist in pheno
#I think simply need to remove the negative ids BECAUSE THEY HAVE WITHDRAWN CONSET (yes> see FAQ: https://www.ukbiobank.ac.uk/media/emlnk0dk/access_064-uk-biobank-exome-release-faq_v11-final.pdf)
#library(tidyverse)
sample1 %>% count(ID_1<0) #so that's 207 people > ahh these must be the same 207 people missing from the pheno file > this means also need to remove these people from the geno file! >done in chunk below
head(sample1)


sample1_F<-sample1 %>% filter(ID_1>0)
#then remove any people from the pheno file that don't have a corresponding ID in the sample file (leaves us with 487202 people)
geno_ids<-sample1_F$ID_1
primary_pheno_small<-primary_pheno[primary_pheno$Participant.ID %in% geno_ids, ]

#head(sample1)
#head(primary_pheno_small)

#now reorder pheno file according to sample file
#mm this didn't work ... old_pheno_small_reordered<-old_pheno_small[match(geno_ids,old_pheno_small$Participant.ID),]
primary_pheno_small<-primary_pheno_small %>% mutate(ID_1=Participant.ID)
primary_pheno_small_reordered<-full_join(sample1_F,primary_pheno_small,by="ID_1")
head(primary_pheno_small_reordered) #FANTASTIC THIS WORKED 

```

#NEXT STEP IS TO join pheno file to geno file (geno file should already be in the same order as sample/pheno according to Amy) -> FANTSTIC - the way to do get this out of a bigSNP file to data frame is with matrix! https://github.com/privefl/bigsnpr/issues/165
```{r}
#class(test$genotypes)
test<-rdsLiu
genodata<-test$genotypes
geno_matrix<-genodata[]
geno_df<-as.data.frame(geno_matrix) #hmmm why are there 487409 observations here, instead of 487202? > SOLVED BELOW!

#need to remove the 207 people who have withdrawn conset - first join sample file so have IDs
geno_df2<-cbind(sample1,geno_df)
geno_df2_F<-geno_df2 %>% filter(ID_1>0) #down from 487409 to 487202!
head(geno_df2_F)

#now merge pheno with geno
#first check that no overlap in column names
str_sort(names(primary_pheno_small_reordered)) #only overlap for ID_1, ID_2, and sex

merged_df<-full_join(primary_pheno_small_reordered,geno_df2_F,by="ID_1")
#now save this
#updating names here 15.04 so don't override versions based on 2022 GSCAn
merged_df_Liu<-merged_df
saveRDS(merged_df_Liu, file = "merged_df_Liu.rds")
merged_df_Liu<-readRDS("merged_df_Liu.rds")
```

#create GRS for Liu with back up betas
#updated 15.04
```{r}

system('dx download "DrinksPerWeek.WithoutUKB.txt.gz"')
Liu_reduced = read.table(gzfile("DrinksPerWeek.WithoutUKB.txt.gz"),sep="\t")
#install.packages("janitor")
#library(tidyverse)
Liu_reduced<-Liu_reduced %>% janitor::row_to_names(row_number=1)
Liu_reduced<-Liu_reduced %>% mutate(PVALUE=as.numeric(PVALUE)) %>% mutate(BETA=as.numeric(BETA)) %>% mutate(SE=as.numeric(SE))
SNPs79<-Liu$rsID
Liu_reduced_matching_79SNPS<-Liu_reduced %>% filter(RSID %in% SNPs79)

#now save this reduced matching dataset so don't have to read that huge table in every time
saveRDS(Liu_reduced_matching_79SNPS, file="Liu_reduced_matching_79SNPS.rds")
Liu_reduced_matching_79SNPS<-readRDS("Liu_reduced_matching_79SNPS.rds")

rm(Liu_reduced)


Liu_reduced_matching_79SNPS<-Liu_reduced_matching_79SNPS %>% mutate(SNP=RSID)
#merged<-left_join(Liu,Liu_reduced_matching_363SNPS,by="SNP")
#merged_F<-merged %>% filter(!is.na(EFFECTIVE_N))

Liu_reduced_matching_79SNPS<-Liu_reduced_matching_79SNPS %>% mutate(X=1:79)
betas<-Liu_reduced_matching_79SNPS$BETA
X<-Liu_reduced_matching_79SNPS$X
df<-data.frame(X, betas)
class(df$X)
df<-df %>% mutate(X=as.character(X))
df$X <- sub("^", "V", df$X )
#names(rds)
X<-df$X
#https://stackoverflow.com/questions/70856361/how-to-create-a-weighted-sum-score-based-on-a-second-dataset-for-specific-variab
df2<-df[1:2,]

#library(tidyverse)
merged_df_Liu_wGRS2<-merged_df_Liu %>%
 mutate(GRS2 = rowSums(across(all_of(df$X), ~ .x * deframe(df)[[cur_column()]])))
temp<-merged_df_Liu_wGRS2 %>% select(ID_1, GRS2)
#WOW THIS RAN VERY QUICKLY
#merged_df2<-merged_df 
#hmm this keeps quitting on me before finishing running!
#let's try the base R version of this and see if it runs instead -> 15.04 funnily enough the below didn't work this time
#merged_df_Liu$GRS2 <- as.vector(as.matrix(merged_df_Liu[df$X]) %*% #this is telling it to cross-product the matrices
 #      with(df, setNames(betas, X)))

saveRDS(merged_df_Liu_wGRS2, file="merged_df_Liu_wGRS2.rds")
merged_df_Liu_wGRS2<-readRDS("merged_df_Liu_wGRS2.rds")




 #YAY THIS WORKED! - need to check that actually the strands are aligned the same way for UKB
#to do this
#checking again 23.03
#up to here end of 15.04
check<-head(merged_df_Liu_wGRS2)
p1<-check[1,] %>% select(V1:V79)
p2<-Liu_reduced_matching_79SNPS$BETA
#now transpose p1 so it's one column instead of one row
p3<-t(p1)
pcheck<-data.frame(p3,p2)
pcheck<-pcheck %>% mutate(p4=p3*p2)
sum(pcheck$p4) #0.1645498
#now compare to the GRS calculated above for person 1
check[1,] %>% select(GRS2) #BINGO! -> so we know the function is working correctly 16.04.23
#now we just need to check that the weights assigned from the CSV DEFINITELY refer to the same allele as the number of copies of allele (V1:V79) variables do

#first read in old filtered MFI file (refers to 363 version of GSCAN, but can filter down to relevant vars)
load(file="full_MFI_F.Rda")
MFI_small_missing<-full_MFI_F %>% filter(V2 %in% Liu_reduced_matching_79SNPS$RSID) #ONLY 17 of the 79!
comparLiu<-Liu_reduced_matching_79SNPS %>% filter(RSID %in% MFI_small_missing$V2)
identical(comparLiu$REF,MFI_small_missing$V4) #excellent! although this is only checking 17 of the 79 snps

#and further check that V4 from the MFI is actually where the reference allele is
#so this indicates that allele1 is the reference allele: https://biobank.ctsu.ox.ac.uk/crystal/refer.cgi?id=531; but to double check I'm downlodaing the marker qc text file (which that page indicates definitely has allele 1 as reference allele) to see if it lines up with the mfi file https://biobank.ctsu.ox.ac.uk/crystal/refer.cgi?id=1955
myfile <- read.table(url("https://biobank.ctsu.ox.ac.uk/crystal/ukb/auxdata/ukb_snp_qc.txt"))
head(myfile)
myfile2<-myfile %>% janitor::row_to_names(row_number=1) %>% janitor::clean_names()
test<-myfile2[1,]
myfileF<-myfile2 %>% filter(rs_id %in% comparLiu$RSID) #now only 3 of the SNPs are in here... weird?
compar_MFI<-MFI_small_missing %>% filter(V2 %in% myfileF$rs_id)
identical(compar_MFI$V4,myfileF$allele1_ref) #yes - but based only on 3 SNPs...

#ok so fairly confident the GRS has been correctly made! (16.04)
```




#now run below code chunks - 1st to create derived alcohol variables; 2nd to create derived diabetes variables/ filter out people with diabetes at baselin; then save the data again > THEN READY FOR NLMR PACKAGE!


#RV 24.10 going to write code for making drinks per week variable, using old pheno data above (then need to regenerate pheno data)
#FIRST DIVIDE PEOPLE INTO DRINKER, LIFETIME ABSTAINER, FORMER 
```{r}
#main %>% count(Alcohol.drinker.status...Instance.0) 
#sum(is.na(main$Alcohol.drinker.status...Instance.0))# a little missing data here, but recognised as blank rather than missing
merged_df2<-merged_df_Liu_wGRS2 %>% mutate(BL_drinker_status=case_when(Alcohol.drinker.status...Instance.0=="Current" ~ "Current", Alcohol.drinker.status...Instance.0=="Never" ~ "Never",Alcohol.drinker.status...Instance.0=="Previous" ~ "Former", TRUE~NA_character_))
merged_df2 %>% count(BL_drinker_status)
```
#whether weekly or less drinker
```{r}
merged_df2 %>% count(Alcohol.intake.frequency....Instance.0)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BL_drinker_status,exclude=NULL) # A will be rows, B will be columns
mytable
```

```{r}
#need to make all these variables numeric
merged_df2<-merged_df2 %>% mutate(weekly_RW=case_when(Average.weekly.red.wine.intake...Instance.0==""|Average.weekly.red.wine.intake...Instance.0=="Do not know"|Average.weekly.red.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.red.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_RW=as.numeric(weekly_RW))
merged_df2 %>% count(weekly_RW) #excellent -> now copy this syntax for all per week and per month vars (then make weekly drinks with case_when code saying if missing per week var, then use per month var? OR else could base this on the frequency variable instead)

merged_df2<-merged_df2 %>% mutate(weekly_WW=case_when(Average.weekly.champagne.plus.white.wine.intake...Instance.0==""|Average.weekly.champagne.plus.white.wine.intake...Instance.0=="Do not know"|Average.weekly.champagne.plus.white.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.champagne.plus.white.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_WW=as.numeric(weekly_WW))
merged_df2 %>% count(weekly_WW)

merged_df2<-merged_df2 %>% mutate(weekly_BC=case_when(Average.weekly.beer.plus.cider.intake...Instance.0==""|Average.weekly.beer.plus.cider.intake...Instance.0=="Do not know"|Average.weekly.beer.plus.cider.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.beer.plus.cider.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_BC=as.numeric(weekly_BC))
merged_df2 %>% count(weekly_BC)


merged_df2<-merged_df2 %>% mutate(weekly_S=case_when(Average.weekly.spirits.intake...Instance.0==""|Average.weekly.spirits.intake...Instance.0=="Do not know"|Average.weekly.spirits.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.spirits.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_S=as.numeric(weekly_S))
merged_df2 %>% count(weekly_S)

merged_df2<-merged_df2 %>% mutate(weekly_FW=case_when(Average.weekly.fortified.wine.intake...Instance.0==""|Average.weekly.fortified.wine.intake...Instance.0=="Do not know"|Average.weekly.fortified.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.fortified.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_FW=as.numeric(weekly_FW))
merged_df2 %>% count(weekly_FW)

merged_df2 %>% count(Average.weekly.intake.of.other.alcoholic.drinks...Instance.0)
merged_df2<-merged_df2 %>% mutate(weekly_O=case_when(Average.weekly.intake.of.other.alcoholic.drinks...Instance.0==""|Average.weekly.intake.of.other.alcoholic.drinks...Instance.0=="Do not know"|Average.weekly.intake.of.other.alcoholic.drinks...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.intake.of.other.alcoholic.drinks...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_O=as.numeric(weekly_O))
merged_df2 %>% count(weekly_O)
 



#a check using BC just to make sure that non-NA (0 or 2) responses are only coming from at least daily drinkers (YEP!)
#there are also NAs for weekly or more drinkers, but this is just probably refusal/don't know responses
merged_df2<-merged_df2 %>% mutate(BC_NA=case_when(is.na(weekly_BC)~1, weekly_BC==0 ~ 0, TRUE~2))
merged_df2 %>% count(BC_NA)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BC_NA,exclude=NULL) # A will be rows, B will be columns
mytable

merged_df2<-merged_df2 %>% mutate(O_NA=case_when(is.na(weekly_O)~1, weekly_O==0 ~ 0, TRUE~2))
merged_df2 %>% count(O_NA)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$O_NA,exclude=NULL) # A will be rows, B will be columns
mytable #SO MANY NAs for this drink question

```

#now monthly versions
```{r}
#need to make all these variables numeric
merged_df2<-merged_df2 %>% mutate(monthly_RW=case_when(Average.monthly.red.wine.intake...Instance.0==""|Average.monthly.red.wine.intake...Instance.0=="Do not know"|Average.monthly.red.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.red.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_RW=as.numeric(monthly_RW))
merged_df2 %>% count(monthly_RW) 

merged_df2<-merged_df2 %>% mutate(monthly_WW=case_when(Average.monthly.champagne.plus.white.wine.intake...Instance.0==""|Average.monthly.champagne.plus.white.wine.intake...Instance.0=="Do not know"|Average.monthly.champagne.plus.white.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.champagne.plus.white.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_WW=as.numeric(monthly_WW))
merged_df2 %>% count(monthly_WW)


merged_df2 %>% count(Average.monthly.beer.plus.cider.intake...Instance.0)
sum(merged_df2$Average.monthly.beer.plus.cider.intake...Instance.0=="")
merged_df2<-merged_df2 %>% mutate(monthly_BC=case_when(Average.monthly.beer.plus.cider.intake...Instance.0==""|Average.monthly.beer.plus.cider.intake...Instance.0=="Do not know"|Average.monthly.beer.plus.cider.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.beer.plus.cider.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_BC=as.numeric(monthly_BC))
merged_df2 %>% count(monthly_BC)

merged_df2<-merged_df2 %>% mutate(monthly_S=case_when(Average.monthly.spirits.intake...Instance.0==""|Average.monthly.spirits.intake...Instance.0=="Do not know"|Average.monthly.spirits.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.spirits.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_S=as.numeric(monthly_S))
merged_df2 %>% count(monthly_S)

merged_df2<-merged_df2 %>% mutate(monthly_FW=case_when(Average.monthly.fortified.wine.intake...Instance.0==""|Average.monthly.fortified.wine.intake...Instance.0=="Do not know"|Average.monthly.fortified.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.fortified.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_FW=as.numeric(monthly_FW))
merged_df2 %>% count(monthly_FW)

merged_df2<-merged_df2 %>% mutate(monthly_O=case_when(Average.monthly.intake.of.other.alcoholic.drinks...Instance.0==""|Average.monthly.intake.of.other.alcoholic.drinks...Instance.0=="Do not know"|Average.monthly.intake.of.other.alcoholic.drinks...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.intake.of.other.alcoholic.drinks...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_O=as.numeric(monthly_O))
merged_df2 %>% count(monthly_O)


#a check using BC just to make sure that non-NA (0 or 2) responses are only coming from less than weekly (but still current) drinkers (YEP!) - HMMM but there are too many NAs for less than monthly drinkers (almost double the number of people saying they have 0 or more beers/ciders per month) -> unfortunately (merged_df2 %>% count(Average.monthly.beer.plus.cider.intake...Instance.0)) this shows there are just a lot of people who have a blank response for this question > can see this in the raw CSV too
merged_df2<-merged_df2 %>% mutate(BC_NA2=case_when(is.na(monthly_BC)~1, monthly_BC==0 ~ 0, TRUE~2))
merged_df2 %>% count(BC_NA2)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BC_NA2,exclude=NULL) # A will be rows, B will be columns
mytable

```

#since Biddinger doesn't say how converted monthly to weekly, will use Topiwla's 4.3 weeks to a month conversion for Biddinger version too

Let's do one route Topiwala conversion (need to use weekly variables for weekly drinkers, and monthly divided by 4.3 for less than weekl drinkers): red or white wine = 1.7 units; fortified wine=1.2 units; pint = 2.4 units; spirits = 1 unit; other (e.g. alcopops) =1.2 units. 
-need to make it so that if someone is missing units for one of the varieties of alcohol (as opposed to 0), then we have to exclude them
```{r}

sum((merged_df2$Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|merged_df2$Alcohol.intake.frequency....Instance.0=="Once or twice a week"|merged_df2$Alcohol.intake.frequency....Instance.0=="Three or four times a week")
&!(is.na(merged_df2$weekly_RW)
   |is.na(merged_df2$weekly_WW)|is.na(merged_df2$weekly_BC)|is.na(merged_df2$weekly_S)|is.na(merged_df2$weekly_FW)|is.na(merged_df2$weekly_O))) #hmm so only 113991 here - meaning that a lot of people are missing responses for at least one of the beverages
#AHAH - it's coming from the 'other' drinks category

#updating this to remove the other volume q from the case_when conditions

#note for below, need to use sum>simply + in order to use the na.rm argument, but then must also use intermediate rowwise step so that it doesn't sum the entire two columns
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(weekly_weighted=sum(1.7*weekly_RW, 1.7*weekly_WW, 2.4*weekly_BC, 1*weekly_S, 1.2*weekly_FW ,1.2*weekly_O,na.rm=TRUE))
merged_df2 %>% count(weekly_weighted)
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(monthly_weighted=sum(1.7*monthly_RW, 1.7*monthly_WW, 2.4*monthly_BC, 1*monthly_S, 1.2*monthly_FW, 1.2*monthly_O,na.rm=TRUE))
merged_df2 %>% count(monthly_weighted)

merged_df2<-merged_df2 %>% mutate(weekly_units_T=case_when( (Alcohol.intake.frequency....Instance.0==""|Alcohol.intake.frequency....Instance.0=="Never"|Alcohol.intake.frequency....Instance.0=="Prefer not to answer") ~ NA_real_,
  (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&(is.na(weekly_RW)|is.na(weekly_WW)|is.na(weekly_BC)|is.na(weekly_S)|is.na(weekly_FW)) ~ NA_real_,
   (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week") ~ weekly_weighted,  
   (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&(is.na(monthly_RW)|is.na(monthly_WW)|is.na(monthly_BC)|is.na(monthly_S)|is.na(monthly_FW)) ~ NA_real_,   
    (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")~ (monthly_weighted/4.3) 
   ))
merged_df2 %>% count(weekly_units_T)
sum(is.na(merged_df2$weekly_units_T))#argh this is very high 348,870 (includes non-drinkers)
sum(!is.na(merged_df2$weekly_units_T))#153,539 > add roughly 40,000 for the non-drinkers, but this is STILL less than the number of people Topiwala had with full alcohol AND outcome AND covariate data for her obserational analysis...
#hmm I think I must've made an error with the weekly drinkers too (too many of them missing) 
#can see just from the weekly answers that should have AT LEAST 345,024 people, so something is wrong with my code for calculating weekly units
#05.11 the prolem is cominf from the abundance of NAs to the other drinks volume qs - need to check how to deal with that
#> found a paper that says to treat NA on this question only as a 0
#> fabulous fixed! the non-na sum is now 379824!

```


And one route Biddinger (which is different even considering the UK to US conversion)
1 beer/cider=16g (2 UK drinks), 1 wine = 16.8 (2.1), 1 fortified = 14.8 (1.76), 1 spirtis = 8g (1); 1 other = 12g (1.5)

```{r}

merged_df2<-merged_df2 %>% rowwise() %>%  mutate(weekly_weighted_B=sum(2.1*weekly_RW, 2.1*weekly_WW, 2*weekly_BC, 1*weekly_S, 1.76*weekly_FW ,1.5*weekly_O,na.rm=TRUE))
merged_df2 %>% count(weekly_weighted_B)
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(monthly_weighted_B=sum(2.1*monthly_RW, 2.1*monthly_WW, 2*monthly_BC, 1*monthly_S, 1.76*monthly_FW, 1.5*monthly_O,na.rm=TRUE))
merged_df2 %>% count(monthly_weighted_B)

merged_df2<-merged_df2 %>% mutate(weekly_units_B=case_when( (Alcohol.intake.frequency....Instance.0==""|Alcohol.intake.frequency....Instance.0=="Never"|Alcohol.intake.frequency....Instance.0=="Prefer not to answer") ~ NA_real_,
  (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&(is.na(weekly_RW)|is.na(weekly_WW)|is.na(weekly_BC)|is.na(weekly_S)|is.na(weekly_FW)) ~ NA_real_,
   (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week") ~ weekly_weighted_B,  
   (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&(is.na(monthly_RW)|is.na(monthly_WW)|is.na(monthly_BC)|is.na(monthly_S)|is.na(monthly_FW)) ~ NA_real_,   
    (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")~ ((monthly_weighted_B)/4.3) 
   ))
merged_df2 %>% count(weekly_units_B)
sum(is.na(merged_df2$weekly_units_B))#argh this is very high 348,870 (includes non-drinkers)
sum(!is.na(merged_df2$weekly_units_B))#153,539 > add roughly 40,000 for the non-drinkers, but this is STILL less than the number of people Topiwala had with full alcohol AND outcome AND covariate data for her obserational analysis...

```
IN TERMS OF THIS ISSUE: investigate why so many less than weekly drinkers weren't asked/didn't answer volume qs [PERHAPS I'VE ACCIDENTALLY DOWNLOADED THE MONTLY VOLUME QS FOR FOLLOW-UP WAVES RATHER THAN BASELINE -> nope can see in the CSV it's all instnce 0)
-let's check if it's a function of recruitment year (not a function of just those with repeat measures having it since the numbers wouldn't even work with so few people at repeat years)
#ANSWER IN END WAS THAT THEY SIMPLY DIDN'T START ASKING NON_WEEKLY DRINKERS ABOUT VOLUME UNTIL SOME TIME INTO THE STUDY 
```{r}
library(tidyverse)
main<-main %>% mutate(r_year=Year.of.birth+Age.at.recruitment)
sum(is.na(main$r_year))
range(main$r_year, na.rm=T) #why are there NAs here?! - only 1 so that's fine; range is 2004-2010

main_04<-main %>% filter(r_year=="2004")
mytable <- table(main_04$Alcohol.intake.frequency....Instance.0,main_04$BC_NA2,exclude=NULL) # all 04 NA on this q
main_05<-main %>% filter(r_year=="2005")
mytable <- table(main_05$Alcohol.intake.frequency....Instance.0,main_05$BC_NA2,exclude=NULL) # all 05 NA on this q
main_06<-main %>% filter(r_year=="2006")
mytable <- table(main_06$Alcohol.intake.frequency....Instance.0,main_06$BC_NA2,exclude=NULL) # all 06 NA on this q except for a single 0
main_07<-main %>% filter(r_year=="2007")
mytable <- table(main_07$Alcohol.intake.frequency....Instance.0,main_07$BC_NA2,exclude=NULL) # all 07 NA on this q 
main_08<-main %>% filter(r_year=="2008")
mytable <- table(main_08$Alcohol.intake.frequency....Instance.0,main_08$BC_NA2,exclude=NULL) # ok! 08 starts to have non-NA qs! although most are still NA
main_09<-main %>% filter(r_year=="2009")
mytable <- table(main_09$Alcohol.intake.frequency....Instance.0,main_09$BC_NA2,exclude=NULL) # now we're getting somewhere - majority of people in 09 have a non-NA answer now
main_10<-main %>% filter(r_year=="2010")
mytable <- table(main_10$Alcohol.intake.frequency....Instance.0,main_10$BC_NA2,exclude=NULL) # vast majority of people in 10 have a non-NA answer
mytable
```

now save again
```{r}
mergedLiu_df3<-merged_df2
saveRDS(mergedLiu_df3, file = "mergedLiu_df3.rds") #done 16.04
```

#18.02 reading this back in
```{r}
mergedLiu_df3<-readRDS("mergedLiu_df3.rds")
```


#UP TO HERE 30.01
#HMMM seems like after adding death and hospital episode data, now my csvs are split in 5... so will have to download the 5 dif files
#updating 28.11 with the new main pheno file (at this stage not going to import the new death and hesin data as hopefully will use first occurences variables instead - otherwise will need these file PLUS gp primary care files)
#10.12 decision is to use just the first occurence variables plus some baseline main pheno file variables to generate T2D (if do want to use the other csvs, redownload as updated on 28.11)
```{r}
#now have to merge sample file with pheno file (keeping order of the sample file!) so that when run MR analyses they are in the same order
#for now just try with the old pheno file (need to regenerate pheno file so suitable for CVD question)
#old_pheno<-read.csv("08.08_participant.csv")
#names(old_pheno)
#head(old_pheno)
#library(tidyverse)
#system('dx download "/28.11_participant_current.csv"')

#now to make T2D + date of onset
#library(lubridate)

#temp<-primary_pheno %>% select(Participant.ID, Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.)
#class(temp$Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.)
primary_pheno<-mergedLiu_df3
primary_pheno<-primary_pheno %>%mutate(T2D_by_firstocc_date=case_when((Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.))
primary_pheno<-primary_pheno %>%mutate(T2D_by_firstocc=case_when((!is.na(T2D_by_firstocc_date))~1, TRUE~0))
#temp<-primary_pheno %>% select(Participant.ID, T2D_by_firstocc_date,T2D_by_firstocc)


  #the below is having trouble parsing certain values
#primary_pheno<-primary_pheno %>%
#mutate(first_rep_date_diab=lubridate::as_date(T2D_by_firstocc_date))
#class(primary_pheno$first_rep_date_diab)

#parse_ymd = function(x){
#  d=lubridate::ymd(x, quiet=TRUE)
#  errors = x[!is.na(x) & is.na(d)]
#  if(length(errors)>0){
#    cli::cli_warn("Failed to parse some dates: {.val {errors}}")
 # }
 # d
#}

#primary_pheno<-primary_pheno %>%
#mutate(first_rep_date_diab=parse_ymd(T2D_by_firstocc_date)) #ahh ok can see the issue is the cells labelled "Code has event date matching participant's date of birth"

#so let's remove those people from the analysis
primary_pheno2<-primary_pheno %>% filter(T2D_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(T2D_by_firstocc_date)) #was only 3 people

#now run!
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_diab=lubridate::as_date(T2D_by_firstocc_date))
#temp<-primary_pheno2 %>% select(Participant.ID, first_rep_date_diab,T2D_by_firstocc)

#getting dates so can remove those with prevalant diabetes at baseline
#update 18.02 -> actually these are the cases we want to keep!/will be the focus of the analyses

primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc_date=case_when((Date.E10.first.reported..insulin.dependent.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E10.first.reported..insulin.dependent.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc=case_when((!is.na(T1D_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(T1D_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(T1D_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_diab1=lubridate::as_date(T1D_by_firstocc_date))

primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc_date=case_when((Date.E12.first.reported..malnutrition.related.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E12.first.reported..malnutrition.related.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc=case_when((!is.na(malDx_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(malDx_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(malDx_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_malDx=lubridate::as_date(malDx_by_firstocc_date))

primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx_date=case_when(( Date.E13.first.reported..other.specified.diabetes.mellitus.=="")~NA_character_, TRUE~ Date.E13.first.reported..other.specified.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx=case_when((!is.na(otherspecDx_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(otherspecDx_date!="Code has event date matching participant's date of birth"|is.na(otherspecDx_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_otherspecDx=lubridate::as_date(otherspecDx_date))

primary_pheno2<-primary_pheno2 %>%mutate(unspecDx_date=case_when((Date.E14.first.reported..unspecified.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E14.first.reported..unspecified.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(unspecDx=case_when((!is.na(unspecDx_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(unspecDx_date!="Code has event date matching participant's date of birth"|is.na(unspecDx_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_unspecDx=lubridate::as_date(unspecDx_date))

primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc_date=case_when((Date.O24.first.reported..diabetes.mellitus.in.pregnancy.=="")~NA_character_, TRUE~Date.O24.first.reported..diabetes.mellitus.in.pregnancy.))
primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc=case_when((!is.na(gestDx_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(gestDx_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(gestDx_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_gestDx=lubridate::as_date(gestDx_by_firstocc_date))

primary_pheno2 %>% count(T2D_by_firstocc)

#14.12 adding date at baseline for purposes of determinnng whether diabetes is already present at baseline > Date.of.attending.assessment.centre...Instance.0
#don't run the below line anymore 18.02
temp<-primary_pheno2 %>% select(Participant.ID, Date.of.attending.assessment.centre...Instance.0,  first_rep_date_diab,T2D_by_firstocc,
                                first_rep_date_diab1,
                                first_rep_date_malDx,
                                first_rep_date_otherspecDx,
                                first_rep_date_unspecDx,
                                first_rep_date_gestDx,
                                Glucose...Instance.0,
                                Glycated.haemoglobin..HbA1c....Instance.0,
                                IGF.1...Instance.0,
                                Source.of.report.of.E10..insulin.dependent.diabetes.mellitus.,
                                Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus.,
                                Source.of.report.of.E12..malnutrition.related.diabetes.mellitus.,
                                Source.of.report.of.E13..other.specified.diabetes.mellitus.,
                                Source.of.report.of.E14..unspecified.diabetes.mellitus.,
                                Source.of.report.of.O24..diabetes.mellitus.in.pregnancy.,
                                Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0,
                          Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0,
                          Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0,
                          Treatment.medication.code...Instance.0)


primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc=case_when((!is.na(first_rep_date_diab1))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc=case_when((!is.na(first_rep_date_malDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx_by_firstocc=case_when((!is.na(first_rep_date_otherspecDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(unspecDx_by_firstocc=case_when((!is.na(first_rep_date_unspecDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc=case_when((!is.na(first_rep_date_gestDx))~1, TRUE~0))

#table_3 <- table(temp$T2D_by_firstocc, temp$T1D_by_firstocc, temp$malDx_by_firstocc, temp$otherspecDx_by_firstocc, #temp$unspecDx_by_firstocc, temp$gestDx_by_firstocc)
#test_table<-ftable(table_3) #hard to read

temp_test<-temp %>% select(T2D_by_firstocc, T1D_by_firstocc, malDx_by_firstocc, otherspecDx_by_firstocc, unspecDx_by_firstocc, gestDx_by_firstocc)
x <- aggregate(list(n=rep(1, nrow(temp_test))), temp_test, length) #ok great this is an excellent solution, can see there (what follows are only those with T2D overlap) are 752 ppl with T1d and T2D recorded; 1 person with both T2d and mal_dx recorded, one person with t2d,t1d AND mal_dx, 164 people with other specified dx and t2d, 17 with other spec and t1d AND t2d, 3658 with unspec diabetes only so we can try to delineate these furhter, >17000 with both unspec and T2D, 3164 with unspec T1dd and T2d, 2 with unsepc, mal_dx AND T2D, 119 with T2D, other and unspec, 70 with T1D, T2D, other and unspec,, 156 with T2D and gest (can ignore), 11 with T2D T1D and gest, 1 with t2d other and gest, 68 with T2D unspec and gest, 34 with T2D T1D unspec and gest, 1 with T2D other unspec and gest

#where an individual is recorded as having more than one kind of diabetes, the one based on hospital records must win-out (no this doesn't make sense as can be diagnosed with more than one kind); write code for this (although for gestational, can have both) -> IMPORTANT,can have both T1D and T2D at the same time

#create a variable to idenityf people with any kind of diabetes at baseline
#first make a variable that gives the earlies of the 6 first rep dates
#then make a variable 0/1 for diabetes at baseline based on whether this above variable is earlier than the baseline date visit
#DON'T INCLUDE GEST_DX
primary_pheno2<-primary_pheno2 %>% mutate(earliest_diab=pmin(first_rep_date_diab,
                                first_rep_date_diab1,
                                first_rep_date_malDx,
                                first_rep_date_otherspecDx,
                                first_rep_date_unspecDx,
                                #first_rep_date_gestDx, 
                                na.rm = TRUE))
sum(is.na(primary_pheno2$earliest_diab))

primary_pheno2<-primary_pheno2 %>% mutate(dX_at_BL=case_when(earliest_diab<=Date.of.attending.assessment.centre...Instance.0 ~ 1, TRUE~0))
#and also one for T2D specifically at BL
primary_pheno2<-primary_pheno2 %>% mutate(T2dX_at_BL=case_when(first_rep_date_diab<=Date.of.attending.assessment.centre...Instance.0 ~ 1, TRUE~0))
#18.02 now want to exclude anyone with diabetes at baseline but whose earliest diabetes (excl gestational) was not T2D, and also exclude anyone who had a T1D diagnosis at any point (including post baseline)
primary_pheno2<-primary_pheno2 %>% mutate(earlistIST2D=case_when(earliest_diab==first_rep_date_diab ~ 1, TRUE~0))
temp <-primary_pheno2 %>% select(earlistIST2D, earliest_diab,first_rep_date_diab, first_rep_date_diab1, first_rep_date_malDx, first_rep_date_otherspecDx,first_rep_date_unspecDx) #GREAT LOOKS GOOD
sum(primary_pheno2$dX_at_BL==1 & primary_pheno2$earlistIST2D==0) #ok so should be 19165 people removed below who have dx at basline by their earliest T2D diagnosis is NOT T2D
primary_pheno3<-primary_pheno2 %>% filter(!(dX_at_BL==1 &earlistIST2D==0)) #yes this matches up!
#now further filter out (ie keep in) anyone with T1D diagnoses at ANY point
primary_pheno3<-primary_pheno3 %>%filter(T1D_by_firstocc==0)


#18.02 no longer run below since not doing Cox
#now exclude those people with any kind of diabetes at baseline (except gestational)
#temp<-temp %>% filter(dX_at_BL==0)
#now remove anyone diagnosed with T1D after baseline (because it's likely that that is simply a misdiagnosis of T2D, including people first diagnosed with T2D and then T1D, because this probably reflects simply an earlier misdiagnosis of T1D)
#temp<-temp %>% filter(T1D_by_firstocc==0)
#temp %>% count(T2D_by_firstocc) #ok so still >20,000 incident cases to work with here



#great -> now refine this variable using self-reported insulin, metaformin,other diabetes druig, hba1c, glucose, non-specific diabetes type reported ->01.01.23 REALISED THAT SELF-reported insulin was only asked of those who reported diabetes, and we are excluding those people anwyay, so this q specifically is useless, but the other drug qs and hba1c/glucose levels can be used to identify people who failed to report on diabetes at baseline but show indications of having it

#diabetes medication use at baseline - ANYONE WITH ONE OF THE FOLLOWING AT BASELINE NEEDS TO BE EXCLUDED
#temp %>% count(Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0) #can see this was asked of 25298 people who self-reported a history of diabetes (diabetes diagnosed by doctor) that wasn't gestational diabetes (dx_at_BL variable counts almost an additional 1,000 people with diabetes who didn't self-report any of the non-gestational diabetes at baseline)
#temp %>% count(Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0) #this was asked of women
#temp %>% count(Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0) #this was asked of men
primary_pheno3 <-primary_pheno3 %>% mutate(insulin_BL=case_when(
  (Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Blood pressure medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Cholesterol lowering medication|Blood pressure medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Cholesterol lowering medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0==
"Insulin|Hormone replacement therapy"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Insulin|Oral contraceptive pill or minipill")~1,
(Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0=="Blood pressure medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Cholesterol lowering medication|Blood pressure medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Cholesterol lowering medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Insulin") ~ 2, TRUE~0
                                              ))
primary_pheno3 %>% count(insulin_BL) #690 people report insulin at BL (because have already filtered out everyone with T1D, let's remove these people too)
primary_pheno3 <-primary_pheno3 %>% filter(insulin_BL==0)
#now do a regex on the free-entry medication qs 
#temp %>% count(Treatment.medication.code...Instance.0) #yuck this is awful because includes all combos -> need to run some regex to capture any answer that INCLUDES one of the relevant drugs -> would be much easier to use the variable with the actual codes for the drugs rather than the names but seems I didn't select that varaible from the showcase
#list of drug names: insulin product ; SULFS (should be 10 according to mason - maybe they only included the ones with >0 cases): amaryl ; chlorpropamide ; diabinese (0 count); glimepiride; glipizide product; minodiab; tolazamide; tolbutamide; glibenclamide; tolanase (0 count); glibenese (0 count); diamicron; daonil (0 count); gliclazide      ; MASON'S 'OTHERS': acarbose; glucobay; glucotard  ; MEGLITINIDES: repaglinide; nateglinide; starlix ; GLITAZONES: pioglitazone; rosiglitazone (the fifth one Mason had was a rosig combo pill); avandia; actos
#01.01.23 > NUP TOO HARD, have to go back to showcase and add the coded var to a csv and reimport > HMMMM SO STRANGELY there i only this one variable in showcase (in fact mason page says uses this variable 20003 - but somehow they were able to use codes but I can't see those)

#AHHH ok have to do a regex of this var Treatment.medication.code...Instance.0 to find people who were taking metformin/insulin at baseline -> then use the flow charts in the powerpoint to refine baseline diabetes type among those who reported any diabetes at baseline (NO WE ARE EXCLUDING POEOPLE WITH ANY DX AT BL SO NO POINT); then use hba1c/glucose to catch any additional diabetes cases that weren't reported on -> THERE'S NO WAY TO REFINE THE INCIDENCE CASES WITH EXTRA DATA (except maybe to censor people who develop a non-T2 diabetes diagnosis in follow-up...? - this is what the incidence flow-charts seem to do ie whichever diabetes diagnosis comes first - yep this is basically what I do re censor any non-T2d, but unlike the flow chart, if get T1D diag and THEN T2D diag assume that T1D was a mistake)

#18.02 DON'T RUN BELOW BECAUE WE DON"T WANT TO FILTER OUT PEOPLE with T2D ON diabetes meds at baseline more generally!!!
#regex step (started chaning temp to primary_pheno but didn't actually run)
toMatch <- c("insulin", "amaryl" , "chlorpropamide" , "glimepiride", "glipizide" , "minodiab", "tolazamide", "tolbutamide", "glibenclamide", "diamicron", "gliclazide "  , "acarbose", "glucobay", "glucotard"  , "repaglinide", "nateglinide", "starlix" , "pioglitazone", "rosiglitazone", "avandia", "actos")
primary_pheno4<-primary_pheno3 %>% mutate(anyDmeds_BL =(grepl(paste(toMatch,collapse="|"), 
                        primary_pheno3$Treatment.medication.code...Instance.0 )))
primary_pheno4 %>% count(anyDmeds_BL) #only 33 people (makes sense given we've already filtered out people self-reporting diabetes at bl/records indicate diagnosed with diabetes before bl/taking insulin at bl)
#now filter these people out
temp2<-temp2 %>% filter(anyDmeds_BL==FALSE)


#18.02 AGAIN DON'T RUN BELOW SINCE WE want people with T2D to stay
#final step is to remove those with elevated hba1c/glucose at BL (using Steven code; for incidence eastwood uses the same hba1c threshold and also glucose omore than or equal to 11.1)
temp_test <-temp2%>% filter(Glycated.haemoglobin..HbA1c....Instance.0>=48)
temp2<-temp2 %>% filter (is.na(Glycated.haemoglobin..HbA1c....Instance.0) | Glycated.haemoglobin..HbA1c....Instance.0<48) # wow that removed almost 4,000 people
temp_test<-temp2 %>% filter(Glucose...Instance.0>=11.1) #an additional 587 people
temp2<-temp2 %>% filter (is.na(Glucose...Instance.0) | Glucose...Instance.0<11.1) 

#02.01.23 FANTASTIC - NOW EVERYONE WITH any kind of diabetes at baseline (diagnosed or not; exlcuding gestational) has been removed, and anyone who develops T1D after baseline is also removed 



#do continuous var winsorisation now that all the baseline diabetes cases have been removed
#identify hba1c and IGF variables -> Glycated.haemoglobin..HbA1c....Instance.0 ; IGF.1...Instance.0
#library(tidyverse)
#str_sort(names(primary_pheno))
#primary_pheno %>% count(IGF.1...Instance.0)
#hist(temp2$IGF.1...Instance.0)
#range(primary_pheno$IGF.1...Instance.0,na.rm=T)
sd<-sd(primary_pheno3$IGF.1...Instance.0, na.rm=T)
mean<-mean(primary_pheno3$IGF.1...Instance.0,na.rm=T)
primary_pheno3 <-primary_pheno3 %>% mutate(IGF_BL_winsor=case_when(IGF.1...Instance.0<(mean-3*sd)~(mean-3*sd),
                                                             IGF.1...Instance.0>(mean+3*sd)~(mean+3*sd),
                                                             TRUE~IGF.1...Instance.0))
#hist(temp2$IGF_BL_winsor) #this is now nicely normally distributed after winsorising
#sum(is.na(temp2$IGF_BL_winsor)) #only 35,456 NA
#sum(!is.na(temp2$IGF_BL_winsor)) #466,953

#hist(temp2$Glycated.haemoglobin..HbA1c....Instance.0)
#range(temp2$Glycated.haemoglobin..HbA1c....Instance.0,na.rm=T) #maxis 47.9 now because filtered out anyone above 48
sd<-sd(primary_pheno3$Glycated.haemoglobin..HbA1c....Instance.0, na.rm=T)
mean<-mean(primary_pheno3$Glycated.haemoglobin..HbA1c....Instance.0,na.rm=T)
35+(3.76*3)
35-(3.76*3) #winsorising makes little change to the upper limit, but raises the lower limit quie a bit
primary_pheno3 <-primary_pheno3 %>% mutate(HbA1c_BL_winsor=case_when(Glycated.haemoglobin..HbA1c....Instance.0<(mean-3*sd)~(mean-3*sd),
                                         Glycated.haemoglobin..HbA1c....Instance.0>(mean+3*sd)~(mean+3*sd),
                                                             TRUE~Glycated.haemoglobin..HbA1c....Instance.0))
#hist(primary_pheno$HbA1c_BL_winsor) #hmm maybe not appropriate to winsorise like this as quite a lot of people were more than 3sds above the mean

saveRDS(primary_pheno3, file = "primary_pheno3.rds") #



#01.01 NO THE BELOW DOESN'T MATTER SINCE REMOVING PEOPLE WITH ANNNYYYY diabetes at baseline (except gestational) so no point trying to deliniate further
#trying to classify those with unspecified diabetes (3658 have unspec alone, another 20 have just unsepc and gestational)
#temp_unspec <- temp %>% filter(T2D_by_firstocc==0 & T1D_by_firstocc==0 & malDx_by_firstocc==0, otherspecDx_by_firstocc==0 & unspecDx_by_firstocc==1 )
#temp_unspec %>% count(Source.of.report.of.E14..unspecified.diabetes.mellitus.) #ok so leave the ones that were death register and hospital admissions sources, but for those that are self-report, see if we can use the other variables to delineate further (mediaction use)
#temp_unspec %>% count(Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0=="Yes") #so 177 with unspecified diabetes at baseline then started insulin within one year... potentially change their dx




#glimpse(primary_pheno)
#system('dx download "/15.11.attempt3_death.csv"')
#death_pheno<-read.csv("15.11.attempt3_death.csv")
#glimpse(death_pheno)
#system('dx download "/15.11.attempt3_death_cause.csv"')
#death_cause_pheno<-read.csv("15.11.attempt3_death_cause.csv")
#glimpse(death_cause_pheno) #hmm ok so each death individual has multiple rows here...
#system('dx download "/15.11.attempt3_hesin.csv"')
#hesin_pheno<-read.csv("15.11.attempt3_hesin.csv")
#glimpse(hesin_pheno) #yikes 3 million rows here 
#system('dx download "/15.11.attempt3_hesin_diag.csv"')
#hesin_diag_pheno<-read.csv("15.11.attempt3_hesin_diag.csv")
#glimpse(hesin_diag_pheno) #15 million rows -> ok so I think what needs to be done is need to make each of these files wide format so that each individual only has a single row
#death_cause_pheno_wide<-death_cause_pheno%>% separate(dnx_death_cause_id, c("dnx_death_cause_id_A","dnx_death_cause_id_B"), sep = "(?<=-[\\d+])*")
#death_cause_pheno_wide<-

#ACTUALLY FORGET THAT -> can see from Steven code that they will figure out diabetes from each of these files first, and ONLY then will they extract the IDs for those individuals and merge with the regular pheno
```


#so when run the actual nlmr next; filter down to Europeans! (DONE); randomly remove one of the related subjects based on kinship (DONE); remove those drinking occasionally who were in one of the first few waves and weren't asked about volume (DONE); first separate the df into 3 sep dfs based on never drinkers, former drinkers, and current drinkers (BL_drinker_status ==0) but ALSO KEEP A COMBINED DF; then, add 1 to each drinking value in combined df and log transform that variable before running G-X in CONTROLS only IN THE COMBINED DF  (i.e. those who are T2dX_at_BL==0), then run G-Y in each of the 3 dfs separately ; age sex genotyping method ("Genotype.measurement.batch") and PCA ("Genetic.principal.components...Array.1" thru 10) need to be included as covariates in both regressions

```{r}
primary_pheno3<-readRDS("primary_pheno3.rds")

#want to see what weekly drinks looks like for occasional drinkers
library(tidyverse)
temp<-primary_pheno3 %>% filter(Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only") #filter to freq occasional only 
temp<-temp %>% select(ID_1, weekly_units_B) #can see that a lot of weekly drinkers end up with a weekly average that's more than 1 drink per week! so next step is to remove occasonal drinkers with NA weekly drinks from the dataset
sum(is.na(temp$weekly_units_B)) #so 67,963/100,000 occasional drinkers are mssing weekly volume -> need to exclude them!
primary_pheno4<-primary_pheno3 %>% mutate(occasionalWOvol=case_when((
  (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&
    is.na(weekly_units_B)
  )~1, TRUE~0))
primary_pheno4<-primary_pheno4 %>% filter(occasionalWOvol==0)

#up to here 18.02 (when reopen, rerun this chunk and then get started on filtering down to europeans etc)

str_sort(names(primary_pheno4))
temp<-primary_pheno4 %>% select(ID_1, Genetic.ethnic.grouping)
temp %>% count(Genetic.ethnic.grouping) #use this one over Ethnic background as this incorporates both genetic and self-identified ethnicity, whereas Ethnic background is self-report only

primary_pheno4<-primary_pheno4 %>% filter(Genetic.ethnic.grouping=="Caucasian") #down to 335948

#now remove one of each of the related individuals
temp<-primary_pheno4 %>% select(ID_1, Genetic.relatedness.exclusions, Genetic.relatedness.factor...Array.0, Genetic.relatedness.IBS0...Array.0, Genetic.relatedness.pairing...Array.0, Genetic.kinship.to.other.participants)
#ARRGGHH I realised I only have array 0, but I need arrays 1-4 to be able to identify all cases of relatedness
#joining on 22.02.23 with additional csv which includes all arrays for the relatedness variables
system('dx download "/22.02_new_cols__participant.csv"')
add_cols<-read.csv("22.02_new_cols__participant.csv")
str_sort(names(add_cols))
#remove the array.0 variables from this so don't overlap with main df
add_cols<-add_cols %>% select(-c(Genetic.relatedness.factor...Array.0,Genetic.relatedness.pairing...Array.0))
add_cols<-add_cols %>% mutate(ID_1=Participant.ID)
add_cols<-add_cols %>% select(-c(Participant.ID))

temp<-primary_pheno4 %>% select(ID_1, ID_2.x, ID_2.y) #all the same
update_pp4<-primary_pheno4 %>% left_join(add_cols,by="ID_1") #should be 335948 rows > excellent! added 12 extra rows
temp<-update_pp4 %>% select(ID_1,  Genetic.relatedness.factor...Array.0,Genetic.relatedness.factor...Array.1,Genetic.relatedness.factor...Array.2,Genetic.relatedness.factor...Array.3,Genetic.relatedness.factor...Array.4,  Genetic.relatedness.pairing...Array.0,Genetic.relatedness.pairing...Array.1,Genetic.relatedness.pairing...Array.2,Genetic.relatedness.pairing...Array.3,Genetic.relatedness.pairing...Array.4, Genetic.kinship.to.other.participants)
temp<-temp %>% filter(Genetic.relatedness.factor...Array.0>.088|Genetic.relatedness.factor...Array.1>.088|Genetic.relatedness.factor...Array.2>.088|Genetic.relatedness.factor...Array.3>.088|Genetic.relatedness.factor...Array.4>.088) #so 5,352 people have at least one substantially related person to them in the cohort
#hmm the complicated part now is the people with more than one relation


saveRDS(update_pp4, file = "update_pp4.rds") #done 23.02
update_pp4<-readRDS("update_pp4.rds")

#so the way to deal with relatedness is to use the UKBtools package function, which requires a vector of the IDs you are interested in (can supply from update_pp4) and also a df with a row for each relationship pairing which can be obtained directly from UKB
system('dx download "/Bulk/Genotype Results/Genotype calls/ukb_rel.dat"')
data <- read.delim("ukb_rel.dat", header = TRUE, sep=" ") 
install.packages("ukbtools")
library(ukbtools)
names(update_pp4)
ukb_with_data<-update_pp4$ID_1 #to get the vector of IDs
remove_IDs<-ukb_gen_samples_to_remove(data, ukb_with_data, cutoff = 0.0884)  
#ok need to save this vector 
write.csv(remove_IDs,file="remove_IDs.csv",row.names=F)

#hmm so there are 20,284 people to remove, despite me only finding 5352 people with a significantly related other person
#where to find disconnect
vector2<-temp$ID_1
diffs<-setdiff(remove_IDs,vector2)
temp2<-temp %>% filter(ID_1=="1527295") #so this person has no relationships
data2<-data %>% filter(ID1=="1527295"|ID2=="1527295") #ok so there are 5 people they are related to in the official relationship data - do I still have these people in temp?
temptemp<-temp %>% filter(ID_1=="4973330"|ID_1=="1199284"|ID_1=="3640301"|ID_1=="3051580"|ID_1=="4756198") #we do! so so strange -> so why are they not related according to the relationship pairing/factor vars, but are related according to the data UKB gives out... can  see that in the temptemp file the kinship column DOES say that they were found to be related to at least one other individuals, so seems just like missing data for coeffieincts/pairings -> will therefore use the list of IDs generated here
###AHHHH FIGURED IT OUT -> my pairing and relatedness vars come from the interim release (only 150,000 people with genotyping at that point), so a lot of people simply have NAs for those vars because they wren't even genotyped by the time of the interim release

#now filter down the dataset by removing these people
'%notin%' <- Negate('%in%')
update_pp5<-update_pp4 %>% filter(ID_1 %notin% remove_IDs) #worked!
str_sort(names(update_pp5))
saveRDS(update_pp5, file = "update_pp5.rds") #done 02.03
update_pp5<-readRDS("update_pp5.rds")

```

04.03 - now split into 3 dfs (plus keep original)
```{r}
#remove those for whom drinking status is NA
#library(tidyverse)
update_pp5 <- update_pp5 %>% filter(!(is.na(BL_drinker_status)))
#remove those for whom drinks per week is NA but are a current drinker
update_pp5<-update_pp5 %>% filter(!(BL_drinker_status=="Current"&is.na(weekly_units_B)))
#now further remove those who are more than weekly drinkers but report 0 drinks per week
update_pp5 <- update_pp5 %>% filter(!
                                      ((Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&weekly_units_B==0)
)


sum(is.na(update_pp5$T2dX_at_BL)) #good, everyone has this variable
df_LA<-update_pp5 %>% filter(BL_drinker_status=="Never")
df_CA<-update_pp5 %>% filter(BL_drinker_status=="Former")
df_DR<-update_pp5 %>% filter(BL_drinker_status=="Current")

nrow(df_CA)+nrow(df_LA)+nrow(df_DR) #adds up
update_pp5 %>% count(weekly_units_B) #still quite a few people on 0 drinks per week; let's check in the current drinker group
df_DR %>% count(weekly_units_B) #hmm yes they're all in there (but all are less than weekly drinkers)
df_DR %>% filter(weekly_units_B==0) %>% count(Alcohol.intake.frequency....Instance.0) #almost all are special occasions only, which makes sense if answered 0 drinks per month on average
df_LA %>% filter(weekly_units_B==0) #good, none
df_CA %>% filter(weekly_units_B==0) #good, none
```


```{r}
#now need to sub in 0 for NA in the combined df for weekly units, then do the log transformation
#so I think what needs to happen is that I calculate the gx in the overall combined df with controlsonly set to TRUE and family==binomial and strata_method set to ranked AND THEN split into 3 separate dfs 
#hmm actually can't split afterwards, because the strata will be different...
#so can do this in the full df, and also in the current drinker only df (or at least without former drinkers), but not sure how to do it in the nondrinker dfs since the G-X estimates will all be 0... > looks like Topiwala actually only did this sens analysis in a linear MR, but still not sure how that would work in non-drinkres > AND I note that Biddinger actually only did a sensitivity analysis by excluding abstainers, not looking at them separately 

#for now let's practice in the full dataset


update_pp6<-update_pp5 %>% mutate(weekly_units_B_R=case_when(is.na(weekly_units_B) ~ 0, TRUE~weekly_units_B))
#visualise skew
#range(update_pp5$weekly_units_B,na.rm=T)
#sum(update_pp5$weekly_units_B>300,na.rm=T) #remove the 9 people with more than 300 standard drinks per week
update_pp6<-update_pp6 %>% filter(weekly_units_B_R<=300)

#CONVERT T2D to factor
class(update_pp6$T2dX_at_BL) #hmm maybe need to convert to factor
update_pp6 %>% count(T2dX_at_BL)
update_pp6<-update_pp6 %>% mutate(T2dX_at_BL=as.factor((T2dX_at_BL)))

#17.03 save
saveRDS(update_pp6, file = "update_pp6.rds")
update_pp6<-readRDS("update_pp6.rds")


#basic visualisation of X-Y

ggplot(update_pp6,aes(x=weekly_units_B_R,y=HbA1c_BL_winsor))+ geom_point() + 
  geom_smooth(method='lm') #ok so this does show a negative linear result

ggplot(update_pp6,aes(x=weekly_units_B_R,y=IGF_BL_winsor))+ geom_point() + 
  geom_smooth(method='lm') #also shows a negative linear relationship > but might not be like that if added a polynomila -> IGF is a weird one unclear what it's relationship with diabetes is
#let's see what realtionship betwen IGF and T2D is




mod1<- glm(update_pp6$T2dX_at_BL~update_pp6$IGF_BL_winsor, family="binomial")
summary(mod1) # a small but sig negative relationship (increasing IGF leads to lower risk for T2dX)
mod2<- glm(update_pp6$T2dX_at_BL~update_pp6$weekly_units_B_R, family="binomial")
summary(mod2) #virtually no relationship here, but doesn't allow possibility of non-linear
logistic_model <- glm(update_pp6$T2dX_at_BL~update_pp6$weekly_units_B_R, family="binomial")
update_pp6<-update_pp6 %>% mutate(T2dX_at_BL=as.numeric(as.character(T2dX_at_BL)))
class(update_pp6$T2dX_at_BL)
ggplot(update_pp6, aes(x=weekly_units_B_R, y=T2dX_at_BL)) + geom_point() +
      stat_smooth(method="glm", color="green", se=FALSE,
                method.args = list(family=binomial))

#now try with gams
library(mgcv)
#install.packages("tidymv")
library(tidymv)
gam_binomial<-gam(T2dX_at_BL~s(weekly_units_B_R),family="binomial",data=update_pp6)
plot(gam_binomial,trans=exp) #hmm the CIs get too high after 250 drinks per week and make it too hard to read
update_gam<-update_pp6 %>% dplyr::filter(weekly_units_B_R<=50)
gam_binomial<-gam(T2dX_at_BL~s(weekly_units_B_R),family="binomial",data=update_gam)
plot(gam_binomial,trans=exp) #hmm so now we need to get rid of the CIs, and also get Y axis plotting on a log scale (let's try log10)
summary(gam_binomial)
options(scipen=999)
#AHHH OK Can see here that there are 3 ways to transform the scale, and exponentiating is one (so when then scale the y axis it cancels out?)
#https://ggplot2.tidyverse.org/reference/coord_trans.html
#so instead try
###AHHHHH NOW I REALISE THIS ISSUE also is that plot_smooths plots only the smooth term, no residuals included etc
tidymv::plot_smooths(model=gam_binomial,series=weekly_units_B_R,trans=exp) +
  coord_trans(y = "exp")
#so use this technique https://stefanocoretta.github.io/tidymv/articles/plot-smooths.html
pred<-get_gam_predictions(gam_binomial,weekly_units_B_R)
pred %>% ggplot(aes(weekly_units_B_R, T2dX_at_BL)) +
  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper), alpha = 0.3) +
  geom_line() #ohhh bugger this doesn't work either because still only plots the smooth rather than the whole graph
#AHHH my mistake was using get_gam_predictions (which gets predictions from a specific smooth) instead of predict_gam which uses the whole model: https://cran.r-project.org/web/packages/tidymv/vignettes/predict-gam.html
pred<-predict_gam(gam_binomial)
pred %>% ggplot(aes(weekly_units_B_R, exp(fit))) + 
  geom_line() + 
  geom_smooth_ci()+
  coord_trans(y = "exp") #hhhhmmmmm ok so this thing now only does what we want in that it only transforms the y axis scale rather than the numbres on it, but the estimates are still really different to the mgcv inbuilt plotting function

#24.04 too hard to plot the above, and also doesn't really even make sense too given it's cross-sectional only
#so just do hba1c for now
#need to include covariates
library(mgcv)
#install.packages("tidymv")
library(tidymv)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
gam_binomial<-gam(HbA1c_BL_winsor~s(weekly_units_B_R)+ Sex_F+ Age.at.recruitment,family="gaussian",data=update_pp679)
plot(gam_binomial) #hmm not sure how to set reference to 0

```

```{r}
ggplot(update_pp6, aes(x=weekly_units_B_R)) + 
  geom_density() #wow this looks silly because just so many more 0s than anything else
update_pp6 %>% filter(weekly_units_B_R>0) %>% ggplot(aes(x=weekly_units_B_R))+geom_density() #still very skewed even without the 0s
update_pp6<-update_pp6 %>% mutate(weekly_units_B_R_PLUS=weekly_units_B_R+1)
ggplot(update_pp6, aes(x=weekly_units_B_R_PLUS)) + 
  geom_density()
range(update_pp6$weekly_units_B_R_PLUS)
update_pp6<-update_pp6 %>% mutate(weekly_units_B_R_PLUS_T=log(weekly_units_B_R_PLUS))
range(update_pp6$weekly_units_B_R_PLUS_T)
ggplot(update_pp6, aes(x=weekly_units_B_R_PLUS_T)) + 
  geom_density() #still weird because of the zeros, but a lot better 

#12.03 G X scatterplot for Haodong (filter to those wih less than 250 units per week for clarity)
update_pp6<-update_pp6 %>% filter(weekly_units_B_R<=250)
df_DR<-df_DR %>% filter(weekly_units_B_R<=250)

ggplot(update_pp6,aes(y=weekly_units_B_R,x=GRS))+ geom_point() + 
  geom_smooth(method='lm') #untransformed, all people
ggplot(update_pp6,aes(y=weekly_units_B_R_PLUS_T,x=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #2.	Drinkers + non-drinkers, log-transformed (drinks per week +1)
ggplot(df_DR,aes(y=weekly_units_B_R,x=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #3.	Drinkers only, standard drinks pre week
ggplot(df_DR,aes(x=weekly_units_B_R_PLUS_T,y=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #4. drinkers only, long transformed drinks per week + 1
temp<-update_pp6 %>% select(weekly_units_B, GRS)
range(temp$GRS)
temp2<-head(update_pp6)


devtools::install_github("amymariemason/SUMnlmr")
#have to convert factor covariates to dummies
library(SUMnlmr)
#testing
test_data<-create_ind_data(N=10000, beta2=2, beta1=1)
test_data$centre<- as.factor(rbinom(nrow(test_data),4, 0.5))
head(test_data)
dummies<- model.matrix(~centre,data=test_data)[,2:5]

#actual dummies 
str_sort(names(update_pp6))
sum(is.na(update_pp6$Sex))
update_pp6 %>% count(Sex)
#####
#WHENEVER REREAD UPDATE_PP6, need to run code below this, and also replace GRS/GRS2 depending on which want to use
#####
#library(tidyverse)
update_pp6<-update_pp6 %>% dplyr::mutate(Sex_F=as.factor(Sex))
update_pp6 %>% count(Sex_F)
dummies_2<-model.matrix(~Sex, data=update_pp6)[,2]  #this doesn't actually make a matrix..., but wonder if it's close enough for purposes of binding later???
  update_pp6 %>% select(Genetic.principal.components...Array.1) %>% head() #this is continuous
  class(update_pp6$Genotype.measurement.batch)
  update_pp6 %>% count(Genotype.measurement.batch) #need to reduce this down to affymetrix vs UKBiLEVEAX
  sum(is.na(update_pp6$Genotype.measurement.batch)) # good 0, everyone has
  update_pp6 <-update_pp6 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  update_pp6 %>% count(array_type) #excellent
  dummies_3<-model.matrix(~array_type, data=update_pp6)[,2] 
  head(dummies_2)
  class(dummies_2)
  head(dummies_3)
  #alternative code didn't use - can make separate matrices of everything here, and form into a single matrix here before feeding into the nlmr code below
  dummies_4<-matrix(update_pp6$Age.at.recruitment)
  class(dummies_4)
  head(dummies_4)
  dummies_2_2<-matrix(dummies_2,ncol=1)
  dummies_3_2<-matrix(dummies_3,ncol=1)
#ACTUALLY, sum_Nlmr wil automatically convert these two variable successfully for me > just says attempting to convert and you say y (because it seems to be doing it correctly) -> ahh but when combine with all variables, becomes too large! instead need to convert the factors to matrices first/dummy code
 
  #note that matrices can only contain data of same type, which is the reaon for the dummy coding above, ok this seems to have worked!
  #updating to use untransformed drinks per week var
  library(SUMnlmr)
  update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  dummies_2<-model.matrix(~Sex, data=update_pp679 )[,2] 
  dummies_3<-model.matrix(~array_type, data=update_pp679 )[,2] 
  
summ_covar_FULL_T2D<-create_nlmr_summary(y = update_pp679$T2dX_at_BL,
                                 x = update_pp679$weekly_units_B_R,
                                 g = update_pp679$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(update_pp679$Age.at.recruitment, update_pp679$Genetic.principal.components...Array.1,update_pp679$Genetic.principal.components...Array.2,update_pp679$Genetic.principal.components...Array.3,update_pp679$Genetic.principal.components...Array.4,update_pp679$Genetic.principal.components...Array.5,update_pp679$Genetic.principal.components...Array.6,update_pp679$Genetic.principal.components...Array.7,update_pp679$Genetic.principal.components...Array.8,update_pp679$Genetic.principal.components...Array.9,update_pp679$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "binomial",
                                 q = 10, strata_method="ranked", controlsonly = TRUE)

model_FULL_T2D<- with(summ_covar_FULL_T2D$summary, frac_poly_summ_mr(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  family="binomial",
                  fig=TRUE)
)
summary(model_FULL_T2D)
model_FULL_T2D <-with(summ_covar_FULL_T2D$summary, piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="binomial",
                  ci_fig="ribbon")
)
summary(model_FULL_T2D)

#now re-dpoing above with current drinkers AND NEVER DRINKERS only
df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current"|BL_drinker_status=="Never")
dummies_2<-model.matrix(~Sex, data=df_DR)[,2] 
  dummies_3<-model.matrix(~array_type, data=df_DR)[,2] 
  summ_covar_DR_T2D<-create_nlmr_summary(y = df_DR$T2dX_at_BL,
                                 x = df_DR$weekly_units_B_R,
                                 g = df_DR$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(df_DR$Age.at.recruitment, df_DR$Genetic.principal.components...Array.1,df_DR$Genetic.principal.components...Array.2,df_DR$Genetic.principal.components...Array.3,df_DR$Genetic.principal.components...Array.4,df_DR$Genetic.principal.components...Array.5,df_DR$Genetic.principal.components...Array.6,df_DR$Genetic.principal.components...Array.7,df_DR$Genetic.principal.components...Array.8,df_DR$Genetic.principal.components...Array.9,df_DR$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "binomial",
                                 q = 10, strata_method="ranked", controlsonly = TRUE)
  model_DR_T2D<- with(summ_covar_DR_T2D$summary, frac_poly_summ_mr(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  family="binomial",
                  fig=TRUE)
)
summary(model_DR_T2D)
model_DR_T2D <-with(summ_covar_DR_T2D$summary, piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="binomial",
                  ci_fig="ribbon")
)
summary(model_DR_T2D)

#09.05 Amy comment -> redo above with drinkers only

df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current")
#then re-run above lines

```



#now repeat above for our two continuous measures
#HbA1c_BL_winsor
```{r}
library(tidyverse)
sum(is.na(update_pp679$HbA1c_BL_winsor))
#need to remove everyone who is NA for that var 
#update_pp679 %>% count(Sex)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  full_HbA1c<-update_pp679 %>% filter(!is.na(HbA1c_BL_winsor))
  #women only
  full_HbA1c_F<-full_HbA1c %>% filter(Sex=="Female")
  #men only
   full_HbA1c_M<-full_HbA1c %>% filter(Sex=="Male")
  

dummies_2<-model.matrix(~Sex, data=full_HbA1c)[,2] 
  dummies_3<-model.matrix(~array_type, data=full_HbA1c)[,2] 
  

summ_covar_FULL_HB<-create_nlmr_summary(y = full_HbA1c$HbA1c_BL_winsor,
                                 x = full_HbA1c$weekly_units_B_R,
                                 g = full_HbA1c$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(full_HbA1c$Age.at.recruitment, full_HbA1c$Genetic.principal.components...Array.1,full_HbA1c$Genetic.principal.components...Array.2,full_HbA1c$Genetic.principal.components...Array.3,full_HbA1c$Genetic.principal.components...Array.4,full_HbA1c$Genetic.principal.components...Array.5,full_HbA1c$Genetic.principal.components...Array.6,full_HbA1c$Genetic.principal.components...Array.7,full_HbA1c$Genetic.principal.components...Array.8,full_HbA1c$Genetic.principal.components...Array.9,full_HbA1c$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)
#MUST REMEMBER TO LOAD METAFOR LIBRARY BEFORE RUN MY VERSION OF THE FUNCTION!
#rather than having to remake function, simply override pref_y below
#also need to add ref values based on mean of lowest category for the fp (1.33), and min (0) for the piecewise
model_FULL_HB<- with(summ_covar_FULL_HB$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  ref=1.33,
                  pref_y = "Relative HbA1c, mmol/mol",
                  family="gaussian",
                  fig=TRUE,ylim_lower = -2.1, ylim_upper = 0, breaks= c(-2,-1.5,-1,-.5,0))
)
model_FULL_HB

summary(model_FULL_HB) 
sum_test<-summary(model_FULL_HB) 
xvals<-model_FULL_HB[["figure"]][["data"]][["x"]]
yvals<-model_FULL_HB[["figure"]][["data"]][["yest"]]
uci<-model_FULL_HB[["figure"]][["data"]][["uci"]]
xyvals<-data.frame(xvals,yvals,uci) 
#for nadir index
which.min(xyvals$yvals)
xyvals[8539,]

model_FULL_HB <-with(summ_covar_FULL_HB$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="gaussian",
                      pref_y = "Relative HbA1c, mmol/mol",
                  ci_fig="ribbon")
)
summary(model_FULL_HB)

#now re-dpoing above with current drinkers AND NEVER DRINKERS only
DR_HbA1c<-full_HbA1c %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
#15.05 doing as well for current drinkers only
DR_HbA1c<-full_HbA1c %>% filter(BL_drinker_status=="Current")

dummies_2<-model.matrix(~Sex, data=DR_HbA1c)[,2] 
  dummies_3<-model.matrix(~array_type, data=DR_HbA1c)[,2] 

  summ_covar_DR_HB<-create_nlmr_summary(y = DR_HbA1c$HbA1c_BL_winsor,
                                 x = DR_HbA1c$weekly_units_B_R,
                                 g = DR_HbA1c$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(DR_HbA1c$Age.at.recruitment, DR_HbA1c$Genetic.principal.components...Array.1,DR_HbA1c$Genetic.principal.components...Array.2,DR_HbA1c$Genetic.principal.components...Array.3,DR_HbA1c$Genetic.principal.components...Array.4,DR_HbA1c$Genetic.principal.components...Array.5,DR_HbA1c$Genetic.principal.components...Array.6,DR_HbA1c$Genetic.principal.components...Array.7,DR_HbA1c$Genetic.principal.components...Array.8,DR_HbA1c$Genetic.principal.components...Array.9,DR_HbA1c$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)
  #rather than having to remake function, simply override pref_y below
  model_DR_HB<- with(summ_covar_DR_HB$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  ref=2.85,  #ref=2.85 when current drinkers only
                  family="gaussian",
                   pref_y = "Relative HbA1c, mmol/mol",
                  fig=TRUE)
)
summary(model_DR_HB)


model_DR_HB <-with(summ_covar_DR_HB$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=.47,
                  family="gaussian",
                   pref_y = "Relative HbA1c, mmol/mol",
                  ci_fig="ribbon")
)
summary(model_DR_HB)



#22.11 split further by BMI category
full_HbA1c_F<-full_HbA1c_F %>% filter(!is.na(Body.mass.index..BMI....Instance.0.participant...p21001_i0.))
full_HbA1c_F_N<-full_HbA1c_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.<25) #ok so this is 68K/160K
full_HbA1c_F_OV<-full_HbA1c_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.>=25
                                             &Body.mass.index..BMI....Instance.0.participant...p21001_i0.<30) #60K
full_HbA1c_F_OB<-full_HbA1c_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.>30) #32K... might be a bit small?

#17.12 using Steven suggestion to stratify on residual BMI instead
#step one is to regress BMI on the PRS
sum(is.na(full_HbA1c_F$Body.mass.index..BMI....Instance.0.participant...p21001_i0.)) #427 people missing
sum(is.na(COX_update79_F$Body.mass.index..BMI....Instance.0.participant...p21001_i0.)) #443 people missing
#library(tidyverse)
full_HbA1c_F<-full_HbA1c_F %>% filter(!is.na(Body.mass.index..BMI....Instance.0.participant...p21001_i0.))
HBREG<-lm(Body.mass.index..BMI....Instance.0.participant...p21001_i0.~GRS_79, data=full_HbA1c_F )
full_HbA1c_F$value_lm <- HBREG$fitted.values
full_HbA1c_F<-full_HbA1c_F %>% mutate(resid_BMI=Body.mass.index..BMI....Instance.0.participant...p21001_i0.-value_lm)
range(full_HbA1c_F$resid_BMI) #these numbers are no longer meaningful in terms of BMI cut-offs, but instead we'll use tertiles
tertiles <- quantile(full_HbA1c_F$resid_BMI, probs=c(.333, .666), na.rm = FALSE)
full_HbA1c_F_N<-full_HbA1c_F %>% filter(resid_BMI <= -2.54) #51096
full_HbA1c_F_OV<-full_HbA1c_F %>% filter(resid_BMI > -2.54
                                             &resid_BMI <1.15) #51196
full_HbA1c_F_OB<-full_HbA1c_F %>% filter(resid_BMI >= 1.15) #51279


#24.04 doing the hba1c analysis stratified by sex
#dummies_2<-model.matrix(~Sex, data=full_HbA1c)[,2] 
library(SUMnlmr)
  dummies_3<-model.matrix(~array_type, data=full_HbA1c_M)[,2] 
  
summ_covar_F_NULL_HB<-create_nlmr_summary(y = full_HbA1c_M$HbA1c_BL_winsor,
                                 x = full_HbA1c_M$weekly_units_B_R,
                                 g = full_HbA1c_M$GRS_79,
                               covar=cbind(dummies_3,matrix(data=c(full_HbA1c_M$Age.at.recruitment, full_HbA1c_M$Genetic.principal.components...Array.1,full_HbA1c_M$Genetic.principal.components...Array.2,full_HbA1c_M$Genetic.principal.components...Array.3,full_HbA1c_M$Genetic.principal.components...Array.4,full_HbA1c_M$Genetic.principal.components...Array.5,full_HbA1c_M$Genetic.principal.components...Array.6,full_HbA1c_M$Genetic.principal.components...Array.7,full_HbA1c_M$Genetic.principal.components...Array.8,full_HbA1c_M$Genetic.principal.components...Array.9,full_HbA1c_M$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)


#ref should be .755 for women; 2.63 for men 
#for F N should be 1.08; .853 for OV; .307 for OB
#using tertiles FN 1.09 FOV .988 F OB should be .42
model_FULL_HB<- with(summ_covar_F_NULL_HB$summary, frac_poly_summ_mrRV(bx=bx, #can see the problem occurs here -> powers are 1 and 1
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  ref=2.63,
                  xmean=xmean,
                  family="gaussian",
                  pref_y = "Relative HbA1c, mmol/mol",
                  fig=TRUE, ,ylim_lower = -2.1, ylim_upper = 0, breaks= c(-2,-1.5,-1,-.5,0)) #these lims/breaks are for overall M+F+overall, not stratified by BMI/resid BMI will need to ammend these for suppl
) 
model_FULL_HB

sumMO<- summary(model_FULL_HB) #+ scale_x_continuous(breaks=seq(0,60,5))
max(model_FULL_HB[["figure"]][["data"]][["x"]]) #ahh ok can see here for female that the max x for the figure is 40.53 -> not sure why it only generated up to here -> ahh ok can see that what's happened is it takes the xmean from highest stratum
sumMO[["figure"]]+ scale_x_continuous(breaks=seq(0,60,5))
#hmm something's going wrong when try to apply my fp function above -> telling me the powers are 1 and 1 (X1 and X1.1) -> same for both female and male version
#hmm doing same thing when use the original frac_poly function too -> GOING TO LEAVE THIS FOR NOW AND HOPE IT FIXES BY THE TIME GET BACK TO IT
#update 17.05 -> is now working for males only (now matching original stats)! but same prob for females
```

#now repeat all the above but using residual method instead (wait to hear from Amy if appropriate); I think next step is to plot drinks per week against GRS just to make sure I've got it the right way, also drinks per week against the three outcomes to see basic observational results
#NO > can see from the G-X betas now that they change enormously over strata, s can't use residual method

#now try one-sample MR (use ivreg code)
https://cnsgenomics.com/data/teaching/CNSG/20160706_MR_Brion/2016_CNSG_MR_Tutorial.pdf
#updating 2SLS 20.03 to include covariates
#do 2SLS using ivtools package; IVW using Haodong method at bottom
```{r}
library(tidyverse)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))


install.packages("ivreg")
library(ivreg)
#library(tidyverse)
df_LA<-update_pp679 %>% filter(BL_drinker_status=="Never")
df_CA<-update_pp679 %>% filter(BL_drinker_status=="Former")
df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current")
df_LA_DR<-update_pp679 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")

#ivreg is having problems for cateforical outcome, soe start with continuous
sum(is.na(update_pp679$T2dX_at_BL))
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=update_pp679) ) #ok so this is for full sample (small but significant linear relationship)
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_DR) ) #for drinkers, again a small but sig neg linear relationship
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_CA) ) #as predicted, doesn't work!
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_LA) ) #as predicted, doesn't work!

#need to run these ones below
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=update_pp679) ) #ok so this is for full sample (small but significant NEGATIVE linear relationship) - aligns with the plos one paper but much much smaller effect
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_DR) ) #basically same as above (-.03)
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_CA) ) #as predicted, doesn't work!
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_LA) ) #as predicted, doesn't work!

#AHH OK IVREG CAN'T DO categorical outcomes (in fact, it's not called 2SLS with binary outcome - instead it's like 2 stage something else) -> but https://academic.oup.com/ije/article/42/4/1134/657927 says to use the tsls function from sem package for two stage least squares
install.packages("sem")
library(sem)
summary(tsls(HbA1c_BL_winsor~weekly_units_B_R, ~ GRS, data=update_pp679)) #HMMMM STILL NOT WORKING FOR A logistic regression
#but did work when tried HbA1C instead (same estimate as when use ivreg above)
#ahh ok can use the new ivtools package: https://www.degruyter.com/document/doi/10.1515/em-2018-0024/html
install.packages("ivtools")
library(tidyverse)
library(ivtools)
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) #so can caluclate G-X in controls only
 fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX not much there at all really
  confint(fitIV_ts)
  
  ###REPLACE T2DX with HBA1C as needed (and swap out binomial and gaussian, and for the fitX.LZ, data should be df_noD for T2D but regular update_pp679 for HbA1c)
  #version including covariates
   fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS_79+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) 
  confint(fitIV_ts)---
title: "Visualize GWAS results"
output: html_document
---

# Explore and annotate GWAS results

This notebook is delivered "As-Is". Notwithstanding anything to the contrary, DNAnexus will have no warranty, support, liability or other obligations with respect to Materials provided hereunder.

[MIT License](https://github.com/dnanexus/UKB_RAP/blob/main/LICENSE) applies to this notebook.


## Working with flat files on DNAnexus in R

Let's process and concatenate regenie output files before loading it into R.


#16.04 Started re-running everything and got up to recalculating diabetes vars etc, but actually realise all I have to do once have the Liu GRS is join it to exisitng old update_pp6 file

```{r}
library(tidyverse)
COX_update<-readRDS("COX_update.rds")
update_pp6<-readRDS("update_pp6.rds")
merged_df_Liu_wGRS2<-readRDS("merged_df_Liu_wGRS2.rds")

#22.04 change SNP names to VV for Liu_79, and then keep so can run MR egger on them later
#change SNP names to VV
names(merged_df_Liu_wGRS2)<-gsub("V", "VV", names(merged_df_Liu_wGRS2))
str_sort(names(merged_df_Liu_wGRS2))
colnames<-grep("^VV[0-9]+",names(merged_df_Liu_wGRS2))
GRS2df<-merged_df_Liu_wGRS2 %>% select(ID_1, GRS2,all_of(colnames)) #great!
str_sort(names(GRS2df))
GRS2df<-GRS2df %>% mutate(GRS_79=GRS2)
colnames<-grep("^VV[0-9]+",names(GRS2df))
GRS2df<-GRS2df %>% select(ID_1,GRS_79,all_of(colnames))

COX_update79<-COX_update %>% left_join(GRS2df, by="ID_1")
update_pp679<-update_pp6%>% left_join(GRS2df, by="ID_1")
saveRDS(update_pp679, file="update_pp679.rds")
saveRDS(COX_update79, file="COX_update79.rds")

COX_update79<-readRDS("COX_update79.rds") #resaved 22.04 #resaved 10.05 so that the survival object is already made
update_pp679<-readRDS("update_pp679.rds") #resaved 22.04 # resvaed 19.05 so that sex_F and array are already made

```


#08.08
#hmm annoying that the columns don't have more informative headers (fixed this with 08.08 csv)..., also now need to figure out how to get genotype (incl. imputed) data in -> even when I redid the data preview thing using field_title option and then reexported using table exporter, still doesn't given informative headers
#15.08 good news the downloaded csvs are still in the folder that I restored at the beginning of the session (now just need to read them into the environment again)

```{r}


library(tidyverse) #this won't work because there is a problem with 'cli'; updated manually in bottom right window; now getting that issue with dplyr
#packageVersion("dplyr")
#update.packages()
#install.packages("dplyr")
#library(dplyr) #not working - need to uninstall tidyr in system packages because this has dolyr 1.0.8 and can't have this loaded if want to lod the new version of dplyr in my user library of packages -> argh it will not delete (because of broom)
#realie 24.10 if havig these problems just restart the session and it should work

#str_order(names(main)) #can't get this working atm as str_order is pat of Kmisc package which comes with tidyverse (and can't seem to download Kmisc directly)
#names(main)
#head(main)
#main %>% glimpse()

primary_pheno<-read.csv("28.11_participant_current.csv")
```


#RV 18.11 checking mfi files for MAF and info scores for our 93 SNPs
```{r}
system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c1_b0_v3.mfi.txt"')
MFI_1<-read.delim("ukb22828_c1_b0_v3.mfi.txt",header=F)
head(MFI_1)

Liu<-read.csv("Liu_small_proper.csv")
Liu_split<-split(Liu, Liu$Chr)
Liu_split_2 <- lapply(Liu_split,function (Liu){ 
  bigSNPr_ids <- Liu$rsID
  }
) 

library(tidyverse)
MFI_1_F<-MFI_1 %>% filter(V2 %in% Liu_split_2[["1"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c2_b0_v3.mfi.txt"')
MFI_2<-read.delim("ukb22828_c2_b0_v3.mfi.txt",header=F)
MFI_2_F<-MFI_2 %>% filter(V2 %in% Liu_split_2[["2"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c3_b0_v3.mfi.txt"')
MFI_3<-read.delim("ukb22828_c3_b0_v3.mfi.txt",header=F)
MFI_3_F<-MFI_3 %>% filter(V2 %in% Liu_split_2[["3"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c4_b0_v3.mfi.txt"')
MFI_4<-read.delim("ukb22828_c4_b0_v3.mfi.txt",header=F)
MFI_4_F<-MFI_4 %>% filter(V2 %in% Liu_split_2[["4"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c5_b0_v3.mfi.txt"')
MFI_5<-read.delim("ukb22828_c5_b0_v3.mfi.txt",header=F)
MFI_5_F<-MFI_5 %>% filter(V2 %in% Liu_split_2[["5"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c6_b0_v3.mfi.txt"')
MFI_6<-read.delim("ukb22828_c6_b0_v3.mfi.txt",header=F)
MFI_6_F<-MFI_6 %>% filter(V2 %in% Liu_split_2[["6"]]) #no data - remember there were none from c6 in Liu

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c7_b0_v3.mfi.txt"')
MFI_7<-read.delim("ukb22828_c7_b0_v3.mfi.txt",header=F)
MFI_7_F<-MFI_7 %>% filter(V2 %in% Liu_split_2[["7"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c8_b0_v3.mfi.txt"')
MFI_8<-read.delim("ukb22828_c8_b0_v3.mfi.txt",header=F)
MFI_8_F<-MFI_8 %>% filter(V2 %in% Liu_split_2[["8"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c9_b0_v3.mfi.txt"')
MFI_9<-read.delim("ukb22828_c9_b0_v3.mfi.txt",header=F)
MFI_9_F<-MFI_9 %>% filter(V2 %in% Liu_split_2[["9"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c10_b0_v3.mfi.txt"')
MFI_10<-read.delim("ukb22828_c10_b0_v3.mfi.txt",header=F)
MFI_10_F<-MFI_10 %>% filter(V2 %in% Liu_split_2[["10"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c11_b0_v3.mfi.txt"')
MFI_11<-read.delim("ukb22828_c11_b0_v3.mfi.txt",header=F)
MFI_11_F<-MFI_11 %>% filter(V2 %in% Liu_split_2[["11"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c12_b0_v3.mfi.txt"')
MFI_12<-read.delim("ukb22828_c12_b0_v3.mfi.txt",header=F)
MFI_12_F<-MFI_12 %>% filter(V2 %in% Liu_split_2[["12"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c13_b0_v3.mfi.txt"')
MFI_13<-read.delim("ukb22828_c13_b0_v3.mfi.txt",header=F)
MFI_13_F<-MFI_13%>% filter(V2 %in% Liu_split_2[["13"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c14_b0_v3.mfi.txt"')
MFI_14<-read.delim("ukb22828_c14_b0_v3.mfi.txt",header=F)
MFI_14_F<-MFI_14 %>% filter(V2 %in% Liu_split_2[["14"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c15_b0_v3.mfi.txt"')
MFI_15<-read.delim("ukb22828_c15_b0_v3.mfi.txt",header=F)
MFI_15_F<-MFI_15%>% filter(V2 %in% Liu_split_2[["15"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c16_b0_v3.mfi.txt"')
MFI_16<-read.delim("ukb22828_c16_b0_v3.mfi.txt",header=F)
MFI_16_F<-MFI_16 %>% filter(V2 %in% Liu_split_2[["16"]])

MFI_17<-read.delim("ukb22828_c17_b0_v3.mfi.txt",header=F)
MFI_17_F<-MFI_17%>% filter(V2 %in% Liu_split_2[["17"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c18_b0_v3.mfi.txt"')
MFI_18<-read.delim("ukb22828_c18_b0_v3.mfi.txt",header=F)
MFI_18_F<-MFI_18%>% filter(V2 %in% Liu_split_2[["18"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c19_b0_v3.mfi.txt"')
MFI_19<-read.delim("ukb22828_c19_b0_v3.mfi.txt",header=F)
MFI_19_F<-MFI_19 %>% filter(V2 %in% Liu_split_2[["19"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c20_b0_v3.mfi.txt"')
MFI_20<-read.delim("ukb22828_c20_b0_v3.mfi.txt",header=F)
MFI_20_F<-MFI_20%>% filter(V2 %in% Liu_split_2[["20"]])

system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c22_b0_v3.mfi.txt"')
MFI_22<-read.delim("ukb22828_c22_b0_v3.mfi.txt",header=F)
MFI_22_F<-MFI_22 %>% filter(V2 %in% Liu_split_2[["22"]])


```




#17.10 - going to try using bigsnpr to join concatenate bgen files
#15.04 updating
```{r}
system('dx download "/ONESAMPfinal.Rda"')
Liu<-readRDS("ONESAMPfinal.Rda")
Liu_split<-split(Liu, Liu$Chr)

Liu_split_2 <- lapply(Liu_split,function (Liu){ 
  bigSNPr_ids <- paste(Liu$Chr, Liu$Position, Liu$Reference.Allele, Liu$Alternate.Allele, sep="_")
  }
) #GREAT THIS WORKED!


#now concatenate all the chromosomes
#Liu<-read.csv("ONESAMPfinal.csv")
#Liu_split<-split(Liu, Liu$Chr)
#Liu_split_2 <- lapply(Liu_split,function (Liu){ 
#  bigSNPr_ids <- paste(Liu$Chr, Liu$Position, Liu$Reference.Allele, Liu$Alternate.Allele, sep="_")
#  }
#) 

#can't include C6 and C21 because the Liu_split_2 list doesn't have them

  rdsLiu <- bigsnpr::snp_readBGEN(
    bgenfiles   = c("c1filtered.bgen","c2filtered.bgen", "c3filtered.bgen", "c4filtered.bgen", "c5filtered.bgen",  "c7filtered.bgen", "c8filtered.bgen", "c9filtered.bgen", "c10filtered.bgen", "c11filtered.bgen", "c12filtered.bgen", "c13filtered.bgen", "c14filtered.bgen", "c15filtered.bgen", "c16filtered.bgen", "c17filtered.bgen", "c18filtered.bgen", "c19filtered.bgen", "c20filtered.bgen", "c22filtered.bgen"),
    list_snp_id = Liu_split_2,
    backingfile = "...x", #note this has to be different every time otherwise it will error message saying you already have a .bk file with this name
  )
  #test <- bigsnpr::snp_attach(rds)
  #head(test[["genotypes"]])
#names(test[["genotypes"]])

  
```


#28.01 reading this RDS file back in
```{r}
rdsLiu<-readRDS("...x.rds")
test<-rdsLiu
  head(test[["genotypes"]])
names(test[["genotypes"]])

```




#EXCELLENT! so file with all genotype data in them is called test
#then need to double check that the sample files are all identical (ie only need to read one in)

```{r}
#system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c1_b0_v3.sample"')
#system('dx download "/Bulk/Imputation/UKB imputation from genotype/ukb22828_c2_b0_v3.sample"')

sample1 <- data.table::fread("ukb22828_c1_b0_v3.sample")
sample2 <- data.table::fread("ukb22828_c2_b0_v3.sample") #yes they are the same! has 487410 rows (not including col headers), first is meaningless symbols (ahhh https://www.well.ox.ac.uk/~gav/snptest/#input_file_formats explains that this row gives the details on the data types for each column); test[[genotype]] has 487409 rows
```


```{r}
#remove first row from sample file (which is what the bigsnpr person does here to the sample file by removing first row https://github.com/privefl/UKBiobank/blob/master/10-get-dosages.R; copy their method in line below)
head(sample1)
sample1<-sample1[-1,]
range(sample1$ID_1) #hmm why are there so many negative ID values here...  all the negative IDs have 0 for sex so they can't be used
library(tidyverse)
range(primary_pheno$Participant.ID)
#wait part of the problem is that old_pheno has way 15,000 extra observations than sample1/genotype file
ind.indiv <- setdiff(primary_pheno$Participant.ID, sample1$ID_1) #15207
ind.indiv <- setdiff(sample1$ID_1,primary_pheno$Participant.ID) #207 Ids in sample1 that don't exist in pheno
#I think simply need to remove the negative ids BECAUSE THEY HAVE WITHDRAWN CONSET (yes> see FAQ: https://www.ukbiobank.ac.uk/media/emlnk0dk/access_064-uk-biobank-exome-release-faq_v11-final.pdf)
#library(tidyverse)
sample1 %>% count(ID_1<0) #so that's 207 people > ahh these must be the same 207 people missing from the pheno file > this means also need to remove these people from the geno file! >done in chunk below
head(sample1)


sample1_F<-sample1 %>% filter(ID_1>0)
#then remove any people from the pheno file that don't have a corresponding ID in the sample file (leaves us with 487202 people)
geno_ids<-sample1_F$ID_1
primary_pheno_small<-primary_pheno[primary_pheno$Participant.ID %in% geno_ids, ]

#head(sample1)
#head(primary_pheno_small)

#now reorder pheno file according to sample file
#mm this didn't work ... old_pheno_small_reordered<-old_pheno_small[match(geno_ids,old_pheno_small$Participant.ID),]
primary_pheno_small<-primary_pheno_small %>% mutate(ID_1=Participant.ID)
primary_pheno_small_reordered<-full_join(sample1_F,primary_pheno_small,by="ID_1")
head(primary_pheno_small_reordered) #FANTASTIC THIS WORKED 

```

#NEXT STEP IS TO join pheno file to geno file (geno file should already be in the same order as sample/pheno according to Amy) -> FANTSTIC - the way to do get this out of a bigSNP file to data frame is with matrix! https://github.com/privefl/bigsnpr/issues/165
```{r}
#class(test$genotypes)
test<-rdsLiu
genodata<-test$genotypes
geno_matrix<-genodata[]
geno_df<-as.data.frame(geno_matrix) #hmmm why are there 487409 observations here, instead of 487202? > SOLVED BELOW!

#need to remove the 207 people who have withdrawn conset - first join sample file so have IDs
geno_df2<-cbind(sample1,geno_df)
geno_df2_F<-geno_df2 %>% filter(ID_1>0) #down from 487409 to 487202!
head(geno_df2_F)

#now merge pheno with geno
#first check that no overlap in column names
str_sort(names(primary_pheno_small_reordered)) #only overlap for ID_1, ID_2, and sex

merged_df<-full_join(primary_pheno_small_reordered,geno_df2_F,by="ID_1")
#now save this
#updating names here 15.04 so don't override versions based on 2022 GSCAn
merged_df_Liu<-merged_df
saveRDS(merged_df_Liu, file = "merged_df_Liu.rds")
merged_df_Liu<-readRDS("merged_df_Liu.rds")
```

#create GRS for Liu with back up betas
#updated 15.04
```{r}

system('dx download "DrinksPerWeek.WithoutUKB.txt.gz"')
Liu_reduced = read.table(gzfile("DrinksPerWeek.WithoutUKB.txt.gz"),sep="\t")
#install.packages("janitor")
#library(tidyverse)
Liu_reduced<-Liu_reduced %>% janitor::row_to_names(row_number=1)
Liu_reduced<-Liu_reduced %>% mutate(PVALUE=as.numeric(PVALUE)) %>% mutate(BETA=as.numeric(BETA)) %>% mutate(SE=as.numeric(SE))
SNPs79<-Liu$rsID
Liu_reduced_matching_79SNPS<-Liu_reduced %>% filter(RSID %in% SNPs79)

#now save this reduced matching dataset so don't have to read that huge table in every time
saveRDS(Liu_reduced_matching_79SNPS, file="Liu_reduced_matching_79SNPS.rds")
Liu_reduced_matching_79SNPS<-readRDS("Liu_reduced_matching_79SNPS.rds")

rm(Liu_reduced)


Liu_reduced_matching_79SNPS<-Liu_reduced_matching_79SNPS %>% mutate(SNP=RSID)
#merged<-left_join(Liu,Liu_reduced_matching_363SNPS,by="SNP")
#merged_F<-merged %>% filter(!is.na(EFFECTIVE_N))

Liu_reduced_matching_79SNPS<-Liu_reduced_matching_79SNPS %>% mutate(X=1:79)
betas<-Liu_reduced_matching_79SNPS$BETA
X<-Liu_reduced_matching_79SNPS$X
df<-data.frame(X, betas)
class(df$X)
df<-df %>% mutate(X=as.character(X))
df$X <- sub("^", "V", df$X )
#names(rds)
X<-df$X
#https://stackoverflow.com/questions/70856361/how-to-create-a-weighted-sum-score-based-on-a-second-dataset-for-specific-variab
df2<-df[1:2,]

#library(tidyverse)
merged_df_Liu_wGRS2<-merged_df_Liu %>%
 mutate(GRS2 = rowSums(across(all_of(df$X), ~ .x * deframe(df)[[cur_column()]])))
temp<-merged_df_Liu_wGRS2 %>% select(ID_1, GRS2)
#WOW THIS RAN VERY QUICKLY
#merged_df2<-merged_df 
#hmm this keeps quitting on me before finishing running!
#let's try the base R version of this and see if it runs instead -> 15.04 funnily enough the below didn't work this time
#merged_df_Liu$GRS2 <- as.vector(as.matrix(merged_df_Liu[df$X]) %*% #this is telling it to cross-product the matrices
 #      with(df, setNames(betas, X)))

saveRDS(merged_df_Liu_wGRS2, file="merged_df_Liu_wGRS2.rds")
merged_df_Liu_wGRS2<-readRDS("merged_df_Liu_wGRS2.rds")




 #YAY THIS WORKED! - need to check that actually the strands are aligned the same way for UKB
#to do this
#checking again 23.03
#up to here end of 15.04
check<-head(merged_df_Liu_wGRS2)
p1<-check[1,] %>% select(V1:V79)
p2<-Liu_reduced_matching_79SNPS$BETA
#now transpose p1 so it's one column instead of one row
p3<-t(p1)
pcheck<-data.frame(p3,p2)
pcheck<-pcheck %>% mutate(p4=p3*p2)
sum(pcheck$p4) #0.1645498
#now compare to the GRS calculated above for person 1
check[1,] %>% select(GRS2) #BINGO! -> so we know the function is working correctly 16.04.23
#now we just need to check that the weights assigned from the CSV DEFINITELY refer to the same allele as the number of copies of allele (V1:V79) variables do

#first read in old filtered MFI file (refers to 363 version of GSCAN, but can filter down to relevant vars)
load(file="full_MFI_F.Rda")
MFI_small_missing<-full_MFI_F %>% filter(V2 %in% Liu_reduced_matching_79SNPS$RSID) #ONLY 17 of the 79!
comparLiu<-Liu_reduced_matching_79SNPS %>% filter(RSID %in% MFI_small_missing$V2)
identical(comparLiu$REF,MFI_small_missing$V4) #excellent! although this is only checking 17 of the 79 snps

#and further check that V4 from the MFI is actually where the reference allele is
#so this indicates that allele1 is the reference allele: https://biobank.ctsu.ox.ac.uk/crystal/refer.cgi?id=531; but to double check I'm downlodaing the marker qc text file (which that page indicates definitely has allele 1 as reference allele) to see if it lines up with the mfi file https://biobank.ctsu.ox.ac.uk/crystal/refer.cgi?id=1955
myfile <- read.table(url("https://biobank.ctsu.ox.ac.uk/crystal/ukb/auxdata/ukb_snp_qc.txt"))
head(myfile)
myfile2<-myfile %>% janitor::row_to_names(row_number=1) %>% janitor::clean_names()
test<-myfile2[1,]
myfileF<-myfile2 %>% filter(rs_id %in% comparLiu$RSID) #now only 3 of the SNPs are in here... weird?
compar_MFI<-MFI_small_missing %>% filter(V2 %in% myfileF$rs_id)
identical(compar_MFI$V4,myfileF$allele1_ref) #yes - but based only on 3 SNPs...

#ok so fairly confident the GRS has been correctly made! (16.04)
```




#now run below code chunks - 1st to create derived alcohol variables; 2nd to create derived diabetes variables/ filter out people with diabetes at baselin; then save the data again > THEN READY FOR NLMR PACKAGE!


#RV 24.10 going to write code for making drinks per week variable, using old pheno data above (then need to regenerate pheno data)
#FIRST DIVIDE PEOPLE INTO DRINKER, LIFETIME ABSTAINER, FORMER 
```{r}
#main %>% count(Alcohol.drinker.status...Instance.0) 
#sum(is.na(main$Alcohol.drinker.status...Instance.0))# a little missing data here, but recognised as blank rather than missing
merged_df2<-merged_df_Liu_wGRS2 %>% mutate(BL_drinker_status=case_when(Alcohol.drinker.status...Instance.0=="Current" ~ "Current", Alcohol.drinker.status...Instance.0=="Never" ~ "Never",Alcohol.drinker.status...Instance.0=="Previous" ~ "Former", TRUE~NA_character_))
merged_df2 %>% count(BL_drinker_status)
```
#whether weekly or less drinker
```{r}
merged_df2 %>% count(Alcohol.intake.frequency....Instance.0)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BL_drinker_status,exclude=NULL) # A will be rows, B will be columns
mytable
```

```{r}
#need to make all these variables numeric
merged_df2<-merged_df2 %>% mutate(weekly_RW=case_when(Average.weekly.red.wine.intake...Instance.0==""|Average.weekly.red.wine.intake...Instance.0=="Do not know"|Average.weekly.red.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.red.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_RW=as.numeric(weekly_RW))
merged_df2 %>% count(weekly_RW) #excellent -> now copy this syntax for all per week and per month vars (then make weekly drinks with case_when code saying if missing per week var, then use per month var? OR else could base this on the frequency variable instead)

merged_df2<-merged_df2 %>% mutate(weekly_WW=case_when(Average.weekly.champagne.plus.white.wine.intake...Instance.0==""|Average.weekly.champagne.plus.white.wine.intake...Instance.0=="Do not know"|Average.weekly.champagne.plus.white.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.champagne.plus.white.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_WW=as.numeric(weekly_WW))
merged_df2 %>% count(weekly_WW)

merged_df2<-merged_df2 %>% mutate(weekly_BC=case_when(Average.weekly.beer.plus.cider.intake...Instance.0==""|Average.weekly.beer.plus.cider.intake...Instance.0=="Do not know"|Average.weekly.beer.plus.cider.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.beer.plus.cider.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_BC=as.numeric(weekly_BC))
merged_df2 %>% count(weekly_BC)


merged_df2<-merged_df2 %>% mutate(weekly_S=case_when(Average.weekly.spirits.intake...Instance.0==""|Average.weekly.spirits.intake...Instance.0=="Do not know"|Average.weekly.spirits.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.spirits.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_S=as.numeric(weekly_S))
merged_df2 %>% count(weekly_S)

merged_df2<-merged_df2 %>% mutate(weekly_FW=case_when(Average.weekly.fortified.wine.intake...Instance.0==""|Average.weekly.fortified.wine.intake...Instance.0=="Do not know"|Average.weekly.fortified.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.fortified.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_FW=as.numeric(weekly_FW))
merged_df2 %>% count(weekly_FW)

merged_df2 %>% count(Average.weekly.intake.of.other.alcoholic.drinks...Instance.0)
merged_df2<-merged_df2 %>% mutate(weekly_O=case_when(Average.weekly.intake.of.other.alcoholic.drinks...Instance.0==""|Average.weekly.intake.of.other.alcoholic.drinks...Instance.0=="Do not know"|Average.weekly.intake.of.other.alcoholic.drinks...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.weekly.intake.of.other.alcoholic.drinks...Instance.0))
merged_df2<-merged_df2 %>% mutate(weekly_O=as.numeric(weekly_O))
merged_df2 %>% count(weekly_O)
 



#a check using BC just to make sure that non-NA (0 or 2) responses are only coming from at least daily drinkers (YEP!)
#there are also NAs for weekly or more drinkers, but this is just probably refusal/don't know responses
merged_df2<-merged_df2 %>% mutate(BC_NA=case_when(is.na(weekly_BC)~1, weekly_BC==0 ~ 0, TRUE~2))
merged_df2 %>% count(BC_NA)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BC_NA,exclude=NULL) # A will be rows, B will be columns
mytable

merged_df2<-merged_df2 %>% mutate(O_NA=case_when(is.na(weekly_O)~1, weekly_O==0 ~ 0, TRUE~2))
merged_df2 %>% count(O_NA)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$O_NA,exclude=NULL) # A will be rows, B will be columns
mytable #SO MANY NAs for this drink question

```

#now monthly versions
```{r}
#need to make all these variables numeric
merged_df2<-merged_df2 %>% mutate(monthly_RW=case_when(Average.monthly.red.wine.intake...Instance.0==""|Average.monthly.red.wine.intake...Instance.0=="Do not know"|Average.monthly.red.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.red.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_RW=as.numeric(monthly_RW))
merged_df2 %>% count(monthly_RW) 

merged_df2<-merged_df2 %>% mutate(monthly_WW=case_when(Average.monthly.champagne.plus.white.wine.intake...Instance.0==""|Average.monthly.champagne.plus.white.wine.intake...Instance.0=="Do not know"|Average.monthly.champagne.plus.white.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.champagne.plus.white.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_WW=as.numeric(monthly_WW))
merged_df2 %>% count(monthly_WW)


merged_df2 %>% count(Average.monthly.beer.plus.cider.intake...Instance.0)
sum(merged_df2$Average.monthly.beer.plus.cider.intake...Instance.0=="")
merged_df2<-merged_df2 %>% mutate(monthly_BC=case_when(Average.monthly.beer.plus.cider.intake...Instance.0==""|Average.monthly.beer.plus.cider.intake...Instance.0=="Do not know"|Average.monthly.beer.plus.cider.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.beer.plus.cider.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_BC=as.numeric(monthly_BC))
merged_df2 %>% count(monthly_BC)

merged_df2<-merged_df2 %>% mutate(monthly_S=case_when(Average.monthly.spirits.intake...Instance.0==""|Average.monthly.spirits.intake...Instance.0=="Do not know"|Average.monthly.spirits.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.spirits.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_S=as.numeric(monthly_S))
merged_df2 %>% count(monthly_S)

merged_df2<-merged_df2 %>% mutate(monthly_FW=case_when(Average.monthly.fortified.wine.intake...Instance.0==""|Average.monthly.fortified.wine.intake...Instance.0=="Do not know"|Average.monthly.fortified.wine.intake...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.fortified.wine.intake...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_FW=as.numeric(monthly_FW))
merged_df2 %>% count(monthly_FW)

merged_df2<-merged_df2 %>% mutate(monthly_O=case_when(Average.monthly.intake.of.other.alcoholic.drinks...Instance.0==""|Average.monthly.intake.of.other.alcoholic.drinks...Instance.0=="Do not know"|Average.monthly.intake.of.other.alcoholic.drinks...Instance.0=="Prefer not to answer" ~ NA_character_, TRUE~Average.monthly.intake.of.other.alcoholic.drinks...Instance.0))
merged_df2<-merged_df2 %>% mutate(monthly_O=as.numeric(monthly_O))
merged_df2 %>% count(monthly_O)


#a check using BC just to make sure that non-NA (0 or 2) responses are only coming from less than weekly (but still current) drinkers (YEP!) - HMMM but there are too many NAs for less than monthly drinkers (almost double the number of people saying they have 0 or more beers/ciders per month) -> unfortunately (merged_df2 %>% count(Average.monthly.beer.plus.cider.intake...Instance.0)) this shows there are just a lot of people who have a blank response for this question > can see this in the raw CSV too
merged_df2<-merged_df2 %>% mutate(BC_NA2=case_when(is.na(monthly_BC)~1, monthly_BC==0 ~ 0, TRUE~2))
merged_df2 %>% count(BC_NA2)
mytable <- table(merged_df2$Alcohol.intake.frequency....Instance.0,merged_df2$BC_NA2,exclude=NULL) # A will be rows, B will be columns
mytable

```

#since Biddinger doesn't say how converted monthly to weekly, will use Topiwla's 4.3 weeks to a month conversion for Biddinger version too

Let's do one route Topiwala conversion (need to use weekly variables for weekly drinkers, and monthly divided by 4.3 for less than weekl drinkers): red or white wine = 1.7 units; fortified wine=1.2 units; pint = 2.4 units; spirits = 1 unit; other (e.g. alcopops) =1.2 units. 
-need to make it so that if someone is missing units for one of the varieties of alcohol (as opposed to 0), then we have to exclude them
```{r}

sum((merged_df2$Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|merged_df2$Alcohol.intake.frequency....Instance.0=="Once or twice a week"|merged_df2$Alcohol.intake.frequency....Instance.0=="Three or four times a week")
&!(is.na(merged_df2$weekly_RW)
   |is.na(merged_df2$weekly_WW)|is.na(merged_df2$weekly_BC)|is.na(merged_df2$weekly_S)|is.na(merged_df2$weekly_FW)|is.na(merged_df2$weekly_O))) #hmm so only 113991 here - meaning that a lot of people are missing responses for at least one of the beverages
#AHAH - it's coming from the 'other' drinks category

#updating this to remove the other volume q from the case_when conditions

#note for below, need to use sum>simply + in order to use the na.rm argument, but then must also use intermediate rowwise step so that it doesn't sum the entire two columns
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(weekly_weighted=sum(1.7*weekly_RW, 1.7*weekly_WW, 2.4*weekly_BC, 1*weekly_S, 1.2*weekly_FW ,1.2*weekly_O,na.rm=TRUE))
merged_df2 %>% count(weekly_weighted)
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(monthly_weighted=sum(1.7*monthly_RW, 1.7*monthly_WW, 2.4*monthly_BC, 1*monthly_S, 1.2*monthly_FW, 1.2*monthly_O,na.rm=TRUE))
merged_df2 %>% count(monthly_weighted)

merged_df2<-merged_df2 %>% mutate(weekly_units_T=case_when( (Alcohol.intake.frequency....Instance.0==""|Alcohol.intake.frequency....Instance.0=="Never"|Alcohol.intake.frequency....Instance.0=="Prefer not to answer") ~ NA_real_,
  (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&(is.na(weekly_RW)|is.na(weekly_WW)|is.na(weekly_BC)|is.na(weekly_S)|is.na(weekly_FW)) ~ NA_real_,
   (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week") ~ weekly_weighted,  
   (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&(is.na(monthly_RW)|is.na(monthly_WW)|is.na(monthly_BC)|is.na(monthly_S)|is.na(monthly_FW)) ~ NA_real_,   
    (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")~ (monthly_weighted/4.3) 
   ))
merged_df2 %>% count(weekly_units_T)
sum(is.na(merged_df2$weekly_units_T))#argh this is very high 348,870 (includes non-drinkers)
sum(!is.na(merged_df2$weekly_units_T))#153,539 > add roughly 40,000 for the non-drinkers, but this is STILL less than the number of people Topiwala had with full alcohol AND outcome AND covariate data for her obserational analysis...
#hmm I think I must've made an error with the weekly drinkers too (too many of them missing) 
#can see just from the weekly answers that should have AT LEAST 345,024 people, so something is wrong with my code for calculating weekly units
#05.11 the prolem is cominf from the abundance of NAs to the other drinks volume qs - need to check how to deal with that
#> found a paper that says to treat NA on this question only as a 0
#> fabulous fixed! the non-na sum is now 379824!

```


And one route Biddinger (which is different even considering the UK to US conversion)
1 beer/cider=16g (2 UK drinks), 1 wine = 16.8 (2.1), 1 fortified = 14.8 (1.76), 1 spirtis = 8g (1); 1 other = 12g (1.5)

```{r}

merged_df2<-merged_df2 %>% rowwise() %>%  mutate(weekly_weighted_B=sum(2.1*weekly_RW, 2.1*weekly_WW, 2*weekly_BC, 1*weekly_S, 1.76*weekly_FW ,1.5*weekly_O,na.rm=TRUE))
merged_df2 %>% count(weekly_weighted_B)
merged_df2<-merged_df2 %>% rowwise() %>%  mutate(monthly_weighted_B=sum(2.1*monthly_RW, 2.1*monthly_WW, 2*monthly_BC, 1*monthly_S, 1.76*monthly_FW, 1.5*monthly_O,na.rm=TRUE))
merged_df2 %>% count(monthly_weighted_B)

merged_df2<-merged_df2 %>% mutate(weekly_units_B=case_when( (Alcohol.intake.frequency....Instance.0==""|Alcohol.intake.frequency....Instance.0=="Never"|Alcohol.intake.frequency....Instance.0=="Prefer not to answer") ~ NA_real_,
  (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&(is.na(weekly_RW)|is.na(weekly_WW)|is.na(weekly_BC)|is.na(weekly_S)|is.na(weekly_FW)) ~ NA_real_,
   (Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week") ~ weekly_weighted_B,  
   (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&(is.na(monthly_RW)|is.na(monthly_WW)|is.na(monthly_BC)|is.na(monthly_S)|is.na(monthly_FW)) ~ NA_real_,   
    (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")~ ((monthly_weighted_B)/4.3) 
   ))
merged_df2 %>% count(weekly_units_B)
sum(is.na(merged_df2$weekly_units_B))#argh this is very high 348,870 (includes non-drinkers)
sum(!is.na(merged_df2$weekly_units_B))#153,539 > add roughly 40,000 for the non-drinkers, but this is STILL less than the number of people Topiwala had with full alcohol AND outcome AND covariate data for her obserational analysis...

```
IN TERMS OF THIS ISSUE: investigate why so many less than weekly drinkers weren't asked/didn't answer volume qs [PERHAPS I'VE ACCIDENTALLY DOWNLOADED THE MONTLY VOLUME QS FOR FOLLOW-UP WAVES RATHER THAN BASELINE -> nope can see in the CSV it's all instnce 0)
-let's check if it's a function of recruitment year (not a function of just those with repeat measures having it since the numbers wouldn't even work with so few people at repeat years)
#ANSWER IN END WAS THAT THEY SIMPLY DIDN'T START ASKING NON_WEEKLY DRINKERS ABOUT VOLUME UNTIL SOME TIME INTO THE STUDY 
```{r}
library(tidyverse)
main<-main %>% mutate(r_year=Year.of.birth+Age.at.recruitment)
sum(is.na(main$r_year))
range(main$r_year, na.rm=T) #why are there NAs here?! - only 1 so that's fine; range is 2004-2010

main_04<-main %>% filter(r_year=="2004")
mytable <- table(main_04$Alcohol.intake.frequency....Instance.0,main_04$BC_NA2,exclude=NULL) # all 04 NA on this q
main_05<-main %>% filter(r_year=="2005")
mytable <- table(main_05$Alcohol.intake.frequency....Instance.0,main_05$BC_NA2,exclude=NULL) # all 05 NA on this q
main_06<-main %>% filter(r_year=="2006")
mytable <- table(main_06$Alcohol.intake.frequency....Instance.0,main_06$BC_NA2,exclude=NULL) # all 06 NA on this q except for a single 0
main_07<-main %>% filter(r_year=="2007")
mytable <- table(main_07$Alcohol.intake.frequency....Instance.0,main_07$BC_NA2,exclude=NULL) # all 07 NA on this q 
main_08<-main %>% filter(r_year=="2008")
mytable <- table(main_08$Alcohol.intake.frequency....Instance.0,main_08$BC_NA2,exclude=NULL) # ok! 08 starts to have non-NA qs! although most are still NA
main_09<-main %>% filter(r_year=="2009")
mytable <- table(main_09$Alcohol.intake.frequency....Instance.0,main_09$BC_NA2,exclude=NULL) # now we're getting somewhere - majority of people in 09 have a non-NA answer now
main_10<-main %>% filter(r_year=="2010")
mytable <- table(main_10$Alcohol.intake.frequency....Instance.0,main_10$BC_NA2,exclude=NULL) # vast majority of people in 10 have a non-NA answer
mytable
```

now save again
```{r}
mergedLiu_df3<-merged_df2
saveRDS(mergedLiu_df3, file = "mergedLiu_df3.rds") #done 16.04
```

#18.02 reading this back in
```{r}
mergedLiu_df3<-readRDS("mergedLiu_df3.rds")
```


#UP TO HERE 30.01
#HMMM seems like after adding death and hospital episode data, now my csvs are split in 5... so will have to download the 5 dif files
#updating 28.11 with the new main pheno file (at this stage not going to import the new death and hesin data as hopefully will use first occurences variables instead - otherwise will need these file PLUS gp primary care files)
#10.12 decision is to use just the first occurence variables plus some baseline main pheno file variables to generate T2D (if do want to use the other csvs, redownload as updated on 28.11)
```{r}
#now have to merge sample file with pheno file (keeping order of the sample file!) so that when run MR analyses they are in the same order
#for now just try with the old pheno file (need to regenerate pheno file so suitable for CVD question)
#old_pheno<-read.csv("08.08_participant.csv")
#names(old_pheno)
#head(old_pheno)
#library(tidyverse)
#system('dx download "/28.11_participant_current.csv"')

#now to make T2D + date of onset
#library(lubridate)

#temp<-primary_pheno %>% select(Participant.ID, Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.)
#class(temp$Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.)
primary_pheno<-mergedLiu_df3
primary_pheno<-primary_pheno %>%mutate(T2D_by_firstocc_date=case_when((Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E11.first.reported..non.insulin.dependent.diabetes.mellitus.))
primary_pheno<-primary_pheno %>%mutate(T2D_by_firstocc=case_when((!is.na(T2D_by_firstocc_date))~1, TRUE~0))
#temp<-primary_pheno %>% select(Participant.ID, T2D_by_firstocc_date,T2D_by_firstocc)


  #the below is having trouble parsing certain values
#primary_pheno<-primary_pheno %>%
#mutate(first_rep_date_diab=lubridate::as_date(T2D_by_firstocc_date))
#class(primary_pheno$first_rep_date_diab)

#parse_ymd = function(x){
#  d=lubridate::ymd(x, quiet=TRUE)
#  errors = x[!is.na(x) & is.na(d)]
#  if(length(errors)>0){
#    cli::cli_warn("Failed to parse some dates: {.val {errors}}")
 # }
 # d
#}

#primary_pheno<-primary_pheno %>%
#mutate(first_rep_date_diab=parse_ymd(T2D_by_firstocc_date)) #ahh ok can see the issue is the cells labelled "Code has event date matching participant's date of birth"

#so let's remove those people from the analysis
primary_pheno2<-primary_pheno %>% filter(T2D_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(T2D_by_firstocc_date)) #was only 3 people

#now run!
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_diab=lubridate::as_date(T2D_by_firstocc_date))
#temp<-primary_pheno2 %>% select(Participant.ID, first_rep_date_diab,T2D_by_firstocc)

#getting dates so can remove those with prevalant diabetes at baseline
#update 18.02 -> actually these are the cases we want to keep!/will be the focus of the analyses

primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc_date=case_when((Date.E10.first.reported..insulin.dependent.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E10.first.reported..insulin.dependent.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc=case_when((!is.na(T1D_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(T1D_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(T1D_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_diab1=lubridate::as_date(T1D_by_firstocc_date))

primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc_date=case_when((Date.E12.first.reported..malnutrition.related.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E12.first.reported..malnutrition.related.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc=case_when((!is.na(malDx_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(malDx_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(malDx_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_malDx=lubridate::as_date(malDx_by_firstocc_date))

primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx_date=case_when(( Date.E13.first.reported..other.specified.diabetes.mellitus.=="")~NA_character_, TRUE~ Date.E13.first.reported..other.specified.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx=case_when((!is.na(otherspecDx_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(otherspecDx_date!="Code has event date matching participant's date of birth"|is.na(otherspecDx_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_otherspecDx=lubridate::as_date(otherspecDx_date))

primary_pheno2<-primary_pheno2 %>%mutate(unspecDx_date=case_when((Date.E14.first.reported..unspecified.diabetes.mellitus.=="")~NA_character_, TRUE~Date.E14.first.reported..unspecified.diabetes.mellitus.))
primary_pheno2<-primary_pheno2 %>%mutate(unspecDx=case_when((!is.na(unspecDx_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(unspecDx_date!="Code has event date matching participant's date of birth"|is.na(unspecDx_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_unspecDx=lubridate::as_date(unspecDx_date))

primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc_date=case_when((Date.O24.first.reported..diabetes.mellitus.in.pregnancy.=="")~NA_character_, TRUE~Date.O24.first.reported..diabetes.mellitus.in.pregnancy.))
primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc=case_when((!is.na(gestDx_by_firstocc_date))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>% filter(gestDx_by_firstocc_date!="Code has event date matching participant's date of birth"|is.na(gestDx_by_firstocc_date)) 
primary_pheno2<-primary_pheno2 %>%
mutate(first_rep_date_gestDx=lubridate::as_date(gestDx_by_firstocc_date))

primary_pheno2 %>% count(T2D_by_firstocc)

#14.12 adding date at baseline for purposes of determinnng whether diabetes is already present at baseline > Date.of.attending.assessment.centre...Instance.0
#don't run the below line anymore 18.02
temp<-primary_pheno2 %>% select(Participant.ID, Date.of.attending.assessment.centre...Instance.0,  first_rep_date_diab,T2D_by_firstocc,
                                first_rep_date_diab1,
                                first_rep_date_malDx,
                                first_rep_date_otherspecDx,
                                first_rep_date_unspecDx,
                                first_rep_date_gestDx,
                                Glucose...Instance.0,
                                Glycated.haemoglobin..HbA1c....Instance.0,
                                IGF.1...Instance.0,
                                Source.of.report.of.E10..insulin.dependent.diabetes.mellitus.,
                                Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus.,
                                Source.of.report.of.E12..malnutrition.related.diabetes.mellitus.,
                                Source.of.report.of.E13..other.specified.diabetes.mellitus.,
                                Source.of.report.of.E14..unspecified.diabetes.mellitus.,
                                Source.of.report.of.O24..diabetes.mellitus.in.pregnancy.,
                                Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0,
                          Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0,
                          Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0,
                          Treatment.medication.code...Instance.0)


primary_pheno2<-primary_pheno2 %>%mutate(T1D_by_firstocc=case_when((!is.na(first_rep_date_diab1))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(malDx_by_firstocc=case_when((!is.na(first_rep_date_malDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(otherspecDx_by_firstocc=case_when((!is.na(first_rep_date_otherspecDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(unspecDx_by_firstocc=case_when((!is.na(first_rep_date_unspecDx))~1, TRUE~0))
primary_pheno2<-primary_pheno2 %>%mutate(gestDx_by_firstocc=case_when((!is.na(first_rep_date_gestDx))~1, TRUE~0))

#table_3 <- table(temp$T2D_by_firstocc, temp$T1D_by_firstocc, temp$malDx_by_firstocc, temp$otherspecDx_by_firstocc, #temp$unspecDx_by_firstocc, temp$gestDx_by_firstocc)
#test_table<-ftable(table_3) #hard to read

temp_test<-temp %>% select(T2D_by_firstocc, T1D_by_firstocc, malDx_by_firstocc, otherspecDx_by_firstocc, unspecDx_by_firstocc, gestDx_by_firstocc)
x <- aggregate(list(n=rep(1, nrow(temp_test))), temp_test, length) #ok great this is an excellent solution, can see there (what follows are only those with T2D overlap) are 752 ppl with T1d and T2D recorded; 1 person with both T2d and mal_dx recorded, one person with t2d,t1d AND mal_dx, 164 people with other specified dx and t2d, 17 with other spec and t1d AND t2d, 3658 with unspec diabetes only so we can try to delineate these furhter, >17000 with both unspec and T2D, 3164 with unspec T1dd and T2d, 2 with unsepc, mal_dx AND T2D, 119 with T2D, other and unspec, 70 with T1D, T2D, other and unspec,, 156 with T2D and gest (can ignore), 11 with T2D T1D and gest, 1 with t2d other and gest, 68 with T2D unspec and gest, 34 with T2D T1D unspec and gest, 1 with T2D other unspec and gest

#where an individual is recorded as having more than one kind of diabetes, the one based on hospital records must win-out (no this doesn't make sense as can be diagnosed with more than one kind); write code for this (although for gestational, can have both) -> IMPORTANT,can have both T1D and T2D at the same time

#create a variable to idenityf people with any kind of diabetes at baseline
#first make a variable that gives the earlies of the 6 first rep dates
#then make a variable 0/1 for diabetes at baseline based on whether this above variable is earlier than the baseline date visit
#DON'T INCLUDE GEST_DX
primary_pheno2<-primary_pheno2 %>% mutate(earliest_diab=pmin(first_rep_date_diab,
                                first_rep_date_diab1,
                                first_rep_date_malDx,
                                first_rep_date_otherspecDx,
                                first_rep_date_unspecDx,
                                #first_rep_date_gestDx, 
                                na.rm = TRUE))
sum(is.na(primary_pheno2$earliest_diab))

primary_pheno2<-primary_pheno2 %>% mutate(dX_at_BL=case_when(earliest_diab<=Date.of.attending.assessment.centre...Instance.0 ~ 1, TRUE~0))
#and also one for T2D specifically at BL
primary_pheno2<-primary_pheno2 %>% mutate(T2dX_at_BL=case_when(first_rep_date_diab<=Date.of.attending.assessment.centre...Instance.0 ~ 1, TRUE~0))
#18.02 now want to exclude anyone with diabetes at baseline but whose earliest diabetes (excl gestational) was not T2D, and also exclude anyone who had a T1D diagnosis at any point (including post baseline)
primary_pheno2<-primary_pheno2 %>% mutate(earlistIST2D=case_when(earliest_diab==first_rep_date_diab ~ 1, TRUE~0))
temp <-primary_pheno2 %>% select(earlistIST2D, earliest_diab,first_rep_date_diab, first_rep_date_diab1, first_rep_date_malDx, first_rep_date_otherspecDx,first_rep_date_unspecDx) #GREAT LOOKS GOOD
sum(primary_pheno2$dX_at_BL==1 & primary_pheno2$earlistIST2D==0) #ok so should be 19165 people removed below who have dx at basline by their earliest T2D diagnosis is NOT T2D
primary_pheno3<-primary_pheno2 %>% filter(!(dX_at_BL==1 &earlistIST2D==0)) #yes this matches up!
#now further filter out (ie keep in) anyone with T1D diagnoses at ANY point
primary_pheno3<-primary_pheno3 %>%filter(T1D_by_firstocc==0)


#18.02 no longer run below since not doing Cox
#now exclude those people with any kind of diabetes at baseline (except gestational)
#temp<-temp %>% filter(dX_at_BL==0)
#now remove anyone diagnosed with T1D after baseline (because it's likely that that is simply a misdiagnosis of T2D, including people first diagnosed with T2D and then T1D, because this probably reflects simply an earlier misdiagnosis of T1D)
#temp<-temp %>% filter(T1D_by_firstocc==0)
#temp %>% count(T2D_by_firstocc) #ok so still >20,000 incident cases to work with here



#great -> now refine this variable using self-reported insulin, metaformin,other diabetes druig, hba1c, glucose, non-specific diabetes type reported ->01.01.23 REALISED THAT SELF-reported insulin was only asked of those who reported diabetes, and we are excluding those people anwyay, so this q specifically is useless, but the other drug qs and hba1c/glucose levels can be used to identify people who failed to report on diabetes at baseline but show indications of having it

#diabetes medication use at baseline - ANYONE WITH ONE OF THE FOLLOWING AT BASELINE NEEDS TO BE EXCLUDED
#temp %>% count(Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0) #can see this was asked of 25298 people who self-reported a history of diabetes (diabetes diagnosed by doctor) that wasn't gestational diabetes (dx_at_BL variable counts almost an additional 1,000 people with diabetes who didn't self-report any of the non-gestational diabetes at baseline)
#temp %>% count(Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0) #this was asked of women
#temp %>% count(Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0) #this was asked of men
primary_pheno3 <-primary_pheno3 %>% mutate(insulin_BL=case_when(
  (Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Blood pressure medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Cholesterol lowering medication|Blood pressure medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Cholesterol lowering medication|Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Insulin"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0==
"Insulin|Hormone replacement therapy"|Medication.for.cholesterol..blood.pressure..diabetes..or.take.exogenous.hormones...Instance.0=="Insulin|Oral contraceptive pill or minipill")~1,
(Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0=="Blood pressure medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Cholesterol lowering medication|Blood pressure medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Cholesterol lowering medication|Insulin"|
   Medication.for.cholesterol..blood.pressure.or.diabetes...Instance.0== "Insulin") ~ 2, TRUE~0
                                              ))
primary_pheno3 %>% count(insulin_BL) #690 people report insulin at BL (because have already filtered out everyone with T1D, let's remove these people too)
primary_pheno3 <-primary_pheno3 %>% filter(insulin_BL==0)
#now do a regex on the free-entry medication qs 
#temp %>% count(Treatment.medication.code...Instance.0) #yuck this is awful because includes all combos -> need to run some regex to capture any answer that INCLUDES one of the relevant drugs -> would be much easier to use the variable with the actual codes for the drugs rather than the names but seems I didn't select that varaible from the showcase
#list of drug names: insulin product ; SULFS (should be 10 according to mason - maybe they only included the ones with >0 cases): amaryl ; chlorpropamide ; diabinese (0 count); glimepiride; glipizide product; minodiab; tolazamide; tolbutamide; glibenclamide; tolanase (0 count); glibenese (0 count); diamicron; daonil (0 count); gliclazide      ; MASON'S 'OTHERS': acarbose; glucobay; glucotard  ; MEGLITINIDES: repaglinide; nateglinide; starlix ; GLITAZONES: pioglitazone; rosiglitazone (the fifth one Mason had was a rosig combo pill); avandia; actos
#01.01.23 > NUP TOO HARD, have to go back to showcase and add the coded var to a csv and reimport > HMMMM SO STRANGELY there i only this one variable in showcase (in fact mason page says uses this variable 20003 - but somehow they were able to use codes but I can't see those)

#AHHH ok have to do a regex of this var Treatment.medication.code...Instance.0 to find people who were taking metformin/insulin at baseline -> then use the flow charts in the powerpoint to refine baseline diabetes type among those who reported any diabetes at baseline (NO WE ARE EXCLUDING POEOPLE WITH ANY DX AT BL SO NO POINT); then use hba1c/glucose to catch any additional diabetes cases that weren't reported on -> THERE'S NO WAY TO REFINE THE INCIDENCE CASES WITH EXTRA DATA (except maybe to censor people who develop a non-T2 diabetes diagnosis in follow-up...? - this is what the incidence flow-charts seem to do ie whichever diabetes diagnosis comes first - yep this is basically what I do re censor any non-T2d, but unlike the flow chart, if get T1D diag and THEN T2D diag assume that T1D was a mistake)

#18.02 DON'T RUN BELOW BECAUE WE DON"T WANT TO FILTER OUT PEOPLE with T2D ON diabetes meds at baseline more generally!!!
#regex step (started chaning temp to primary_pheno but didn't actually run)
toMatch <- c("insulin", "amaryl" , "chlorpropamide" , "glimepiride", "glipizide" , "minodiab", "tolazamide", "tolbutamide", "glibenclamide", "diamicron", "gliclazide "  , "acarbose", "glucobay", "glucotard"  , "repaglinide", "nateglinide", "starlix" , "pioglitazone", "rosiglitazone", "avandia", "actos")
primary_pheno4<-primary_pheno3 %>% mutate(anyDmeds_BL =(grepl(paste(toMatch,collapse="|"), 
                        primary_pheno3$Treatment.medication.code...Instance.0 )))
primary_pheno4 %>% count(anyDmeds_BL) #only 33 people (makes sense given we've already filtered out people self-reporting diabetes at bl/records indicate diagnosed with diabetes before bl/taking insulin at bl)
#now filter these people out
temp2<-temp2 %>% filter(anyDmeds_BL==FALSE)


#18.02 AGAIN DON'T RUN BELOW SINCE WE want people with T2D to stay
#final step is to remove those with elevated hba1c/glucose at BL (using Steven code; for incidence eastwood uses the same hba1c threshold and also glucose omore than or equal to 11.1)
temp_test <-temp2%>% filter(Glycated.haemoglobin..HbA1c....Instance.0>=48)
temp2<-temp2 %>% filter (is.na(Glycated.haemoglobin..HbA1c....Instance.0) | Glycated.haemoglobin..HbA1c....Instance.0<48) # wow that removed almost 4,000 people
temp_test<-temp2 %>% filter(Glucose...Instance.0>=11.1) #an additional 587 people
temp2<-temp2 %>% filter (is.na(Glucose...Instance.0) | Glucose...Instance.0<11.1) 

#02.01.23 FANTASTIC - NOW EVERYONE WITH any kind of diabetes at baseline (diagnosed or not; exlcuding gestational) has been removed, and anyone who develops T1D after baseline is also removed 



#do continuous var winsorisation now that all the baseline diabetes cases have been removed
#identify hba1c and IGF variables -> Glycated.haemoglobin..HbA1c....Instance.0 ; IGF.1...Instance.0
#library(tidyverse)
#str_sort(names(primary_pheno))
#primary_pheno %>% count(IGF.1...Instance.0)
#hist(temp2$IGF.1...Instance.0)
#range(primary_pheno$IGF.1...Instance.0,na.rm=T)
sd<-sd(primary_pheno3$IGF.1...Instance.0, na.rm=T)
mean<-mean(primary_pheno3$IGF.1...Instance.0,na.rm=T)
primary_pheno3 <-primary_pheno3 %>% mutate(IGF_BL_winsor=case_when(IGF.1...Instance.0<(mean-3*sd)~(mean-3*sd),
                                                             IGF.1...Instance.0>(mean+3*sd)~(mean+3*sd),
                                                             TRUE~IGF.1...Instance.0))
#hist(temp2$IGF_BL_winsor) #this is now nicely normally distributed after winsorising
#sum(is.na(temp2$IGF_BL_winsor)) #only 35,456 NA
#sum(!is.na(temp2$IGF_BL_winsor)) #466,953

#hist(temp2$Glycated.haemoglobin..HbA1c....Instance.0)
#range(temp2$Glycated.haemoglobin..HbA1c....Instance.0,na.rm=T) #maxis 47.9 now because filtered out anyone above 48
sd<-sd(primary_pheno3$Glycated.haemoglobin..HbA1c....Instance.0, na.rm=T)
mean<-mean(primary_pheno3$Glycated.haemoglobin..HbA1c....Instance.0,na.rm=T)
35+(3.76*3)
35-(3.76*3) #winsorising makes little change to the upper limit, but raises the lower limit quie a bit
primary_pheno3 <-primary_pheno3 %>% mutate(HbA1c_BL_winsor=case_when(Glycated.haemoglobin..HbA1c....Instance.0<(mean-3*sd)~(mean-3*sd),
                                         Glycated.haemoglobin..HbA1c....Instance.0>(mean+3*sd)~(mean+3*sd),
                                                             TRUE~Glycated.haemoglobin..HbA1c....Instance.0))
#hist(primary_pheno$HbA1c_BL_winsor) #hmm maybe not appropriate to winsorise like this as quite a lot of people were more than 3sds above the mean

saveRDS(primary_pheno3, file = "primary_pheno3.rds") #



#01.01 NO THE BELOW DOESN'T MATTER SINCE REMOVING PEOPLE WITH ANNNYYYY diabetes at baseline (except gestational) so no point trying to deliniate further
#trying to classify those with unspecified diabetes (3658 have unspec alone, another 20 have just unsepc and gestational)
#temp_unspec <- temp %>% filter(T2D_by_firstocc==0 & T1D_by_firstocc==0 & malDx_by_firstocc==0, otherspecDx_by_firstocc==0 & unspecDx_by_firstocc==1 )
#temp_unspec %>% count(Source.of.report.of.E14..unspecified.diabetes.mellitus.) #ok so leave the ones that were death register and hospital admissions sources, but for those that are self-report, see if we can use the other variables to delineate further (mediaction use)
#temp_unspec %>% count(Started.insulin.within.one.year.diagnosis.of.diabetes...Instance.0=="Yes") #so 177 with unspecified diabetes at baseline then started insulin within one year... potentially change their dx




#glimpse(primary_pheno)
#system('dx download "/15.11.attempt3_death.csv"')
#death_pheno<-read.csv("15.11.attempt3_death.csv")
#glimpse(death_pheno)
#system('dx download "/15.11.attempt3_death_cause.csv"')
#death_cause_pheno<-read.csv("15.11.attempt3_death_cause.csv")
#glimpse(death_cause_pheno) #hmm ok so each death individual has multiple rows here...
#system('dx download "/15.11.attempt3_hesin.csv"')
#hesin_pheno<-read.csv("15.11.attempt3_hesin.csv")
#glimpse(hesin_pheno) #yikes 3 million rows here 
#system('dx download "/15.11.attempt3_hesin_diag.csv"')
#hesin_diag_pheno<-read.csv("15.11.attempt3_hesin_diag.csv")
#glimpse(hesin_diag_pheno) #15 million rows -> ok so I think what needs to be done is need to make each of these files wide format so that each individual only has a single row
#death_cause_pheno_wide<-death_cause_pheno%>% separate(dnx_death_cause_id, c("dnx_death_cause_id_A","dnx_death_cause_id_B"), sep = "(?<=-[\\d+])*")
#death_cause_pheno_wide<-

#ACTUALLY FORGET THAT -> can see from Steven code that they will figure out diabetes from each of these files first, and ONLY then will they extract the IDs for those individuals and merge with the regular pheno
```


#so when run the actual nlmr next; filter down to Europeans! (DONE); randomly remove one of the related subjects based on kinship (DONE); remove those drinking occasionally who were in one of the first few waves and weren't asked about volume (DONE); first separate the df into 3 sep dfs based on never drinkers, former drinkers, and current drinkers (BL_drinker_status ==0) but ALSO KEEP A COMBINED DF; then, add 1 to each drinking value in combined df and log transform that variable before running G-X in CONTROLS only IN THE COMBINED DF  (i.e. those who are T2dX_at_BL==0), then run G-Y in each of the 3 dfs separately ; age sex genotyping method ("Genotype.measurement.batch") and PCA ("Genetic.principal.components...Array.1" thru 10) need to be included as covariates in both regressions

```{r}
primary_pheno3<-readRDS("primary_pheno3.rds")

#want to see what weekly drinks looks like for occasional drinkers
library(tidyverse)
temp<-primary_pheno3 %>% filter(Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only") #filter to freq occasional only 
temp<-temp %>% select(ID_1, weekly_units_B) #can see that a lot of weekly drinkers end up with a weekly average that's more than 1 drink per week! so next step is to remove occasonal drinkers with NA weekly drinks from the dataset
sum(is.na(temp$weekly_units_B)) #so 67,963/100,000 occasional drinkers are mssing weekly volume -> need to exclude them!
primary_pheno4<-primary_pheno3 %>% mutate(occasionalWOvol=case_when((
  (Alcohol.intake.frequency....Instance.0=="One to three times a month"|Alcohol.intake.frequency....Instance.0=="Special occasions only")&
    is.na(weekly_units_B)
  )~1, TRUE~0))
primary_pheno4<-primary_pheno4 %>% filter(occasionalWOvol==0)

#up to here 18.02 (when reopen, rerun this chunk and then get started on filtering down to europeans etc)

str_sort(names(primary_pheno4))
temp<-primary_pheno4 %>% select(ID_1, Genetic.ethnic.grouping)
temp %>% count(Genetic.ethnic.grouping) #use this one over Ethnic background as this incorporates both genetic and self-identified ethnicity, whereas Ethnic background is self-report only

primary_pheno4<-primary_pheno4 %>% filter(Genetic.ethnic.grouping=="Caucasian") #down to 335948

#now remove one of each of the related individuals
temp<-primary_pheno4 %>% select(ID_1, Genetic.relatedness.exclusions, Genetic.relatedness.factor...Array.0, Genetic.relatedness.IBS0...Array.0, Genetic.relatedness.pairing...Array.0, Genetic.kinship.to.other.participants)
#ARRGGHH I realised I only have array 0, but I need arrays 1-4 to be able to identify all cases of relatedness
#joining on 22.02.23 with additional csv which includes all arrays for the relatedness variables
system('dx download "/22.02_new_cols__participant.csv"')
add_cols<-read.csv("22.02_new_cols__participant.csv")
str_sort(names(add_cols))
#remove the array.0 variables from this so don't overlap with main df
add_cols<-add_cols %>% select(-c(Genetic.relatedness.factor...Array.0,Genetic.relatedness.pairing...Array.0))
add_cols<-add_cols %>% mutate(ID_1=Participant.ID)
add_cols<-add_cols %>% select(-c(Participant.ID))

temp<-primary_pheno4 %>% select(ID_1, ID_2.x, ID_2.y) #all the same
update_pp4<-primary_pheno4 %>% left_join(add_cols,by="ID_1") #should be 335948 rows > excellent! added 12 extra rows
temp<-update_pp4 %>% select(ID_1,  Genetic.relatedness.factor...Array.0,Genetic.relatedness.factor...Array.1,Genetic.relatedness.factor...Array.2,Genetic.relatedness.factor...Array.3,Genetic.relatedness.factor...Array.4,  Genetic.relatedness.pairing...Array.0,Genetic.relatedness.pairing...Array.1,Genetic.relatedness.pairing...Array.2,Genetic.relatedness.pairing...Array.3,Genetic.relatedness.pairing...Array.4, Genetic.kinship.to.other.participants)
temp<-temp %>% filter(Genetic.relatedness.factor...Array.0>.088|Genetic.relatedness.factor...Array.1>.088|Genetic.relatedness.factor...Array.2>.088|Genetic.relatedness.factor...Array.3>.088|Genetic.relatedness.factor...Array.4>.088) #so 5,352 people have at least one substantially related person to them in the cohort
#hmm the complicated part now is the people with more than one relation


saveRDS(update_pp4, file = "update_pp4.rds") #done 23.02
update_pp4<-readRDS("update_pp4.rds")

#so the way to deal with relatedness is to use the UKBtools package function, which requires a vector of the IDs you are interested in (can supply from update_pp4) and also a df with a row for each relationship pairing which can be obtained directly from UKB
system('dx download "/Bulk/Genotype Results/Genotype calls/ukb_rel.dat"')
data <- read.delim("ukb_rel.dat", header = TRUE, sep=" ") 
install.packages("ukbtools")
library(ukbtools)
names(update_pp4)
ukb_with_data<-update_pp4$ID_1 #to get the vector of IDs
remove_IDs<-ukb_gen_samples_to_remove(data, ukb_with_data, cutoff = 0.0884)  
#ok need to save this vector 
write.csv(remove_IDs,file="remove_IDs.csv",row.names=F)

#hmm so there are 20,284 people to remove, despite me only finding 5352 people with a significantly related other person
#where to find disconnect
vector2<-temp$ID_1
diffs<-setdiff(remove_IDs,vector2)
temp2<-temp %>% filter(ID_1=="1527295") #so this person has no relationships
data2<-data %>% filter(ID1=="1527295"|ID2=="1527295") #ok so there are 5 people they are related to in the official relationship data - do I still have these people in temp?
temptemp<-temp %>% filter(ID_1=="4973330"|ID_1=="1199284"|ID_1=="3640301"|ID_1=="3051580"|ID_1=="4756198") #we do! so so strange -> so why are they not related according to the relationship pairing/factor vars, but are related according to the data UKB gives out... can  see that in the temptemp file the kinship column DOES say that they were found to be related to at least one other individuals, so seems just like missing data for coeffieincts/pairings -> will therefore use the list of IDs generated here
###AHHHH FIGURED IT OUT -> my pairing and relatedness vars come from the interim release (only 150,000 people with genotyping at that point), so a lot of people simply have NAs for those vars because they wren't even genotyped by the time of the interim release

#now filter down the dataset by removing these people
'%notin%' <- Negate('%in%')
update_pp5<-update_pp4 %>% filter(ID_1 %notin% remove_IDs) #worked!
str_sort(names(update_pp5))
saveRDS(update_pp5, file = "update_pp5.rds") #done 02.03
update_pp5<-readRDS("update_pp5.rds")

```

04.03 - now split into 3 dfs (plus keep original)
```{r}
#remove those for whom drinking status is NA
#library(tidyverse)
update_pp5 <- update_pp5 %>% filter(!(is.na(BL_drinker_status)))
#remove those for whom drinks per week is NA but are a current drinker
update_pp5<-update_pp5 %>% filter(!(BL_drinker_status=="Current"&is.na(weekly_units_B)))
#now further remove those who are more than weekly drinkers but report 0 drinks per week
update_pp5 <- update_pp5 %>% filter(!
                                      ((Alcohol.intake.frequency....Instance.0=="Daily or almost daily"|Alcohol.intake.frequency....Instance.0=="Once or twice a week"|Alcohol.intake.frequency....Instance.0=="Three or four times a week")&weekly_units_B==0)
)


sum(is.na(update_pp5$T2dX_at_BL)) #good, everyone has this variable
df_LA<-update_pp5 %>% filter(BL_drinker_status=="Never")
df_CA<-update_pp5 %>% filter(BL_drinker_status=="Former")
df_DR<-update_pp5 %>% filter(BL_drinker_status=="Current")

nrow(df_CA)+nrow(df_LA)+nrow(df_DR) #adds up
update_pp5 %>% count(weekly_units_B) #still quite a few people on 0 drinks per week; let's check in the current drinker group
df_DR %>% count(weekly_units_B) #hmm yes they're all in there (but all are less than weekly drinkers)
df_DR %>% filter(weekly_units_B==0) %>% count(Alcohol.intake.frequency....Instance.0) #almost all are special occasions only, which makes sense if answered 0 drinks per month on average
df_LA %>% filter(weekly_units_B==0) #good, none
df_CA %>% filter(weekly_units_B==0) #good, none
```


```{r}
#now need to sub in 0 for NA in the combined df for weekly units, then do the log transformation
#so I think what needs to happen is that I calculate the gx in the overall combined df with controlsonly set to TRUE and family==binomial and strata_method set to ranked AND THEN split into 3 separate dfs 
#hmm actually can't split afterwards, because the strata will be different...
#so can do this in the full df, and also in the current drinker only df (or at least without former drinkers), but not sure how to do it in the nondrinker dfs since the G-X estimates will all be 0... > looks like Topiwala actually only did this sens analysis in a linear MR, but still not sure how that would work in non-drinkres > AND I note that Biddinger actually only did a sensitivity analysis by excluding abstainers, not looking at them separately 

#for now let's practice in the full dataset


update_pp6<-update_pp5 %>% mutate(weekly_units_B_R=case_when(is.na(weekly_units_B) ~ 0, TRUE~weekly_units_B))
#visualise skew
#range(update_pp5$weekly_units_B,na.rm=T)
#sum(update_pp5$weekly_units_B>300,na.rm=T) #remove the 9 people with more than 300 standard drinks per week
update_pp6<-update_pp6 %>% filter(weekly_units_B_R<=300)

#CONVERT T2D to factor
class(update_pp6$T2dX_at_BL) #hmm maybe need to convert to factor
update_pp6 %>% count(T2dX_at_BL)
update_pp6<-update_pp6 %>% mutate(T2dX_at_BL=as.factor((T2dX_at_BL)))

#17.03 save
saveRDS(update_pp6, file = "update_pp6.rds")
update_pp6<-readRDS("update_pp6.rds")


#basic visualisation of X-Y

ggplot(update_pp6,aes(x=weekly_units_B_R,y=HbA1c_BL_winsor))+ geom_point() + 
  geom_smooth(method='lm') #ok so this does show a negative linear result

ggplot(update_pp6,aes(x=weekly_units_B_R,y=IGF_BL_winsor))+ geom_point() + 
  geom_smooth(method='lm') #also shows a negative linear relationship > but might not be like that if added a polynomila -> IGF is a weird one unclear what it's relationship with diabetes is
#let's see what realtionship betwen IGF and T2D is




mod1<- glm(update_pp6$T2dX_at_BL~update_pp6$IGF_BL_winsor, family="binomial")
summary(mod1) # a small but sig negative relationship (increasing IGF leads to lower risk for T2dX)
mod2<- glm(update_pp6$T2dX_at_BL~update_pp6$weekly_units_B_R, family="binomial")
summary(mod2) #virtually no relationship here, but doesn't allow possibility of non-linear
logistic_model <- glm(update_pp6$T2dX_at_BL~update_pp6$weekly_units_B_R, family="binomial")
update_pp6<-update_pp6 %>% mutate(T2dX_at_BL=as.numeric(as.character(T2dX_at_BL)))
class(update_pp6$T2dX_at_BL)
ggplot(update_pp6, aes(x=weekly_units_B_R, y=T2dX_at_BL)) + geom_point() +
      stat_smooth(method="glm", color="green", se=FALSE,
                method.args = list(family=binomial))

#now try with gams
library(mgcv)
#install.packages("tidymv")
library(tidymv)
gam_binomial<-gam(T2dX_at_BL~s(weekly_units_B_R),family="binomial",data=update_pp6)
plot(gam_binomial,trans=exp) #hmm the CIs get too high after 250 drinks per week and make it too hard to read
update_gam<-update_pp6 %>% dplyr::filter(weekly_units_B_R<=50)
gam_binomial<-gam(T2dX_at_BL~s(weekly_units_B_R),family="binomial",data=update_gam)
plot(gam_binomial,trans=exp) #hmm so now we need to get rid of the CIs, and also get Y axis plotting on a log scale (let's try log10)
summary(gam_binomial)
options(scipen=999)
#AHHH OK Can see here that there are 3 ways to transform the scale, and exponentiating is one (so when then scale the y axis it cancels out?)
#https://ggplot2.tidyverse.org/reference/coord_trans.html
#so instead try
###AHHHHH NOW I REALISE THIS ISSUE also is that plot_smooths plots only the smooth term, no residuals included etc
tidymv::plot_smooths(model=gam_binomial,series=weekly_units_B_R,trans=exp) +
  coord_trans(y = "exp")
#so use this technique https://stefanocoretta.github.io/tidymv/articles/plot-smooths.html
pred<-get_gam_predictions(gam_binomial,weekly_units_B_R)
pred %>% ggplot(aes(weekly_units_B_R, T2dX_at_BL)) +
  geom_ribbon(aes(ymin = CI_lower, ymax = CI_upper), alpha = 0.3) +
  geom_line() #ohhh bugger this doesn't work either because still only plots the smooth rather than the whole graph
#AHHH my mistake was using get_gam_predictions (which gets predictions from a specific smooth) instead of predict_gam which uses the whole model: https://cran.r-project.org/web/packages/tidymv/vignettes/predict-gam.html
pred<-predict_gam(gam_binomial)
pred %>% ggplot(aes(weekly_units_B_R, exp(fit))) + 
  geom_line() + 
  geom_smooth_ci()+
  coord_trans(y = "exp") #hhhhmmmmm ok so this thing now only does what we want in that it only transforms the y axis scale rather than the numbres on it, but the estimates are still really different to the mgcv inbuilt plotting function

#24.04 too hard to plot the above, and also doesn't really even make sense too given it's cross-sectional only
#so just do hba1c for now
#need to include covariates
library(mgcv)
#install.packages("tidymv")
library(tidymv)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
gam_binomial<-gam(HbA1c_BL_winsor~s(weekly_units_B_R)+ Sex_F+ Age.at.recruitment,family="gaussian",data=update_pp679)
plot(gam_binomial) #hmm not sure how to set reference to 0

```

```{r}
ggplot(update_pp6, aes(x=weekly_units_B_R)) + 
  geom_density() #wow this looks silly because just so many more 0s than anything else
update_pp6 %>% filter(weekly_units_B_R>0) %>% ggplot(aes(x=weekly_units_B_R))+geom_density() #still very skewed even without the 0s
update_pp6<-update_pp6 %>% mutate(weekly_units_B_R_PLUS=weekly_units_B_R+1)
ggplot(update_pp6, aes(x=weekly_units_B_R_PLUS)) + 
  geom_density()
range(update_pp6$weekly_units_B_R_PLUS)
update_pp6<-update_pp6 %>% mutate(weekly_units_B_R_PLUS_T=log(weekly_units_B_R_PLUS))
range(update_pp6$weekly_units_B_R_PLUS_T)
ggplot(update_pp6, aes(x=weekly_units_B_R_PLUS_T)) + 
  geom_density() #still weird because of the zeros, but a lot better 

#12.03 G X scatterplot for Haodong (filter to those wih less than 250 units per week for clarity)
update_pp6<-update_pp6 %>% filter(weekly_units_B_R<=250)
df_DR<-df_DR %>% filter(weekly_units_B_R<=250)

ggplot(update_pp6,aes(y=weekly_units_B_R,x=GRS))+ geom_point() + 
  geom_smooth(method='lm') #untransformed, all people
ggplot(update_pp6,aes(y=weekly_units_B_R_PLUS_T,x=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #2.	Drinkers + non-drinkers, log-transformed (drinks per week +1)
ggplot(df_DR,aes(y=weekly_units_B_R,x=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #3.	Drinkers only, standard drinks pre week
ggplot(df_DR,aes(x=weekly_units_B_R_PLUS_T,y=GRS))+ geom_point()+ 
  geom_smooth(method='lm') #4. drinkers only, long transformed drinks per week + 1
temp<-update_pp6 %>% select(weekly_units_B, GRS)
range(temp$GRS)
temp2<-head(update_pp6)


devtools::install_github("amymariemason/SUMnlmr")
#have to convert factor covariates to dummies
library(SUMnlmr)
#testing
test_data<-create_ind_data(N=10000, beta2=2, beta1=1)
test_data$centre<- as.factor(rbinom(nrow(test_data),4, 0.5))
head(test_data)
dummies<- model.matrix(~centre,data=test_data)[,2:5]

#actual dummies 
str_sort(names(update_pp6))
sum(is.na(update_pp6$Sex))
update_pp6 %>% count(Sex)
#####
#WHENEVER REREAD UPDATE_PP6, need to run code below this, and also replace GRS/GRS2 depending on which want to use
#####
#library(tidyverse)
update_pp6<-update_pp6 %>% dplyr::mutate(Sex_F=as.factor(Sex))
update_pp6 %>% count(Sex_F)
dummies_2<-model.matrix(~Sex, data=update_pp6)[,2]  #this doesn't actually make a matrix..., but wonder if it's close enough for purposes of binding later???
  update_pp6 %>% select(Genetic.principal.components...Array.1) %>% head() #this is continuous
  class(update_pp6$Genotype.measurement.batch)
  update_pp6 %>% count(Genotype.measurement.batch) #need to reduce this down to affymetrix vs UKBiLEVEAX
  sum(is.na(update_pp6$Genotype.measurement.batch)) # good 0, everyone has
  update_pp6 <-update_pp6 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  update_pp6 %>% count(array_type) #excellent
  dummies_3<-model.matrix(~array_type, data=update_pp6)[,2] 
  head(dummies_2)
  class(dummies_2)
  head(dummies_3)
  #alternative code didn't use - can make separate matrices of everything here, and form into a single matrix here before feeding into the nlmr code below
  dummies_4<-matrix(update_pp6$Age.at.recruitment)
  class(dummies_4)
  head(dummies_4)
  dummies_2_2<-matrix(dummies_2,ncol=1)
  dummies_3_2<-matrix(dummies_3,ncol=1)
#ACTUALLY, sum_Nlmr wil automatically convert these two variable successfully for me > just says attempting to convert and you say y (because it seems to be doing it correctly) -> ahh but when combine with all variables, becomes too large! instead need to convert the factors to matrices first/dummy code
 
  #note that matrices can only contain data of same type, which is the reaon for the dummy coding above, ok this seems to have worked!
  #updating to use untransformed drinks per week var
  library(SUMnlmr)
  update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  dummies_2<-model.matrix(~Sex, data=update_pp679 )[,2] 
  dummies_3<-model.matrix(~array_type, data=update_pp679 )[,2] 
  
summ_covar_FULL_T2D<-create_nlmr_summary(y = update_pp679$T2dX_at_BL,
                                 x = update_pp679$weekly_units_B_R,
                                 g = update_pp679$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(update_pp679$Age.at.recruitment, update_pp679$Genetic.principal.components...Array.1,update_pp679$Genetic.principal.components...Array.2,update_pp679$Genetic.principal.components...Array.3,update_pp679$Genetic.principal.components...Array.4,update_pp679$Genetic.principal.components...Array.5,update_pp679$Genetic.principal.components...Array.6,update_pp679$Genetic.principal.components...Array.7,update_pp679$Genetic.principal.components...Array.8,update_pp679$Genetic.principal.components...Array.9,update_pp679$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "binomial",
                                 q = 10, strata_method="ranked", controlsonly = TRUE)

model_FULL_T2D<- with(summ_covar_FULL_T2D$summary, frac_poly_summ_mr(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  family="binomial",
                  fig=TRUE)
)
summary(model_FULL_T2D)
model_FULL_T2D <-with(summ_covar_FULL_T2D$summary, piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="binomial",
                  ci_fig="ribbon")
)
summary(model_FULL_T2D)

#now re-dpoing above with current drinkers AND NEVER DRINKERS only
df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current"|BL_drinker_status=="Never")
dummies_2<-model.matrix(~Sex, data=df_DR)[,2] 
  dummies_3<-model.matrix(~array_type, data=df_DR)[,2] 
  summ_covar_DR_T2D<-create_nlmr_summary(y = df_DR$T2dX_at_BL,
                                 x = df_DR$weekly_units_B_R,
                                 g = df_DR$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(df_DR$Age.at.recruitment, df_DR$Genetic.principal.components...Array.1,df_DR$Genetic.principal.components...Array.2,df_DR$Genetic.principal.components...Array.3,df_DR$Genetic.principal.components...Array.4,df_DR$Genetic.principal.components...Array.5,df_DR$Genetic.principal.components...Array.6,df_DR$Genetic.principal.components...Array.7,df_DR$Genetic.principal.components...Array.8,df_DR$Genetic.principal.components...Array.9,df_DR$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "binomial",
                                 q = 10, strata_method="ranked", controlsonly = TRUE)
  model_DR_T2D<- with(summ_covar_DR_T2D$summary, frac_poly_summ_mr(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  family="binomial",
                  fig=TRUE)
)
summary(model_DR_T2D)
model_DR_T2D <-with(summ_covar_DR_T2D$summary, piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="binomial",
                  ci_fig="ribbon")
)
summary(model_DR_T2D)

#09.05 Amy comment -> redo above with drinkers only

df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current")
#then re-run above lines

```



#now repeat above for our two continuous measures
#HbA1c_BL_winsor
```{r}
library(tidyverse)
sum(is.na(update_pp679$HbA1c_BL_winsor))
#need to remove everyone who is NA for that var 
#update_pp679 %>% count(Sex)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
  full_HbA1c<-update_pp679 %>% filter(!is.na(HbA1c_BL_winsor))
  #women only
  full_HbA1c_F<-full_HbA1c %>% filter(Sex=="Female")
  #men only
   full_HbA1c_M<-full_HbA1c %>% filter(Sex=="Male")
  

dummies_2<-model.matrix(~Sex, data=full_HbA1c)[,2] 
  dummies_3<-model.matrix(~array_type, data=full_HbA1c)[,2] 
  

summ_covar_FULL_HB<-create_nlmr_summary(y = full_HbA1c$HbA1c_BL_winsor,
                                 x = full_HbA1c$weekly_units_B_R,
                                 g = full_HbA1c$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(full_HbA1c$Age.at.recruitment, full_HbA1c$Genetic.principal.components...Array.1,full_HbA1c$Genetic.principal.components...Array.2,full_HbA1c$Genetic.principal.components...Array.3,full_HbA1c$Genetic.principal.components...Array.4,full_HbA1c$Genetic.principal.components...Array.5,full_HbA1c$Genetic.principal.components...Array.6,full_HbA1c$Genetic.principal.components...Array.7,full_HbA1c$Genetic.principal.components...Array.8,full_HbA1c$Genetic.principal.components...Array.9,full_HbA1c$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)
#MUST REMEMBER TO LOAD METAFOR LIBRARY BEFORE RUN MY VERSION OF THE FUNCTION!
#rather than having to remake function, simply override pref_y below
#also need to add ref values based on mean of lowest category for the fp (1.33), and min (0) for the piecewise
model_FULL_HB<- with(summ_covar_FULL_HB$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  ref=1.33,
                  pref_y = "Relative HbA1C, mmol/mol",
                  family="gaussian",
                  fig=TRUE)
)
summary(model_FULL_HB) 
sum_test<-summary(model_FULL_HB) 
xvals<-model_FULL_HB[["figure"]][["data"]][["x"]]
yvals<-model_FULL_HB[["figure"]][["data"]][["yest"]]
uci<-model_FULL_HB[["figure"]][["data"]][["uci"]]
xyvals<-data.frame(xvals,yvals,uci) 
#for nadir index
which.min(xyvals$yvals)
xyvals[8539,]

model_FULL_HB <-with(summ_covar_FULL_HB$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  family="gaussian",
                      pref_y = "Relative HbA1C, mmol/mol",
                  ci_fig="ribbon")
)
summary(model_FULL_HB)

#now re-dpoing above with current drinkers AND NEVER DRINKERS only
DR_HbA1c<-full_HbA1c %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
#15.05 doing as well for current drinkers only
DR_HbA1c<-full_HbA1c %>% filter(BL_drinker_status=="Current")

dummies_2<-model.matrix(~Sex, data=DR_HbA1c)[,2] 
  dummies_3<-model.matrix(~array_type, data=DR_HbA1c)[,2] 

  summ_covar_DR_HB<-create_nlmr_summary(y = DR_HbA1c$HbA1c_BL_winsor,
                                 x = DR_HbA1c$weekly_units_B_R,
                                 g = DR_HbA1c$GRS_79,
                               covar=cbind(dummies_2,dummies_3,matrix(data=c(DR_HbA1c$Age.at.recruitment, DR_HbA1c$Genetic.principal.components...Array.1,DR_HbA1c$Genetic.principal.components...Array.2,DR_HbA1c$Genetic.principal.components...Array.3,DR_HbA1c$Genetic.principal.components...Array.4,DR_HbA1c$Genetic.principal.components...Array.5,DR_HbA1c$Genetic.principal.components...Array.6,DR_HbA1c$Genetic.principal.components...Array.7,DR_HbA1c$Genetic.principal.components...Array.8,DR_HbA1c$Genetic.principal.components...Array.9,DR_HbA1c$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)
  #rather than having to remake function, simply override pref_y below
  model_DR_HB<- with(summ_covar_DR_HB$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  xmean=xmean,
                  ref=2.85,  #ref=2.85 when current drinkers only
                  family="gaussian",
                   pref_y = "Relative HbA1C, mmol/mol",
                  fig=TRUE)
)
summary(model_DR_HB)


model_DR_HB <-with(summ_covar_DR_HB$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=.47,
                  family="gaussian",
                   pref_y = "Relative HbA1C, mmol/mol",
                  ci_fig="ribbon")
)
summary(model_DR_HB)



#24.04 doing the hba1c analysis stratified by sex
#dummies_2<-model.matrix(~Sex, data=full_HbA1c)[,2] 
library(SUMnlmr)
  dummies_3<-model.matrix(~array_type, data=full_HbA1c_F)[,2] 
  
summ_covar_FULL_HB<-create_nlmr_summary(y = full_HbA1c_F$HbA1c_BL_winsor,
                                 x = full_HbA1c_F$weekly_units_B_R,
                                 g = full_HbA1c_F$GRS_79,
                               covar=cbind(dummies_3,matrix(data=c(full_HbA1c_F$Age.at.recruitment, full_HbA1c_F$Genetic.principal.components...Array.1,full_HbA1c_F$Genetic.principal.components...Array.2,full_HbA1c_F$Genetic.principal.components...Array.3,full_HbA1c_F$Genetic.principal.components...Array.4,full_HbA1c_F$Genetic.principal.components...Array.5,full_HbA1c_F$Genetic.principal.components...Array.6,full_HbA1c_F$Genetic.principal.components...Array.7,full_HbA1c_F$Genetic.principal.components...Array.8,full_HbA1c_F$Genetic.principal.components...Array.9,full_HbA1c_F$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "gaussian",
                                 q = 10, strata_method="ranked", controlsonly = FALSE)


#ref should be .755 for women; 2.63 for men 
model_FULL_HB<- with(summ_covar_FULL_HB$summary, frac_poly_summ_mrRV(bx=bx, #can see the problem occurs here -> powers are 1 and 1
                  by=by, 
                  bxse=bxse, 
                  byse=byse, 
                  ref=.755,
                  xmean=xmean,
                  family="gaussian",
                  pref_y = "Relative HbA1C, mmol/mol",
                  fig=TRUE)
) 

sumMO<- summary(model_FULL_HB) #+ scale_x_continuous(breaks=seq(0,60,5))
max(model_FULL_HB[["figure"]][["data"]][["x"]]) #ahh ok can see here for female that the max x for the figure is 40.53 -> not sure why it only generated up to here -> ahh ok can see that what's happened is it takes the xmean from highest stratum
sumMO[["figure"]]+ scale_x_continuous(breaks=seq(0,60,5))
#hmm something's going wrong when try to apply my fp function above -> telling me the powers are 1 and 1 (X1 and X1.1) -> same for both female and male version
#hmm doing same thing when use the original frac_poly function too -> GOING TO LEAVE THIS FOR NOW AND HOPE IT FIXES BY THE TIME GET BACK TO IT
#update 17.05 -> is now working for males only (now matching original stats)! but same prob for females
```

#now repeat all the above but using residual method instead (wait to hear from Amy if appropriate); I think next step is to plot drinks per week against GRS just to make sure I've got it the right way, also drinks per week against the three outcomes to see basic observational results
#NO > can see from the G-X betas now that they change enormously over strata, s can't use residual method

#now try one-sample MR (use ivreg code)
https://cnsgenomics.com/data/teaching/CNSG/20160706_MR_Brion/2016_CNSG_MR_Tutorial.pdf
#updating 2SLS 20.03 to include covariates
#do 2SLS using ivtools package; IVW using Haodong method at bottom
```{r}
library(tidyverse)
update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))


install.packages("ivreg")
library(ivreg)
#library(tidyverse)
df_LA<-update_pp679 %>% filter(BL_drinker_status=="Never")
df_CA<-update_pp679 %>% filter(BL_drinker_status=="Former")
df_DR<-update_pp679 %>% filter(BL_drinker_status=="Current")
df_LA_DR<-update_pp679 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")

#ivreg is having problems for cateforical outcome, soe start with continuous
sum(is.na(update_pp679$T2dX_at_BL))
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=update_pp679) ) #ok so this is for full sample (small but significant linear relationship)
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_DR) ) #for drinkers, again a small but sig neg linear relationship
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_CA) ) #as predicted, doesn't work!
summary(ivreg(IGF_BL_winsor ~ weekly_units_B_R | GRS, data=df_LA) ) #as predicted, doesn't work!

#need to run these ones below
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=update_pp679) ) #ok so this is for full sample (small but significant NEGATIVE linear relationship) - aligns with the plos one paper but much much smaller effect
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_DR) ) #basically same as above (-.03)
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_CA) ) #as predicted, doesn't work!
summary(ivreg(HbA1c_BL_winsor ~ weekly_units_B_R | GRS, data=df_LA) ) #as predicted, doesn't work!

#AHH OK IVREG CAN'T DO categorical outcomes (in fact, it's not called 2SLS with binary outcome - instead it's like 2 stage something else) -> but https://academic.oup.com/ije/article/42/4/1134/657927 says to use the tsls function from sem package for two stage least squares
install.packages("sem")
library(sem)
summary(tsls(HbA1c_BL_winsor~weekly_units_B_R, ~ GRS, data=update_pp679)) #HMMMM STILL NOT WORKING FOR A logistic regression
#but did work when tried HbA1C instead (same estimate as when use ivreg above)
#ahh ok can use the new ivtools package: https://www.degruyter.com/document/doi/10.1515/em-2018-0024/html
install.packages("ivtools")
library(tidyverse)
library(ivtools)
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) #so can caluclate G-X in controls only
 fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX not much there at all really
  confint(fitIV_ts)
  
  ###REPLACE T2DX with HBA1C as needed (and swap out binomial and gaussian, and for the fitX.LZ, data should be df_noD for T2D but regular update_pp679 for HbA1c)
  #version including covariates
   fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS_79+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  #for hba1c it's -0.0341956; CIs: -0.0417091676 -0.026681996
  #for T2D it's 0.001348; CIs: -0.005400848  0.008096246 > need to exponentiate these
  TSLS_main_T2D<-exp(c(0.001111 , -0.005760410,  0.007982028))
TSLS_main_HbA1C<-c(-0.018520,-0.0285250004, -0.008514135)


  

  #and excluding ex-drinkers (not really that appropriate since the 2 sample can't do that)
 df_LA_DR_noD<-df_noD %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=df_LA_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=df_LA_DR) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA_DR)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
    #LIU SENSITIVITY version including covariates
   fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS2+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX 
  confint(fitIV_ts) 

 df_LA_DR_noD<-update_pp679 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=df_LA_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS2+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=df_LA_DR_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA_DR)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  
  #let's see what happens when do separately in drinkers, non-drinkers etc
  #first: never drinkers -> DOESN'T WORK! as predicted
  df_LA_noD<-df_noD %>% filter(BL_drinker_status=="Never")
   fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=df_LA) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_LA_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  #now, drinkers -> this does work (makes sense), again, a non-sig relationship when restrict to linear
  df_DR_noD<-df_noD %>% filter(BL_drinker_status=="Current")
   fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=df_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_DR_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  #now HbA1c
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R,data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###as when using ivreg package, the estimate is -.036 (very significant)
  confint(fitIV_ts)
 
#using Haodong's code (from MendelianRandomization package)
#see if can repllicate PlosOne paper results for HBA1C and T2D (using both IVW and 2SLS methods); use Haodong IVW code/MendelianRandomization package R
#theirs is on the WHOLE sample
#I think Haodong's approahc to use GRS in IVW instead of idnidivusla variants is acceptable
#-> NO ACTUALLY I THINK NEED TO ENTER THEM SEPARATELY (but see notes that it's ok for 2SLS/other 2 stage)
#do fitGX in controls only >UPDATE HAODONG SAYS IVW/2SLS basically interchangeable here, can just use GRS
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) 
update_pp679 %>% count(T2dX_at_BL)

summary(fitGX)
fitGX<-lm(    df_noD$weekly_units_B_R~  df_noD$GRS_79 +df_noD$Sex_F+df_noD$array_type+ df_noD$Age.at.recruitment +  df_noD$Genetic.principal.components...Array.1+df_noD$Genetic.principal.components...Array.2+df_noD$Genetic.principal.components...Array.3+df_noD$Genetic.principal.components...Array.4+df_noD$Genetic.principal.components...Array.5+df_noD$Genetic.principal.components...Array.6+df_noD$Genetic.principal.components...Array.7+df_noD$Genetic.principal.components...Array.8+df_noD$Genetic.principal.components...Array.9+df_noD$Genetic.principal.components...Array.10);bGX<-summary(fitGX)$coef[2,1] ;seGX<- summary(fitGX)$coef[2,2] ; bx<-as.numeric( bGX  ); bxse<-as.numeric(  seGX)
summary(fitGY)
fitGY<-glm( update_pp679$T2dX_at_BL~  update_pp679$GRS +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10,family="binomial" );bGY<-summary(fitGY)$coef[2,1] ;seGY<-summary(fitGY)$coef[2,2] ; by<-as.numeric( bGY  ); byse<-as.numeric(  seGY)
#hmm so the above shows a neg relationship which is why the IVW estimates aren't as expected
# below I'm going to run the above in higher strata and see what happens

library(MendelianRandomization)
IVW_res<-mr_ivw(mr_input(bx, bxse, by, byse))
#now redoing for hba1c, then run above line again
fitGX<-lm(    update_pp679$weekly_units_B_R~  update_pp679$GRS_79 +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10);bGX<-summary(fitGX)$coef[2,1] ;seGX<- summary(fitGX)$coef[2,2] ; bx<-as.numeric( bGX  ); bxse<-as.numeric(  seGX)
fitGY<-lm( update_pp679$HbA1c_BL_winsor~  update_pp679$GRS +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10 );bGY<-summary(fitGY)$coef[2,1];seGY<-summary(fitGY)$coef[2,2] ; by<-as.numeric( bGY  ); byse<-as.numeric(  seGY) #differs only slightly from the 2SLS method

IVW_main_T2D<-exp(c(IVW_res@Estimate, IVW_res@CILower, IVW_res@CIUpper))
IVW_main_HbA1C<-c(IVW_res@Estimate, IVW_res@CILower, IVW_res@CIUpper)

#10.05 SNP-based one sample linear -> NO EGGER!
#update 19.05 so that G-X is only calculated in controls!
#update 26.05 to include covariates! (remember the covariates have already been included in the 2 sample, but need to do this ourselves for one sample)
str_sort(names(update_pp679))
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) 
#ok first make MR input object
colnames<-grep("^VV[0-9]+",names(update_pp679))
my_lms <- lapply(df_noD[colnames], function(x) lm(df_noD$weekly_units_B_R ~ x +df_noD$Sex_F+df_noD$array_type+ df_noD$Age.at.recruitment +  df_noD$Genetic.principal.components...Array.1+df_noD$Genetic.principal.components...Array.2+df_noD$Genetic.principal.components...Array.3+df_noD$Genetic.principal.components...Array.4+df_noD$Genetic.principal.components...Array.5+df_noD$Genetic.principal.components...Array.6+df_noD$Genetic.principal.components...Array.7+df_noD$Genetic.principal.components...Array.8+df_noD$Genetic.principal.components...Array.9+df_noD$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#26.05 must remove my_lms from environment now as it's huge! -> DOESN'T WORK WELL ENOUGH! instead use a larget memory instance of the RAP (used 32GB to be safe)
rm(my_lms)
#now repeat for b-y (but not just in controls!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679[colnames], function(x) glm(update_pp679$T2dX_at_BL ~ x +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
rm(my_lms2)
#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")
library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_T2D_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
#presso_T2D_results<-c( "MR PRESSO",  res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#ahh ok presso detected no outliers, tehrefore did not conduct outlier corrected estimate test (still true when changed g-x to calc in controls only; in fact then the global test wasn't sig p=.58) https://github.com/rondolab/MR-PRESSO/issues/9 -> 26.05 when add covariates, the global test is sig but no significant outliers were detectect therefore no outlier corrected estimates

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS)
res2_T2D<-data.frame(res2)
class(res2_T2D$b)
res2_T2D[] <- lapply(res2_T2D, unlist)
res2_T2D<-generate_odds_ratios(res2_T2D) #ExCELLENT!!! all worked
```


```{r}
#now repeat above but split by sex (won't be able to join on to two sample results since can't split those by sex); but will need to repeat the GRS-based TSLS estimate split by sex -> START HERE 18.05
library(tidyverse)

update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
update_pp679_F<-update_pp679 %>% filter(Sex_F=="Female")
update_pp679_M<-update_pp679 %>% filter(Sex_F=="Male")

#19.05 fix below so only calculating G-X in controls
df_noD_F<-update_pp679_F %>% filter(T2dX_at_BL==0)
df_noD_M<-update_pp679_M %>% filter(T2dX_at_BL==0)

#add covariates ExCLUDING SEX
#sub in _F and _M
colnames<-grep("^VV[0-9]+",names(update_pp679_M))
my_lms <- lapply(df_noD_M[colnames], function(x) lm(df_noD_M$weekly_units_B_R ~ x+df_noD_M$array_type+ df_noD_M$Age.at.recruitment +  df_noD_M$Genetic.principal.components...Array.1+df_noD_M$Genetic.principal.components...Array.2+df_noD_M$Genetic.principal.components...Array.3+df_noD_M$Genetic.principal.components...Array.4+df_noD_M$Genetic.principal.components...Array.5+df_noD_M$Genetic.principal.components...Array.6+df_noD_M$Genetic.principal.components...Array.7+df_noD_M$Genetic.principal.components...Array.8+df_noD_M$Genetic.principal.components...Array.9+df_noD_M$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
rm(my_lms)
gc()
#now repeat for b-y (not just in controls though!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679_M[colnames], function(x) glm(update_pp679_M$T2dX_at_BL ~ x +update_pp679_M$array_type+ update_pp679_M$Age.at.recruitment +  update_pp679_M$Genetic.principal.components...Array.1+update_pp679_M$Genetic.principal.components...Array.2+update_pp679_M$Genetic.principal.components...Array.3+update_pp679_M$Genetic.principal.components...Array.4+update_pp679_M$Genetic.principal.components...Array.5+update_pp679_M$Genetic.principal.components...Array.6+update_pp679_M$Genetic.principal.components...Array.7+update_pp679_M$Genetic.principal.components...Array.8+update_pp679_M$Genetic.principal.components...Array.9+update_pp679_M$Genetic.principal.components...Array.10, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()

#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")
#library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_T2D_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
#presso_T2D_results<-c( "MR PRESSO",  res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#ahh ok FOR COMBINED SAMPLE presso detected no outliers, tehrefore did not conduct outlier corrected estimate test https://github.com/rondolab/MR-PRESSO/issues/9
#within women the MR presso global test wasn't even significant p=.62 (g-x in controls) ->26.05 same when add covariates (.65)
#within men the global test was sig, but no sig outliers ->26.05 same when add covariates


#and TSLS estimate
#adding covariates
library(ivtools)

 fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R + array_type+ Age.at.recruitment +  Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="binomial",data=update_pp679_M) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS +array_type+ Age.at.recruitment +  Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=df_noD_M) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679_M)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX not much there at all really
  confint(fitIV_ts) #26.05 I actually checked what happens if change data for second regression to the df INCLUDING those with diabetes, and changes the direction of the estimate! (also means the data call in the ivglm function doesn't overrirse data call in second regression)

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS)
res2_T2D<-data.frame(res2)
class(res2_T2D$b)
res2_T2D[] <- lapply(res2_T2D, unlist)
res2_T2D<-generate_odds_ratios(res2_T2D)


```

###then do the same for Hba1c
```{r}
#10.05 SNP-based one sample linear -> NO EGGER!

#str_sort(names(update_pp679))
#df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) #not needed when using hba1c as outcome
#ok first make MR input object
colnames<-grep("^VV[0-9]+",names(update_pp679))
my_lms <- lapply(update_pp679[colnames], function(x) lm(update_pp679$weekly_units_B_R ~ x +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but not just in controls!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679[colnames], function(x) glm(update_pp679$HbA1c_BL_winsor ~ x+update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10, family="gaussian")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
rm(my_lms)
rm(my_lms2)
gc()
#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="HbA1C") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="HbA1C")
#library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_HbA1C_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
#don't think the above line was necessary for anything??
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
presso_HbA1C_results<-c( res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#pressoSE<-res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]]/sqrt(79)
#presso_HbA1C_results[2]=pressoSE -> no, it DOES produce SE not Sd: https://github.com/rondolab/MR-PRESSO/issues/15
#PRESSO is significant and provides outlier orrected estimates for hva1c (incl when incorporate covariates)

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS, presso_HbA1C_results)
res2_HbA1C<-data.frame(res2)
class(res2_HbA1C$b)
res2_HbA1C[] <- lapply(res2_HbA1C, unlist)
#res2_T2D<-generate_odds_ratios(res2_T2D) #ExCELLENT!!! all worked
res2_HbA1C<-res2_HbA1C %>% mutate(lowerCI=b-(1.96*se))
res2_HbA1C<-res2_HbA1C %>% mutate(upperCI=b+(1.96*se))
```


#now try NLMR code but first recalculating GRSs by subbing in betas from Liu
```{r}
system('dx download "DrinksPerWeek.WithoutUKB.txt.gz"')
Liu_reduced = read.table(gzfile("DrinksPerWeek.WithoutUKB.txt.gz"),sep="\t")
#install.packages("janitor")
#library(tidyverse)
Liu_reduced<-Liu_reduced %>% janitor::row_to_names(row_number=1)
Liu_reduced<-Liu_reduced %>% mutate(PVALUE=as.numeric(PVALUE)) %>% mutate(BETA=as.numeric(BETA)) %>% mutate(SE=as.numeric(SE))
SNPs363<-read.csv("newGSCAN_finalSNPs_1SAMPLE.csv")
The_363<-SNPs363$SNP
Liu_reduced_matching_363SNPS<-Liu_reduced %>% filter(RSID %in% The_363)

#now save this reduced matching dataset so don't have to read that huge table in everytime
saveRDS(Liu_reduced_matching_363SNPS, file="Liu_reduced_matching_363SNPS.rds")
Liu_reduced_matching_363SNPS<-readRDS(file='Liu_reduced_matching_363SNPS.rds')
update_pp6<-readRDS(file='update_pp6.rds')
#now remove larger file from enviro
rm(Liu_reduced)

#can see that Liu is missing 38 of the sig SNPs from the 2022 GSCAN, but that will have to do
#now to recalculate the GRS - UP TO HERE 17.03

tocompare<-head(update_pp6)
Liu_reduced_matching_363SNPS<-Liu_reduced_matching_363SNPS %>% mutate(SNP=RSID)
mergedLiu<-left_join(SNPs363,Liu_reduced_matching_363SNPS,by="SNP")
mergedLiu_F<-mergedLiu %>% filter(!is.na(EFFECTIVE_N))

betas<-mergedLiu_F$BETA
X<-mergedLiu_F$X
df<-data.frame(X, betas)
class(df$X)
df<-df %>% mutate(X=as.character(X))
df$X <- sub("^", "V", df$X )
#names(rds)
X<-df$X
#https://stackoverflow.com/questions/70856361/how-to-create-a-weighted-sum-score-based-on-a-second-dataset-for-specific-variab
df2<-df[1:2,]

#library(tidyverse)
mergedLiu_df<-update_pp6 %>%
  mutate(GRS2 = rowSums(across(all_of(df$X), ~ .x * deframe(df)[[cur_column()]])))
#mergedLiu_df2<-mergedLiu_df 
#hmm this keeps quitting on me before finishing running!
#let's try the base R version of this and see if it runs instead
update_pp6$GRS2 <- as.vector(as.matrix(update_pp6[df$X]) %*% #this is telling it to cross-product the matrices
       with(df, setNames(betas, X)))
head(update_pp6$GRS2)
temp<-update_pp6 %>% select(GRS,GRS2)#YAY THIS WORKED! 
corr<-cor(update_pp6$GRS,update_pp6$GRS2)
summary(corr) #so the correlation is pretty strong! .87 -> check results anyway
#resave 19.03
saveRDS(update_pp6, file="update_pp6.rds")
#now go back and rerun all the nlmr
```

#31.03 neeed to rerun filtering code made earlier so suitable for Cox models
#also need to make a time-to-event/censoring/time-in-study variable
#01.04 -> making this into a separate file (after reading in update_pp6 above and then running the lines of code needed after re-resding in related to the sex and affy variables)

```{r}
#time to event first
#caclualte as censored according to date lost to follow up, date of death, also find date data acually goes up to (need to put censoring date as 31 May 2016 if people have not been lost to follow up/died/developed T2D before then)
#so need to make a status variable (0=does not develop T2D; 1=does develop T2D) and then a censoring date variable (equal to date of death or date lost to FU or date developed T2D, or else 31.05.16 -> use a case_when with pmin function > note that the date variables don't have true NAs but just blank text entry so need to fix this firs); then make a 'time' variable which is censoring date - date of attending assessment centre

grep("death", names(update_pp6), value = TRUE)
library(tidyverse)
library(dplyr)
temp<-update_pp6 %>% dplyr::select(ID_1,Death_date,Date.of.death...Instance.0,Date.lost.to.follow.up,first_rep_date_diab, Cohort_censor, earliest_diab, dX_at_BL,anyDmeds_BL)
update_pp6 %>% dplyr::count(T2D_by_firstocc)
update_pp6<-update_pp6 %>% dplyr::mutate(STATUS=dplyr::case_when(T2D_by_firstocc==1~1, TRUE~0))
update_pp6 %>% dplyr::count(STATUS)
update_pp6<-update_pp6 %>% dplyr::mutate(Death_date=lubridate::as_date(Date.of.death...Instance.0))
update_pp6<-update_pp6 %>% dplyr::mutate(Lost_date=lubridate::as_date(Date.lost.to.follow.up))
update_pp6<-update_pp6 %>% dplyr::mutate(Cohort_censor=as.Date("2016-05-31"))

#actually need to remove those with baseline diabetes FIRST! so that we don't have any diabetes dates before date of baseline assessment:

#now exclude those people with any kind of diabetes at baseline (except gestational)
update_pp6<-update_pp6%>% dplyr::filter(dX_at_BL==0)
#now remove anyone diagnosed with T1D after baseline (because it's likely that that is simply a misdiagnosis of T2D, including people first diagnosed with T2D and then T1D, because this probably reflects simply an earlier misdiagnosis of T1D)
update_pp6<-update_pp6 %>% dplyr::filter(T1D_by_firstocc==0) #31.03 think had already run this over update_pp6 accidentally, but makes sense to run for the non-Cox analyes too
#similarly, had already filtered out those taking insulin at BL
update_pp6 <-update_pp6 %>% filter(insulin_BL==0)

update_pp6 %>% dplyr::count(T2D_by_firstocc) #ok so still >10,000 incident cases to work with here
#filter out those reporting diabetes meds at BL who don't seld report diabetes/have records of diabetes
toMatch <- c("insulin", "amaryl" , "chlorpropamide" , "glimepiride", "glipizide" , "minodiab", "tolazamide", "tolbutamide", "glibenclamide", "diamicron", "gliclazide "  , "acarbose", "glucobay", "glucotard"  , "repaglinide", "nateglinide", "starlix" , "pioglitazone", "rosiglitazone", "avandia", "actos")
update_pp6<-update_pp6 %>% dplyr::mutate(anyDmeds_BL =(grepl(paste(toMatch,collapse="|"), Treatment.medication.code...Instance.0 )))
update_pp6 %>% count(anyDmeds_BL) #only 15 people (makes sense given we've already filtered out people self-reporting diabetes at bl/records indicate diagnosed with diabetes before bl/taking insulin at bl)
#now filter these people out
update_pp6<-update_pp6 %>% dplyr::filter(anyDmeds_BL==FALSE)
#final step is to remove those with elevated hba1c/glucose at BL (using Steven code; for incidence eastwood uses the same hba1c threshold and also glucose omore than or equal to 11.1)
update_pp6<-update_pp6%>% dplyr::filter (is.na(Glycated.haemoglobin..HbA1c....Instance.0) | Glycated.haemoglobin..HbA1c....Instance.0<48) # wow that removed almost 2,000 people
update_pp6<-update_pp6 %>% dplyr::filter (is.na(Glucose...Instance.0) | Glucose...Instance.0<11.1) #only removed a few extra people



update_pp6<-update_pp6 %>% dplyr::mutate(CENSDATE=pmin(Death_date, Lost_date, first_rep_date_diab, Cohort_censor , na.rm=TRUE))
temp<-update_pp6 %>% dplyr::select(ID_1,Death_date,Date.of.death...Instance.0,Date.lost.to.follow.up,first_rep_date_diab, Cohort_censor, earliest_diab, dX_at_BL,anyDmeds_BL, CENSDATE, BL_DATE, TIS) #GREAT, this worked

#now a time in study var
update_pp6<-update_pp6 %>% dplyr::mutate(BL_DATE=as.Date(Date.of.attending.assessment.centre...Instance.0))
update_pp6<-update_pp6 %>% dplyr::mutate(TIS=CENSDATE - BL_DATE)
class(update_pp6$TIS)

#now name as a new file and save
COX_update<-update_pp6
saveRDS(COX_update, file="COX_update.rds")
COX_update<-readRDS("COX_update.rds")
```

#AWESOME! ok now run a Cox model -> try observational first before MR version
#realised can't just run a regular COX model, needs to be a spline term -> which can do with either the pspline within coxph function (survival package), or what seems more common now is rcs within cph function (rms package) -> the latter is what Louise did
https://stats.stackexchange.com/questions/427436/pspline-or-rms-in-a-cox-model
```{r}
#09.05 figuring out additional covariates to add
COX_update79 %>% count(Past.tobacco.smoking...Instance.0) #weirdly 21,780 have a blank entry -> must just be NA
#COX_update79 %>% count(Age.completed.full.time.education...Instance.0) #hmm way too much missing data here
#COX_update79 %>% count(Qualifications...Instance.0) #going to split into those with tertiary degree vs those without
COX_update79 <-COX_update79 %>% mutate (tert_deg= case_when (grepl("College or University degree", Qualifications...Instance.0)~"Yes", TRUE ~"No"))
COX_update79 %>% count(tert_deg)
COX_update79 %>% count(Townsend.deprivation.index.at.recruitment)
class(COX_update79$Townsend.deprivation.index.at.recruitment)
COX_update79 %>% count(Summed.MET.minutes.per.week.for.all.activity...Instance.0)
class(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0)




library(survival)
#devtools::install_github("harrelfe/rms")
install.packages("rms")
library(rms)
#coxmod<-coxph(formula = Surv(TIS, STATUS) ~ weekly_units_B+ Sex_F+ Age.at.recruitment , data = COX_update)

#these lines are essential for predict and plot.Predict functions
detach(COX_update79_noEx)
attach(COX_update79)
dd <- datadist(weekly_units_B_R, Sex_F, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Sex_F+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79) #using 3 knots


p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp) #ok this hasn't worked, need to revisit...
lsf.str("package:rms") #ok for some reason the plot.Predict function didn't come in with this, so have to define it myself using the github code

acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 
#AWESOME! get a very nice J-shape for observational survival analysis #update 24.04 great this now works to have reference at 0 drinks per week

#by sex
COX_update79_F<-COX_update79 %>% filter(Sex=="Female")
detach(COX_update79)
attach(COX_update79_F)
dd <- datadist(weekly_units_B_R, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_F, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_F) #using 3 knots

p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp)
acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 

COX_update79_M<-COX_update79 %>% filter(Sex=="Male")
detach(COX_update79_F)
attach(COX_update79_M)
dd <- datadist(weekly_units_B_R, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_M, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_M) #using 3 knots

p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp)
acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 

#and removing former drinkers > very similar results
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
detach(COX_update79_M)
attach(COX_update79_noEx)
dd <- datadist(weekly_units_B_R, Sex_F, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_noEx, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Sex_F+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_noEx) #using 3 knots


#09.05 with current drinkers only -> results don't really change from above because only removing less than 20,000 people
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")
detach(COX_update79_noEx)

```
#now run nlmr Cox models (vary data set below between COX_update and COX_update_noEx and also whether use GRS/GRS2) ->16.04 should be GRS_79
#09.05 vary running noEx based on the current drinker only version
```{r}
detach(package:SUMnlmr, unload = TRUE)
devtools::install_github("amymariemason/SUMnlmr") #reinstalling so can get latest version with cox option
library(SUMnlmr)
#COX_update_noEx<-COX_update_noEx %>% mutate(survobj=Surv(TIS,STATUS))
#COX_update<-COX_update %>% mutate(survobj=Surv(TIS,STATUS))
#COX_update79<-COX_update79%>% mutate(survobj=Surv(TIS,STATUS))
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
#09.05 and with current drinkers only
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")

#sum(is.na(COX_update_noEx$weekly_units_B))
dummies_2<-model.matrix(~Sex, data=COX_update79)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79)[,2] 

summ_covar_FULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79$survobj,
                                 x = COX_update79$weekly_units_B_R, 
                                 g = COX_update79$GRS_79,
                                 covar=cbind(dummies_2,dummies_3,matrix(data=c(COX_update79$Age.at.recruitment, COX_update79$Genetic.principal.components...Array.1,COX_update79$Genetic.principal.components...Array.2,COX_update79$Genetic.principal.components...Array.3,COX_update79$Genetic.principal.components...Array.4,COX_update79$Genetic.principal.components...Array.5,COX_update79$Genetic.principal.components...Array.6,COX_update79$Genetic.principal.components...Array.7,COX_update79$Genetic.principal.components...Array.8,COX_update79$Genetic.principal.components...Array.9,COX_update79$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)

#NOTE BELOW THERE IS NO coxph family > if you write it t won't throw an error but will return result as if familyt had been gaussian
#19.04 updating to ref=0 -> ok this doesn't work because it's actually before the graph starts on X axis -> must take mean X of bottom strata and use that as the reference (1.34 in the case of full sample; 1.98 excl former drinkers; 2.85 for current drinkers only)
#RV adapted the function to remove red referene point -> update family=function because now it will plot with 'hazard ratio on y axis (Amy recent fix)
library(metafor)
library(stats)
library(matrixStats)
  model_DR_COX<- with(summ_covar_FULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=1.34,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE,  ylim_lower = .45, ylim_upper = 4.2, breaks= c(0.5,1,2,3))
)
summary(model_DR_COX)
#ok now to extract the NDE value
xvals<-model_DR_COX[["figure"]][["data"]][["x"]]
yvals<-model_DR_COX[["figure"]][["data"]][["yest"]]
uci<-model_DR_COX[["figure"]][["data"]][["uci"]]
xyvals<-data.frame(xvals,yvals,uci) #once ordered these, can see NDE is 31.31 drinks per week; but this is only sig up to 11.45 drinks per week
#for nadir index
which.min(xyvals$yvals)
xyvals[6358,]

#here can actually set ref to 0! but need to try to figure out how to reduce y axis
model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, SUMnlmr::piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)
LACESUM<-summary(model_DR_COX)
#zoomed in version -> I adapted the function setting own y limits -> no SCRAPPED this! but have changed it so that has more meaningful axis labels and x axis breaks

####IMPORTANT NOTE, when using current drinkers only MUST update the ref value to minimum, otherwise will get an error saying object ref_pos not found -> not sure how to work out what this number is because it's less than the mean for the bottom stratum... ->>> ahh it's the MIN for the bootom stratum
#min(COX_update79_noEx$weekly_units_B_R)
model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=1,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX) #hmm this is actually too misleading without the confidence intervals


#update 07.04 also going to vary between male and female to see if any difference
#library(tidyverse)
library(tidyverse)
COX_update79 %>% count(Sex)
library(survival) 
#COX_update79<-COX_update79%>% mutate(survobj=Surv(TIS,STATUS))
#COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")
COX_update79_M<-COX_update79 %>% filter(Sex=="Male")
COX_update79_F<-COX_update79 %>% filter(Sex=="Female")

#22.11 splitting females by BMI - for now just use regular BMI measure, but should excxlude people with too much difference between refular and bioimpedence https://www.bmj.com/content/352/bmj.i582.full
str_sort(names(COX_update79))
COX_update79_F_N<-COX_update79_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.<25) #ok so this is 68K/160K
COX_update79_F_OV<-COX_update79_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.>=25
                                             &Body.mass.index..BMI....Instance.0.participant...p21001_i0.<30) #60K
COX_update79_F_OB<-COX_update79_F %>% filter(Body.mass.index..BMI....Instance.0.participant...p21001_i0.>30) #32K... might be a bit small?
#will try running the analysis on regular weight females

#17.12 using Steven's suggestion to use residual BMI instead
COX_update79_F<-COX_update79_F %>% filter(!is.na(Body.mass.index..BMI....Instance.0.participant...p21001_i0.))
HBREG<-lm(Body.mass.index..BMI....Instance.0.participant...p21001_i0.~GRS_79, data=COX_update79_F )
COX_update79_F$value_lm <- HBREG$fitted.values
COX_update79_F<-COX_update79_F %>% mutate(resid_BMI=Body.mass.index..BMI....Instance.0.participant...p21001_i0.-value_lm)
range(COX_update79_F$resid_BMI) #these numbers are no longer meaningful in terms of BMI cut-offs, but instead we'll use tertiles
tertiles <- quantile(COX_update79_F$resid_BMI, probs=c(.333, .666), na.rm = FALSE)
COX_update79_F_N<-COX_update79_F %>% filter(resid_BMI <= -2.51) #53191
COX_update79_F_OV<-COX_update79_F %>% filter(resid_BMI > -2.51
                                             &resid_BMI <1.14) #53185
COX_update79_F_OB<-COX_update79_F %>% filter(resid_BMI >= 1.14) #53335

COX_update79_noEx_M<-COX_update79_noEx %>% filter(Sex=="Male")
COX_update79_noEx_F<-COX_update79_noEx %>% filter(Sex=="Female")
#dummies_2<-model.matrix(~Sex, data=COX_update79_noEx)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79_F_OB)[,2] 

summ_covar_noEx_FULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79_F_OB$survobj,
                                 x = COX_update79_F_OB$weekly_units_B_R, 
                                 g = COX_update79_F_OB$GRS_79,
                                 covar=cbind(dummies_3,matrix(data=c(COX_update79_F_OB$Age.at.recruitment, COX_update79_F_OB$Genetic.principal.components...Array.1,COX_update79_F_OB$Genetic.principal.components...Array.2,COX_update79_F_OB$Genetic.principal.components...Array.3,COX_update79_F_OB$Genetic.principal.components...Array.4,COX_update79_F_OB$Genetic.principal.components...Array.5,COX_update79_F_OB$Genetic.principal.components...Array.6,COX_update79_F_OB$Genetic.principal.components...Array.7,COX_update79_F_OB$Genetic.principal.components...Array.8,COX_update79_F_OB$Genetic.principal.components...Array.9,COX_update79_F_OB$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)

#NOTE BELOW THERE IS NO coxph family > if you write it t won't throw an error but will return result as if familyt had been gaussian #yes has since been updated
#for females the ref should be: .76; for males: 2.65 -> for current drinkers only F is 2.00 M is 4.51
#for female normal weight 1.08, female ov .856, fem ob .32
#tertiles FN 1.11 FOV .966 FOB .439 
  model_DR_COX<- with(summ_covar_noEx_FULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=.439,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE,ylim_lower = .19, ylim_upper = 1.5, breaks= c(0.2,.5,1, 1.5)  )) #use the following bit for M/F/overall not split by BMI: , ylim_lower = .45, ylim_upper = 4.3, breaks= c(0.5,1,2,3)) #for normal weight/tertile 1 women don't set limits/breaks as way too high CIs; #for ov/obese women use
#ylim_lower = .18, ylim_upper = 1.2, breaks= c(0.2,.5,1), for tertile 2+3 women use ylim_lower = .2, ylim_upper = 1.5, breaks= c(0.19,.5,1, 1.5))
model_DR_COX  
  
summary(model_DR_COX)

####IMPORTANT NOTE, when using current drinkers only MUST update the ref value to minimum, otherwise will get an error saying object ref_pos not found -> not sure how to work out what this number is because it's less than the mean for the bottom stratum... ->>> ahh it's the MIN for the bootom stratum
model_DR_COX <-with(summ_covar_noEx_MULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)


#15.05 running Amy suggestion to remove primary care diagnoses and see new results
str_sort(names(COX_update79)) #"Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus." 
temp<-COX_update79 %>% select(ID_1,"Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus." )
COX_update79<-COX_update79 %>% mutate(source_T2D=Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus.)
COX_update79 %>% dplyr::count(source_T2D) #ohhh interesting -> vast majority of T2D diags are from hospital admissions
#confirmed that this is the number of incident cases used in the main Cox analysis (must have already removed people who had other kinds of diabetes first etc -> yes this makes sense!)
36+273+8437+542+660+137+126

#now remove those diagnosed through primary care only and primary care and other source(s)
COX_update79<-COX_update79 %>% filter(source_T2D!="Primary care only")
COX_update79<-COX_update79 %>% filter(source_T2D!="Primary care and other source(s)")
#now re-run main Cox 
dummies_2<-model.matrix(~Sex, data=COX_update79)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79)[,2] 

summ_covar_FULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79$survobj,
                                 x = COX_update79$weekly_units_B_R, 
                                 g = COX_update79$GRS_79,
                                 covar=cbind(dummies_2,dummies_3,matrix(data=c(COX_update79$Age.at.recruitment, COX_update79$Genetic.principal.components...Array.1,COX_update79$Genetic.principal.components...Array.2,COX_update79$Genetic.principal.components...Array.3,COX_update79$Genetic.principal.components...Array.4,COX_update79$Genetic.principal.components...Array.5,COX_update79$Genetic.principal.components...Array.6,COX_update79$Genetic.principal.components...Array.7,COX_update79$Genetic.principal.components...Array.8,COX_update79$Genetic.principal.components...Array.9,COX_update79$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)


  model_DR_COX<- with(summ_covar_FULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=1.36,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE
                                )
)
summary(model_DR_COX)
#ok now to extract the NDE value
xvals<-model_DR_COX[["figure"]][["data"]][["x"]]
yvals<-model_DR_COX[["figure"]][["data"]][["yest"]]
uci<-model_DR_COX[["figure"]][["data"]][["uci"]]
lci<-model_DR_COX[["figure"]][["data"]][["lci"]]
xyvals<-data.frame(xvals,yvals,uci, lci) #once ordered these, can see NDE is 50.68 drinks per week; but this is only sig up to 22.16 drinks per week -> #17.12 updated these, these were wrong in manuscript!
#for nadir index
which.min(xyvals$yvals)
xyvals[6766,]

model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)
#haven't run male/female split for now
```

#07.04 regressing exposure on GRS to get F statistic
#also other descriptive stats
```{r}
Fstatcheck<-lm(update_pp679$weekly_units_B_R~update_pp679$GRS_79)
summary(Fstatcheck)

#actual formul 16.04
Fstat<-((nrow(update_pp679)-79-1)/79)*(.005769/(1-.005769))

update_pp6 %>% count(T2dX_at_BL)
COX_update %>% filter(T2dX_at_BL==0) %>% count(STATUS)

install.packages("table1")
library(table1)
#to answer Amy's suggestion about swapping Sex to column and drining group to row for supplementary, instead going to nest sex within drining group
TABBY1<-table1(~ weekly_units_B_R + STATUS_F + HbA1c_BL_winsor + Age.at.recruitment  +  Past.tobacco.smoking...Instance.0_F + tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0 + array_type_F  | BL_drinker_status_F*Sex_F, data=COX_update79) #addin extra covariates as well as incident diabetes status variable

COX_update79 <-COX_update79 %>% mutate (tert_deg= case_when (grepl("College or University degree", Qualifications...Instance.0)~"Yes", TRUE ~"No"))
COX_update79%>% dplyr::count(tert_deg)
COX_update79$tert_deg<-factor(COX_update79$tert_deg, levels=c("No","Yes"),
         labels=c("No", 
                  "Yes"))
COX_update79%>% dplyr::count(Past.tobacco.smoking...Instance.0_F)
 COX_update79$Past.tobacco.smoking...Instance.0_F<-factor(COX_update79$Past.tobacco.smoking...Instance.0, levels=c("","I have never smoked","Just tried once or twice","Prefer not to answer","Smoked occasionally","Smoked on most or all days"),
         labels=c("N/A", 
                  "Never", "Once or twice", "Prefer not to answer", "Occasionally", "Most or all days"))
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_relevel(COX_update79$Past.tobacco.smoking...Instance.0_F, "N/A", "Prefer not to answer", "Never", "Once or twice", "Occasionally", "Most or all days")
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_collapse(COX_update79$Past.tobacco.smoking...Instance.0_F, Missing= c("N/A", "Prefer not to answer"))
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_relevel(COX_update79$Past.tobacco.smoking...Instance.0_F, "Never", "Once or twice", "Occasionally", "Most or all days", "Missing")
COX_update79%>% dplyr::count(array_type_F)
COX_update79$array_type_F<-factor(COX_update79$array_type, levels=c("Affy","UKBiLEVEAX"),
         labels=c("UK Biobank Axiom array", 
                  "UKBiLEVE Axiom array"))
COX_update79%>% dplyr::count(STATUS_F)
COX_update79$STATUS_F<-factor(COX_update79$STATUS, levels=c("0","1"),
         labels=c("Did not develop incident T2D", 
                  "Developed incident T2D"))
COX_update79%>% dplyr::count(BL_drinker_status)
COX_update79$BL_drinker_status_F<-factor(COX_update79$BL_drinker_status, levels=c("Current","Former","Never"),
         labels=c("Current Drinker", 
                  "Former Drinker", "Never Drinker"))

label(COX_update79$Sex_F)       <- "Sex"
label(COX_update79$Age.at.recruitment)       <- "Age"
label(COX_update79$weekly_units_B_R)     <- "Drinks per week"
label(COX_update79$HbA1c_BL_winsor) <- "HbA1C (winsorised)"
label(COX_update79$Past.tobacco.smoking...Instance.0_F)       <- "Smoking history"
label(COX_update79$tert_deg)<- "Tertiary degree"
label(COX_update79$Townsend.deprivation.index.at.recruitment)     <- "Townsend deprivation index"
label(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0) <- "MET minutes per week"
label(COX_update79$array_type_F)     <- "Genotyping array"
label(COX_update79$STATUS_F) <- "Incident diabetes status"


#get new sample size for observational analyses
nrow(COX_update79) #305,614 -> what I had written in the paper good
sum((!COX_update79$Past.tobacco.smoking...Instance.0_F=="Missing")&!is.na(COX_update79$Townsend.deprivation.index.at.recruitment)&!is.na(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0)) #down to 233,568

```



old code for trying to deal with relatedness
```{r}


temp<-temp %>% filter(Genetic.relatedness.factor...Array.0>.0|Genetic.relatedness.factor...Array.1>.0|Genetic.relatedness.factor...Array.2>.0|Genetic.relatedness.factor...Array.3>.0|Genetic.relatedness.factor...Array.4>.0)
temp1<-temp %>% pivot_longer(cols=starts_with("Genetic.relatedness.pairing"),names_to="array",values_to="UNID")
temp1<-temp1 %>% relocate(UNID, .after=ID_1)
temp1<-temp1 %>% sort("UNID")
temp2<-temp1 %>% pivot_wider(values_from="ID_1",names_from="UNID") #values_from


class(temp2$"8542")
#first make a kinship coefficient variable for each row (UNID) based on which array is mention in "array"
temp3<-temp2 %>% mutate(KINSHIP_co=case_when(array=="Genetic.relatedness.pairing...Array.0" ~ Genetic.relatedness.factor...Array.0, array=="Genetic.relatedness.pairing...Array.1" ~ Genetic.relatedness.factor...Array.1, array=="Genetic.relatedness.pairing...Array.2"~ Genetic.relatedness.factor...Array.2, array=="Genetic.relatedness.pairing...Array.3" ~ Genetic.relatedness.factor...Array.3, array=="Genetic.relatedness.pairing...Array.4" ~ Genetic.relatedness.factor...Array.4, TRUE~NA_real_))
#now combine all the pairing columns into 1 column, removing the 'NULL' values so left with just a 'c(ID1,ID2)' for each row
#first remove the 'NA' col (formed as a result of the original pivot_longer from those pairing cells that were NA)
temp4<-temp3 %>% select(-c("NA"))
#find index positions of columns
grep("7289",colnames(temp4)) #8
grep("6316",colnames(temp4)) #3940
temp4<-temp4 %>% unite("PAIRING", 8:3940, remove=TRUE,na.rm=TRUE) #from the first pairing ID variable to the last, as listed in the df; remove = TRUE removes input columns from output data frame; automatically uses underscore as the separator
#ahh bugger I can see this isn't the right approach because 

#now remove all "NULL_" from this new value, so should just be left with the two IDs we're interested in
temp4$PAIRING2<- gsub("NULL_","",temp4$PAIRING)

```


#22.04 testing for pleiotropy using MR-egger within strata
using the code Haodong shared with me to make the strata
hang on have to use update_pp6 instad of COX_update because interested in baseline logistic rather than incident
mmm for now just use incident
#update 20.05 -> using this code but with COX_update79 to try to do nlmr with sensitivity methods
```{r}
N<-310440  ;No<-31044     #10 ests #RV not perfectly fitting into 10 strata...
N/No


#ok for these purposes, going to remove the people with the 8 highest drinks per week values


set.seed(1123)



##fitting
library(tidyverse)
dat_Hao_order<-update_pp679[ order(update_pp679$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<235)

#residual exposure #RV says add column calculated by subtracting genetically predicted drinks per week from actual drinks per week 
#dat_Hao_order<-cbind(  dat_Hao_order   ,  dat_Hao_order$weekly_units_B_R -lm(  dat_Hao_order$weekly_units_B_R~dat_Hao_order$GRS )$fitted)
#old LACE stratums #RV says add a column with ranks based on residual method only (ie the column created above)
#'No' is defined above to be 10% of the sample -> floor gives the lowest residual value for each of the 10 strata
#so actually this produces a new column with the strata for each person based on residuals
#dat_Hao_order<-cbind(  dat_Hao_order   ,  
#                   floor( (rank( dat_Hao_order[610] ,ties.method = "first"  )/(No+0.000000001) ) )+1  )  #RV the column above is now the 610th variable 
#temp<-dat_Hao_order %>% select(weekly_units_B_R,GRS,611) 

##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 385000

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y
class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) glm(X[[10]]$T2dX_at_BL ~ x, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()


#library(MendelianRandomization)
MRInputObject <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)

IVW10<-mr_ivw(MRInputObject)
IVW10
exp(.03)

#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

Egg1<-mr_egger(MRInputObject)
Egg1 #this is really the only strata with a real effect going on
Egg2<-mr_egger(MRInputObject)
Egg2
Egg3<-mr_egger(MRInputObject)
Egg3
IVW3<-mr_ivw(MRInputObject)
IVW3 #hmm the effect sizes are just really tiny here compared to the LACEs, makes me think I might have done something wrong here in setting up the MRInputObject 
Egg4<-mr_egger(MRInputObject)
Egg4 #now approaching significance (although teeny tiny estimate size)
Egg5<-mr_egger(MRInputObject)
Egg5
Egg6<-mr_egger(MRInputObject)
Egg6
Egg7<-mr_egger(MRInputObject)
Egg7
Egg8<-mr_egger(MRInputObject)
Egg8 #ahh ok this is now a significant intercept! (although still a really tiny, but significant, positive estimate)
Egg9<-mr_egger(MRInputObject)
Egg9 #again now a significant intercept
Egg10<-mr_egger(MRInputObject)
Egg10 #and now not significant...



#20.05
#updating 25.05 with male and female stratified versions as well 
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79[ order(COX_update79$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<270) #get rid of the top 4 so nicely divides by 10
N<-305610  ;No<-30561     #10 ests #RV not perfectly fitting into 10 strata...


#female - get rid of top 4 so nicely divides by 10
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79_F[ order(COX_update79_F$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-160150 ;No<-16015  


#male already divides neatly by 10
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79_M[ order(COX_update79_M$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
#dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-145460 ;No<-14546


N/No
##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 305610

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
#for sex stratified grey out sex covariate
#library(survival)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x + #X[[10]]$Sex_F+ 
                                                    X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using survobj 
#library (survival)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) coxph(X[[10]]$survobj ~ x + # X[[10]]$Sex_F+ 
                                                        X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[1, c(1,3)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
names(dfby)

library(MendelianRandomization)
MRInputObject1 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.) #ok so this worked for the first strata; but before continuing check whether want to exponentiate first -> ok so can see from AMY sumnlmr create summary code that they take the se as the unexponentiated, unclear exactly where the beta itself comes from... in any case, confirmed by looking in summ_covar_FULL_T2D_COX that at that stage the Y-G betas are STILL unexponentiated because some of them are negative  by[j] <- model$coef[1] byse[j] <- summary(model)$coef[1, 3]

MRInputObject2 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject3 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject4 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject5 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject6 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject7 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject8 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject9 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject10 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

#and then once run below for a given sens test (just sub out med for IVW etc), add columns to LACESUM[["coefficients"]] which are from the main results (or make a list of them instead?) -> actually only works for median and IVW, for RAPS PRESSO and weighted mode will have to use other packages because Mendelian Randomisation package doesn't include them


ivw1<-MendelianRandomization::mr_ivw(MRInputObject1)
ivw1 #interesting much smaller/non-sig decrease
ivw2<-MendelianRandomization::mr_ivw(MRInputObject2)
ivw2
ivw3<-MendelianRandomization::mr_ivw(MRInputObject3)
ivw3
ivw4<-MendelianRandomization::mr_ivw(MRInputObject4)
ivw4 
ivw5<-MendelianRandomization::mr_ivw(MRInputObject5)
ivw5
ivw6<-MendelianRandomization::mr_ivw(MRInputObject6)
ivw6
ivw7<-MendelianRandomization::mr_ivw(MRInputObject7)
ivw7
ivw8<-MendelianRandomization::mr_ivw(MRInputObject8)
ivw8 
ivw9<-MendelianRandomization::mr_ivw(MRInputObject9)
ivw9 
ivw10<-MendelianRandomization::mr_ivw(MRInputObject10)
ivw10 #this one is sig positive
summary(ivw10)

ivwres1<-c(ivw1@Estimate,ivw1@StdError,ivw1@CILower,ivw1@CIUpper,ivw1@Pvalue)
ivwres2<-c(ivw2@Estimate,ivw2@StdError,ivw2@CILower,ivw2@CIUpper,ivw2@Pvalue)
ivwres3<-c(ivw3@Estimate,ivw3@StdError,ivw3@CILower,ivw3@CIUpper,ivw3@Pvalue)
ivwres4<-c(ivw4@Estimate,ivw4@StdError,ivw4@CILower,ivw4@CIUpper,ivw4@Pvalue)
ivwres5<-c(ivw5@Estimate,ivw5@StdError,ivw5@CILower,ivw5@CIUpper,ivw5@Pvalue)
ivwres6<-c(ivw6@Estimate,ivw6@StdError,ivw6@CILower,ivw6@CIUpper,ivw6@Pvalue)
ivwres7<-c(ivw7@Estimate,ivw7@StdError,ivw7@CILower,ivw7@CIUpper,ivw7@Pvalue)
ivwres8<-c(ivw8@Estimate,ivw8@StdError,ivw8@CILower,ivw8@CIUpper,ivw8@Pvalue)
ivwres9<-c(ivw9@Estimate,ivw9@StdError,ivw9@CILower,ivw9@CIUpper,ivw9@Pvalue)
ivwres10<-c(ivw10@Estimate,ivw10@StdError,ivw10@CILower,ivw10@CIUpper,ivw10@Pvalue)

ivwRES<-t(data.frame(ivwres1,ivwres2,ivwres3,ivwres4,ivwres5,ivwres6,ivwres7,ivwres8,ivwres9,ivwres10))
ivwRES<-data.frame(ivwRES) #24.05 adding covariates seems to have attenuated results for both ivw and ivwian, only slightly

#ok now to do the other methods using the twosampleMR package
library(TwoSampleMR)
SNPSdf1<-cbind(MRInputObject1$betaX,MRInputObject1$betaXse,MRInputObject1$betaY,MRInputObject1$betaYse)
SNPSdf1<-data.frame(SNPSdf1)
colnames(SNPSdf1)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf1<-SNPSdf1 %>% mutate(SNP=1:79)
SNPSdf1<-SNPSdf1 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf1<-SNPSdf1 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf2<-cbind(MRInputObject2$betaX,MRInputObject2$betaXse,MRInputObject2$betaY,MRInputObject2$betaYse)
SNPSdf2<-data.frame(SNPSdf2)
colnames(SNPSdf2)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf2<-SNPSdf2 %>% mutate(SNP=1:79)
SNPSdf2<-SNPSdf2 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf2<-SNPSdf2 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf3<-cbind(MRInputObject3$betaX,MRInputObject3$betaXse,MRInputObject3$betaY,MRInputObject3$betaYse)
SNPSdf3<-data.frame(SNPSdf3)
colnames(SNPSdf3)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf3<-SNPSdf3 %>% mutate(SNP=1:79)
SNPSdf3<-SNPSdf3 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf3<-SNPSdf3 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf4<-cbind(MRInputObject4$betaX,MRInputObject4$betaXse,MRInputObject4$betaY,MRInputObject4$betaYse)
SNPSdf4<-data.frame(SNPSdf4)
colnames(SNPSdf4)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf4<-SNPSdf4 %>% mutate(SNP=1:79)
SNPSdf4<-SNPSdf4 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf4<-SNPSdf4 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf5<-cbind(MRInputObject5$betaX,MRInputObject5$betaXse,MRInputObject5$betaY,MRInputObject5$betaYse)
SNPSdf5<-data.frame(SNPSdf5)
colnames(SNPSdf5)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf5<-SNPSdf5 %>% mutate(SNP=1:79)
SNPSdf5<-SNPSdf5 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf5<-SNPSdf5 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf6<-cbind(MRInputObject6$betaX,MRInputObject6$betaXse,MRInputObject6$betaY,MRInputObject6$betaYse)
SNPSdf6<-data.frame(SNPSdf6)
colnames(SNPSdf6)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf6<-SNPSdf6 %>% mutate(SNP=1:79)
SNPSdf6<-SNPSdf6 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf6<-SNPSdf6 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf7<-cbind(MRInputObject7$betaX,MRInputObject7$betaXse,MRInputObject7$betaY,MRInputObject7$betaYse)
SNPSdf7<-data.frame(SNPSdf7)
colnames(SNPSdf7)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf7<-SNPSdf7 %>% mutate(SNP=1:79)
SNPSdf7<-SNPSdf7 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf7<-SNPSdf7 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf8<-cbind(MRInputObject8$betaX,MRInputObject8$betaXse,MRInputObject8$betaY,MRInputObject8$betaYse)
SNPSdf8<-data.frame(SNPSdf8)
colnames(SNPSdf8)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf8<-SNPSdf8 %>% mutate(SNP=1:79)
SNPSdf8<-SNPSdf8 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf8<-SNPSdf8 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf9<-cbind(MRInputObject9$betaX,MRInputObject9$betaXse,MRInputObject9$betaY,MRInputObject9$betaYse)
SNPSdf9<-data.frame(SNPSdf9)
colnames(SNPSdf9)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf9<-SNPSdf9 %>% mutate(SNP=1:79)
SNPSdf9<-SNPSdf9 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf9<-SNPSdf9 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf10<-cbind(MRInputObject10$betaX,MRInputObject10$betaXse,MRInputObject10$betaY,MRInputObject10$betaYse)
SNPSdf10<-data.frame(SNPSdf10)
colnames(SNPSdf10)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf10<-SNPSdf10 %>% mutate(SNP=1:79)
SNPSdf10<-SNPSdf10 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf10<-SNPSdf10 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf<-list(SNPSdf1,SNPSdf2,SNPSdf3,SNPSdf4,SNPSdf5,SNPSdf6,SNPSdf7,SNPSdf8,SNPSdf9,SNPSdf10)

#weighted mode
my_lms <- lapply(SNPSdf, function(x) mr_weighted_mode(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$b-(1.96*x$se);x$upperCI<-x$b+(1.96*x$se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
modeRES<-as.data.frame(do.call(rbind,add_CIs))
modeRES<-modeRES %>% select(b,se,lowerCI,upperCI,pval) #DONE!
class(modeRES)
class(modeRES$b)
modeRES2<- unnest(modeRES,b) %>% unnest(modeRES,se) %>% unnest(modeRES,lowerCI) %>% unnest(modeRES,upperCI) %>% unnest(modeRES,pval) #none are now sig once incorp covariates
class(modeRES2$se)

#raps
my_lms <- lapply(SNPSdf, function(x) mr.raps::mr.raps(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome, diagnosis=TRUE)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$beta.hat-(1.96*x$beta.se);x$upperCI<-x$beta.hat+(1.96*x$beta.se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
rapsRES<-as.data.frame(do.call(rbind,add_CIs))
rapsRES<-rapsRES %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value) #DONE!
rapsRES2<- unnest(rapsRES,beta.hat) %>% unnest(rapsRES,beta.se) %>% unnest(rapsRES,lowerCI) %>% unnest(rapsRES,upperCI) %>% unnest(rapsRES,beta.p.value) 
class(rapsRES2$beta.se)

#finally presso
my_lms <- lapply(SNPSdf, function(x) run_mr_presso(x, NbDistribution = 2500, SignifThreshold = 0.05)) 
#all 10 global tests >.05, therefore no outlier corrected estmates produced
#24.05 same for when added covariates; 25.05 same for females; same for males EXCEPT stratum 9, but then no sig outliers could be found

M_FOURxsensresultsCOV<-list(ivwRES,medRES,modeRES2,rapsRES2)
saveRDS(M_FOURxsensresultsCOV, file="M_FOURxsensresultsCOV.rds")
saveRDS(M_FOURxsensresultsCOV, file="M_FOURxsensresultsCOV.RData")
M_FOURxsensresultsCOV<-readRDS("M_FOURxsensresultsCOV.rds") 

M_FOURxsensresultsCOV[[3]]<-M_FOURxsensresultsCOV[[3]] %>% select(b,se,lowerCI,upperCI,pval)
M_FOURxsensresultsCOV[[4]]<-M_FOURxsensresultsCOV[[4]] %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value)
#so now have LACEs in there with variance/CIs, need to add the mean x for each stratum now so that can figure out how to do fractional polynomial
#actually can just calculate by hand
mean1<-mean(X[[1]]$weekly_units_B_R)
mean2<-mean(X[[2]]$weekly_units_B_R)
mean3<-mean(X[[3]]$weekly_units_B_R)
mean4<-mean(X[[4]]$weekly_units_B_R)
mean5<-mean(X[[5]]$weekly_units_B_R)
mean6<-mean(X[[6]]$weekly_units_B_R)
mean7<-mean(X[[7]]$weekly_units_B_R)
mean8<-mean(X[[8]]$weekly_units_B_R)
mean9<-mean(X[[9]]$weekly_units_B_R)
mean10<-mean(X[[10]]$weekly_units_B_R)
Xmeans<-c(mean1,mean2,mean3,mean4,mean5,mean6,mean7,mean8,mean9,mean10)#now attach these back to sensitivity results
M_FOURxsensresultsCOV2<-lapply(M_FOURxsensresultsCOV, function(x) cbind(x, Xmeans)) #EXCELLENT! now see if can feed into the NLMR package to generate plots
devtools::install_github("jrs95/nlmr")
library(nlmr)
ls("package:nlmr") #so that fracpoly_best function IS here, need to see what's in it
View(nlmr::fracpoly_best) #excellent -> this opens the function in a separate tab, and unlike the sumNLMR equivalent only needs the values for LACE, se and xmeans rather than the individual bx by stats (which force the function to use ratio method) -> want to use argument d="both"
```

```{r}
 ##### Best-fitting fractional polynomial #####
  fracpb <- nlmr::fracpoly_best(coef=M_FOURxsensresultsCOV2[[1]][["X1"]], coef_se=M_FOURxsensresultsCOV2[[1]][["X2"]], xmean=M_FOURxsensresultsCOV2[[1]]$Xmeans, d="both", pd=.05, method="FE")
  #so p1_ML is best fitting of degree 1, p2_ML is best fitting of degree 2; fp_p is p value for a first degree fp over linear; fp_d12_p is for degree 2 over degree 1, not sure what p_ML is though??? (eg for first one - IVW - p_ML is -2 whereas p1_ML is -1 and p2_ML is -.5)->>>> AHHHH this is wrong! p_ML is degree 1, p1_ML and p2_ML relate to the best fitting second degree (ie the two fractions that compose best fitting second degree polynomial) -> not significant in this case anyway
#GOOD news is tht didn't use bootstrapped CIs/ses for main nlmr analyses fracpoly (only for piecewise), so don't need to calclate here (which for some reason requires the x and y and g stats)
model <- fracpb$model; p_ML <- fracpb$p_ML; p1_ML <- fracpb$p1_ML; p2_ML <- fracpb$p2_ML; fp_p <- fracpb$fp_p; fp_d12_p <- fracpb$fp_d12_p
  d <- fracpb$d
    ##### Non-linearity tests #####
  #library(metafor)
  p_quadratic <- rma(M_FOURxsensresultsCOV2[[1]][["X1"]] ~ M_FOURxsensresultsCOV2[[1]]$Xmeans, M_FOURxsensresultsCOV2[[1]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[1]][["X1"]], vi=(M_FOURxsensresultsCOV2[[1]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
  #and to make figure
  
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
  

     #View(nlmr::fracpoly_figure)
     
     ###AHHHH ok below need to supply mean of lowest stratum as xmin and mean of highest stratum as xmax, not the literal highest and lowest x values! 1.34 and 53.78 for overall; .77 and 40.53 for women; 2.65 and 63.53 for men
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=2, p_ML=-1, p1_ML=-1, p2_ML=-.5, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional polynoial degrees from the actual data, apart from that the shape is just generic! so what I'll do is simply generate the polynomial tests and list of LACEs, and won't make the plots!!!
   #ohhhh my GOD I GOT THE GFIGURE WORKING!!! -well the CIs are still a little weird on the left hand side; have edited the function foior now to remove CIs s can see line better -> weird that doesn't properly align with the Xmean for lowest caeory -> I think the nlmr package must plot in a sep way
  
   #do for sensitivity 2-4 (median,mode,RAPS) -> one above is IVW
    fracpbMEDIAN <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[2]][["X1"]], coef_se=M_FOURxsensresultsCOV2[[2]][["X2"]], xmean=M_FOURxsensresultsCOV2[[2]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbMEDIAN$model; p_ML <- fracpbMEDIAN$p_ML; p1_ML <- fracpbMEDIAN$p1_ML; p2_ML <- fracpbMEDIAN$p2_ML; fp_p <- fracpbMEDIAN$fp_p; fp_d12_p <- fracpbMEDIAN$fp_d12_p
  d <- fracpbMEDIAN$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(M_FOURxsensresultsCOV2[[2]][["X1"]] ~ M_FOURxsensresultsCOV2[[2]]$Xmeans, M_FOURxsensresultsCOV2[[2]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[2]][["X1"]], vi=(M_FOURxsensresultsCOV2[[2]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=2, p_ML=-3, p1_ML=-1, p2_ML=-.5, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  
    fracpbmode <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[3]][["b"]], coef_se=M_FOURxsensresultsCOV2[[3]][["se"]], xmean=M_FOURxsensresultsCOV2[[3]]$Xmeans, d="both", pd=.05, method="FE")
        model <- fracpbmode$model; p_ML <- fracpbmode$p_ML; p1_ML <- fracpbmode$p1_ML; p2_ML <- fracpbmode$p2_ML; fp_p <- fracpbmode$fp_p; fp_d12_p <- fracpbmode$fp_d12_p
  d <- fracpbmode$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(M_FOURxsensresultsCOV2[[3]][["b"]] ~ M_FOURxsensresultsCOV2[[3]]$Xmeans, M_FOURxsensresultsCOV2[[3]][["se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[3]][["b"]], vi=(M_FOURxsensresultsCOV2[[3]][["se"]])^2)$QE, df=(10-1))
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=1, p_ML=1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
    
    
     fracpbraps <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[4]][["beta.hat"]], coef_se=M_FOURxsensresultsCOV2[[4]][["beta.se"]], xmean=M_FOURxsensresultsCOV2[[4]]$Xmeans, d="both", pd=.05, method="FE")
      model <- fracpbraps$model; p_ML <- fracpbraps$p_ML; p1_ML <- fracpbraps$p1_ML; p2_ML <- fracpbraps$p2_ML; fp_p <- fracpbraps$fp_p; fp_d12_p <- fracpbraps$fp_d12_p
  d <- fracpbraps$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(M_FOURxsensresultsCOV2[[4]][["beta.hat"]] ~ M_FOURxsensresultsCOV2[[4]]$Xmeans, M_FOURxsensresultsCOV2[[4]][["beta.se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[4]][["beta.hat"]], vi=(M_FOURxsensresultsCOV2[[4]][["beta.se"]])^2)$QE, df=(10-1))
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=1, p_ML=1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional 
     
     #23.03 OK NEED TO REDO ALL OF THIS AFTER INCORPORATING COVARIATES -> 24th done!, 
     #ALSO THEN DO BELOW WITH MALES AND FEMALES SEPARATELY
```

#ok now for HBA1C

```{r}
#first remove those without hba1c values
 full_HbA1c<-update_pp679 %>% filter(!is.na(HbA1c_BL_winsor))
  #women only

#20.05
#updating 25.05 with male and female stratified versions as well 
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c[ order(full_HbA1c$GRS_79),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<275) #get rid of the top 2 so nicely divides by 10
N<-295710  ;No<-29571     #10 ests #RV not perfectly fitting into 10 strata...


#female - get rid of top 4 so nicely divides by 10
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c_M[ order(full_HbA1c_F$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-160150 ;No<-16015  


#male already divides neatly by 10
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c_M[ order(full_HbA1c_M$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
#dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-145460 ;No<-14546


N/No
##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 305610

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
#for sex stratified grey out sex covariate
#library(survival)
colnames<-grep("^VV[0-9]+",names(X[[1]]))
my_lms <- lapply(X[[1]][colnames], function(x) lm(X[[1]]$weekly_units_B_R ~ x + X[[1]]$Sex_F+ 
                                                    X[[1]]$array_type+ X[[1]]$Age.at.recruitment + X[[1]]$Genetic.principal.components...Array.1+ X[[1]]$Genetic.principal.components...Array.2+ X[[1]]$Genetic.principal.components...Array.3+ X[[1]]$Genetic.principal.components...Array.4+ X[[1]]$Genetic.principal.components...Array.5+ X[[1]]$Genetic.principal.components...Array.6+ X[[1]]$Genetic.principal.components...Array.7+ X[[1]]$Genetic.principal.components...Array.8+ X[[1]]$Genetic.principal.components...Array.9+ X[[1]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[1]]$T2dX_at_BL)
my_lms2 <- lapply(X[[1]][colnames], function(x) lm(X[[1]]$HbA1c_BL_winsor ~ x + X[[1]]$Sex_F+ 
                                                        X[[1]]$array_type+ X[[1]]$Age.at.recruitment + X[[1]]$Genetic.principal.components...Array.1+ X[[1]]$Genetic.principal.components...Array.2+ X[[1]]$Genetic.principal.components...Array.3+ X[[1]]$Genetic.principal.components...Array.4+ X[[1]]$Genetic.principal.components...Array.5+ X[[1]]$Genetic.principal.components...Array.6+ X[[1]]$Genetic.principal.components...Array.7+ X[[1]]$Genetic.principal.components...Array.8+ X[[1]]$Genetic.principal.components...Array.9+ X[[1]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
names(dfby)

library(MendelianRandomization)
MRInputObject1 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error) #ok so this worked for the first strata; but before continuing check whether want to exponentiate first -> ok so can see from AMY sumnlmr create summary code that they take the se as the unexponentiated, unclear exactly where the beta itself comes from... in any case, confirmed by looking in summ_covar_FULL_T2D_COX that at that stage the Y-G betas are STILL unexponentiated because some of them are negative  by[j] <- model$coef[1] byse[j] <- summary(model)$coef[1, 3]
colnames<-grep("^VV[0-9]+",names(X[[2]]))
my_lms <- lapply(X[[2]][colnames], function(x) lm(X[[2]]$weekly_units_B_R ~ x + X[[2]]$Sex_F+ 
                                                    X[[2]]$array_type+ X[[2]]$Age.at.recruitment + X[[2]]$Genetic.principal.components...Array.1+ X[[2]]$Genetic.principal.components...Array.2+ X[[2]]$Genetic.principal.components...Array.3+ X[[2]]$Genetic.principal.components...Array.4+ X[[2]]$Genetic.principal.components...Array.5+ X[[2]]$Genetic.principal.components...Array.6+ X[[2]]$Genetic.principal.components...Array.7+ X[[2]]$Genetic.principal.components...Array.8+ X[[2]]$Genetic.principal.components...Array.9+ X[[2]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[2]]$T2dX_at_BL)
my_lms2 <- lapply(X[[2]][colnames], function(x) lm(X[[2]]$HbA1c_BL_winsor ~ x + X[[2]]$Sex_F+ 
                                                        X[[2]]$array_type+ X[[2]]$Age.at.recruitment + X[[2]]$Genetic.principal.components...Array.1+ X[[2]]$Genetic.principal.components...Array.2+ X[[2]]$Genetic.principal.components...Array.3+ X[[2]]$Genetic.principal.components...Array.4+ X[[2]]$Genetic.principal.components...Array.5+ X[[2]]$Genetic.principal.components...Array.6+ X[[2]]$Genetic.principal.components...Array.7+ X[[2]]$Genetic.principal.components...Array.8+ X[[2]]$Genetic.principal.components...Array.9+ X[[2]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject2 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[3]]))
my_lms <- lapply(X[[3]][colnames], function(x) lm(X[[3]]$weekly_units_B_R ~ x + X[[3]]$Sex_F+ 
                                                    X[[3]]$array_type+ X[[3]]$Age.at.recruitment + X[[3]]$Genetic.principal.components...Array.1+ X[[3]]$Genetic.principal.components...Array.2+ X[[3]]$Genetic.principal.components...Array.3+ X[[3]]$Genetic.principal.components...Array.4+ X[[3]]$Genetic.principal.components...Array.5+ X[[3]]$Genetic.principal.components...Array.6+ X[[3]]$Genetic.principal.components...Array.7+ X[[3]]$Genetic.principal.components...Array.8+ X[[3]]$Genetic.principal.components...Array.9+ X[[3]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[3]]$T2dX_at_BL)
my_lms2 <- lapply(X[[3]][colnames], function(x) lm(X[[3]]$HbA1c_BL_winsor ~ x + X[[3]]$Sex_F+ 
                                                        X[[3]]$array_type+ X[[3]]$Age.at.recruitment + X[[3]]$Genetic.principal.components...Array.1+ X[[3]]$Genetic.principal.components...Array.2+ X[[3]]$Genetic.principal.components...Array.3+ X[[3]]$Genetic.principal.components...Array.4+ X[[3]]$Genetic.principal.components...Array.5+ X[[3]]$Genetic.principal.components...Array.6+ X[[3]]$Genetic.principal.components...Array.7+ X[[3]]$Genetic.principal.components...Array.8+ X[[3]]$Genetic.principal.components...Array.9+ X[[3]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject3 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[1]]))
my_lms <- lapply(X[[4]][colnames], function(x) lm(X[[4]]$weekly_units_B_R ~ x + X[[4]]$Sex_F+ 
                                                    X[[4]]$array_type+ X[[4]]$Age.at.recruitment + X[[4]]$Genetic.principal.components...Array.1+ X[[4]]$Genetic.principal.components...Array.2+ X[[4]]$Genetic.principal.components...Array.3+ X[[4]]$Genetic.principal.components...Array.4+ X[[4]]$Genetic.principal.components...Array.5+ X[[4]]$Genetic.principal.components...Array.6+ X[[4]]$Genetic.principal.components...Array.7+ X[[4]]$Genetic.principal.components...Array.8+ X[[4]]$Genetic.principal.components...Array.9+ X[[4]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[4]]$T2dX_at_BL)
my_lms2 <- lapply(X[[4]][colnames], function(x) lm(X[[4]]$HbA1c_BL_winsor ~ x + X[[4]]$Sex_F+ 
                                                        X[[4]]$array_type+ X[[4]]$Age.at.recruitment + X[[4]]$Genetic.principal.components...Array.1+ X[[4]]$Genetic.principal.components...Array.2+ X[[4]]$Genetic.principal.components...Array.3+ X[[4]]$Genetic.principal.components...Array.4+ X[[4]]$Genetic.principal.components...Array.5+ X[[4]]$Genetic.principal.components...Array.6+ X[[4]]$Genetic.principal.components...Array.7+ X[[4]]$Genetic.principal.components...Array.8+ X[[4]]$Genetic.principal.components...Array.9+ X[[4]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject4 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[5]]))
my_lms <- lapply(X[[5]][colnames], function(x) lm(X[[5]]$weekly_units_B_R ~ x + X[[5]]$Sex_F+ 
                                                    X[[5]]$array_type+ X[[5]]$Age.at.recruitment + X[[5]]$Genetic.principal.components...Array.1+ X[[5]]$Genetic.principal.components...Array.2+ X[[5]]$Genetic.principal.components...Array.3+ X[[5]]$Genetic.principal.components...Array.4+ X[[5]]$Genetic.principal.components...Array.5+ X[[5]]$Genetic.principal.components...Array.6+ X[[5]]$Genetic.principal.components...Array.7+ X[[5]]$Genetic.principal.components...Array.8+ X[[5]]$Genetic.principal.components...Array.9+ X[[5]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[5]]$T2dX_at_BL)
my_lms2 <- lapply(X[[5]][colnames], function(x) lm(X[[5]]$HbA1c_BL_winsor ~ x + X[[5]]$Sex_F+ 
                                                        X[[5]]$array_type+ X[[5]]$Age.at.recruitment + X[[5]]$Genetic.principal.components...Array.1+ X[[5]]$Genetic.principal.components...Array.2+ X[[5]]$Genetic.principal.components...Array.3+ X[[5]]$Genetic.principal.components...Array.4+ X[[5]]$Genetic.principal.components...Array.5+ X[[5]]$Genetic.principal.components...Array.6+ X[[5]]$Genetic.principal.components...Array.7+ X[[5]]$Genetic.principal.components...Array.8+ X[[5]]$Genetic.principal.components...Array.9+ X[[5]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject5 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[6]]))
my_lms <- lapply(X[[6]][colnames], function(x) lm(X[[6]]$weekly_units_B_R ~ x + X[[6]]$Sex_F+ 
                                                    X[[6]]$array_type+ X[[6]]$Age.at.recruitment + X[[6]]$Genetic.principal.components...Array.1+ X[[6]]$Genetic.principal.components...Array.2+ X[[6]]$Genetic.principal.components...Array.3+ X[[6]]$Genetic.principal.components...Array.4+ X[[6]]$Genetic.principal.components...Array.5+ X[[6]]$Genetic.principal.components...Array.6+ X[[6]]$Genetic.principal.components...Array.7+ X[[6]]$Genetic.principal.components...Array.8+ X[[6]]$Genetic.principal.components...Array.9+ X[[6]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[6]]$T2dX_at_BL)
my_lms2 <- lapply(X[[6]][colnames], function(x) lm(X[[6]]$HbA1c_BL_winsor ~ x + X[[6]]$Sex_F+ 
                                                        X[[6]]$array_type+ X[[6]]$Age.at.recruitment + X[[6]]$Genetic.principal.components...Array.1+ X[[6]]$Genetic.principal.components...Array.2+ X[[6]]$Genetic.principal.components...Array.3+ X[[6]]$Genetic.principal.components...Array.4+ X[[6]]$Genetic.principal.components...Array.5+ X[[6]]$Genetic.principal.components...Array.6+ X[[6]]$Genetic.principal.components...Array.7+ X[[6]]$Genetic.principal.components...Array.8+ X[[6]]$Genetic.principal.components...Array.9+ X[[6]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject6 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[7]]))
my_lms <- lapply(X[[7]][colnames], function(x) lm(X[[7]]$weekly_units_B_R ~ x + X[[7]]$Sex_F+ 
                                                    X[[7]]$array_type+ X[[7]]$Age.at.recruitment + X[[7]]$Genetic.principal.components...Array.1+ X[[7]]$Genetic.principal.components...Array.2+ X[[7]]$Genetic.principal.components...Array.3+ X[[7]]$Genetic.principal.components...Array.4+ X[[7]]$Genetic.principal.components...Array.5+ X[[7]]$Genetic.principal.components...Array.6+ X[[7]]$Genetic.principal.components...Array.7+ X[[7]]$Genetic.principal.components...Array.8+ X[[7]]$Genetic.principal.components...Array.9+ X[[7]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[7]]$T2dX_at_BL)
my_lms2 <- lapply(X[[7]][colnames], function(x) lm(X[[7]]$HbA1c_BL_winsor ~ x + X[[7]]$Sex_F+ 
                                                        X[[7]]$array_type+ X[[7]]$Age.at.recruitment + X[[7]]$Genetic.principal.components...Array.1+ X[[7]]$Genetic.principal.components...Array.2+ X[[7]]$Genetic.principal.components...Array.3+ X[[7]]$Genetic.principal.components...Array.4+ X[[7]]$Genetic.principal.components...Array.5+ X[[7]]$Genetic.principal.components...Array.6+ X[[7]]$Genetic.principal.components...Array.7+ X[[7]]$Genetic.principal.components...Array.8+ X[[7]]$Genetic.principal.components...Array.9+ X[[7]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject7 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[8]]))
my_lms <- lapply(X[[8]][colnames], function(x) lm(X[[8]]$weekly_units_B_R ~ x + X[[8]]$Sex_F+ 
                                                    X[[8]]$array_type+ X[[8]]$Age.at.recruitment + X[[8]]$Genetic.principal.components...Array.1+ X[[8]]$Genetic.principal.components...Array.2+ X[[8]]$Genetic.principal.components...Array.3+ X[[8]]$Genetic.principal.components...Array.4+ X[[8]]$Genetic.principal.components...Array.5+ X[[8]]$Genetic.principal.components...Array.6+ X[[8]]$Genetic.principal.components...Array.7+ X[[8]]$Genetic.principal.components...Array.8+ X[[8]]$Genetic.principal.components...Array.9+ X[[8]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[8]]$T2dX_at_BL)
my_lms2 <- lapply(X[[8]][colnames], function(x) lm(X[[8]]$HbA1c_BL_winsor ~ x + X[[8]]$Sex_F+ 
                                                        X[[8]]$array_type+ X[[8]]$Age.at.recruitment + X[[8]]$Genetic.principal.components...Array.1+ X[[8]]$Genetic.principal.components...Array.2+ X[[8]]$Genetic.principal.components...Array.3+ X[[8]]$Genetic.principal.components...Array.4+ X[[8]]$Genetic.principal.components...Array.5+ X[[8]]$Genetic.principal.components...Array.6+ X[[8]]$Genetic.principal.components...Array.7+ X[[8]]$Genetic.principal.components...Array.8+ X[[8]]$Genetic.principal.components...Array.9+ X[[8]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject8 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[9]]))
my_lms <- lapply(X[[9]][colnames], function(x) lm(X[[9]]$weekly_units_B_R ~ x + X[[9]]$Sex_F+ 
                                                    X[[9]]$array_type+ X[[9]]$Age.at.recruitment + X[[9]]$Genetic.principal.components...Array.1+ X[[9]]$Genetic.principal.components...Array.2+ X[[9]]$Genetic.principal.components...Array.3+ X[[9]]$Genetic.principal.components...Array.4+ X[[9]]$Genetic.principal.components...Array.5+ X[[9]]$Genetic.principal.components...Array.6+ X[[9]]$Genetic.principal.components...Array.7+ X[[9]]$Genetic.principal.components...Array.8+ X[[9]]$Genetic.principal.components...Array.9+ X[[9]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[9]]$T2dX_at_BL)
my_lms2 <- lapply(X[[9]][colnames], function(x) lm(X[[9]]$HbA1c_BL_winsor ~ x + X[[9]]$Sex_F+ 
                                                        X[[9]]$array_type+ X[[9]]$Age.at.recruitment + X[[9]]$Genetic.principal.components...Array.1+ X[[9]]$Genetic.principal.components...Array.2+ X[[9]]$Genetic.principal.components...Array.3+ X[[9]]$Genetic.principal.components...Array.4+ X[[9]]$Genetic.principal.components...Array.5+ X[[9]]$Genetic.principal.components...Array.6+ X[[9]]$Genetic.principal.components...Array.7+ X[[9]]$Genetic.principal.components...Array.8+ X[[9]]$Genetic.principal.components...Array.9+ X[[9]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject9 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x + X[[10]]$Sex_F+ 
                                                    X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$HbA1c_BL_winsor ~ x + X[[10]]$Sex_F+ 
                                                        X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject10 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

#and then once run below for a given sens test (just sub out med for IVW etc), add columns to LACESUM[["coefficients"]] which are from the main results (or make a list of them instead?) -> actually only works for median and IVW, for RAPS PRESSO and weighted mode will have to use other packages because Mendelian Randomisation package doesn't include them


med1<-MendelianRandomization::mr_median(MRInputObject1)
med1 #interesting much smaller/non-sig decrease
med2<-MendelianRandomization::mr_median(MRInputObject2)
med2
med3<-MendelianRandomization::mr_median(MRInputObject3)
med3
med4<-MendelianRandomization::mr_median(MRInputObject4)
med4 
med5<-MendelianRandomization::mr_median(MRInputObject5)
med5
med6<-MendelianRandomization::mr_median(MRInputObject6)
med6
med7<-MendelianRandomization::mr_median(MRInputObject7)
med7
med8<-MendelianRandomization::mr_median(MRInputObject8)
med8 
med9<-MendelianRandomization::mr_median(MRInputObject9)
med9 
med10<-MendelianRandomization::mr_median(MRInputObject10)
med10 #this one is sig positive
summary(med10)

medres1<-c(med1@Estimate,med1@StdError,med1@CILower,med1@CIUpper,med1@Pvalue)
medres2<-c(med2@Estimate,med2@StdError,med2@CILower,med2@CIUpper,med2@Pvalue)
medres3<-c(med3@Estimate,med3@StdError,med3@CILower,med3@CIUpper,med3@Pvalue)
medres4<-c(med4@Estimate,med4@StdError,med4@CILower,med4@CIUpper,med4@Pvalue)
medres5<-c(med5@Estimate,med5@StdError,med5@CILower,med5@CIUpper,med5@Pvalue)
medres6<-c(med6@Estimate,med6@StdError,med6@CILower,med6@CIUpper,med6@Pvalue)
medres7<-c(med7@Estimate,med7@StdError,med7@CILower,med7@CIUpper,med7@Pvalue)
medres8<-c(med8@Estimate,med8@StdError,med8@CILower,med8@CIUpper,med8@Pvalue)
medres9<-c(med9@Estimate,med9@StdError,med9@CILower,med9@CIUpper,med9@Pvalue)
medres10<-c(med10@Estimate,med10@StdError,med10@CILower,med10@CIUpper,med10@Pvalue)

medRES<-t(data.frame(medres1,medres2,medres3,medres4,medres5,medres6,medres7,medres8,medres9,medres10))
medRES<-data.frame(medRES) #24.05 adding covariates seems to have attenuated results for both med and median, only slightly

#ok now to do the other methods using the twosampleMR package
library(TwoSampleMR)
SNPSdf1<-cbind(MRInputObject1$betaX,MRInputObject1$betaXse,MRInputObject1$betaY,MRInputObject1$betaYse)
SNPSdf1<-data.frame(SNPSdf1)
colnames(SNPSdf1)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf1<-SNPSdf1 %>% mutate(SNP=1:79)
SNPSdf1<-SNPSdf1 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf1<-SNPSdf1 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf2<-cbind(MRInputObject2$betaX,MRInputObject2$betaXse,MRInputObject2$betaY,MRInputObject2$betaYse)
SNPSdf2<-data.frame(SNPSdf2)
colnames(SNPSdf2)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf2<-SNPSdf2 %>% mutate(SNP=1:79)
SNPSdf2<-SNPSdf2 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf2<-SNPSdf2 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf3<-cbind(MRInputObject3$betaX,MRInputObject3$betaXse,MRInputObject3$betaY,MRInputObject3$betaYse)
SNPSdf3<-data.frame(SNPSdf3)
colnames(SNPSdf3)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf3<-SNPSdf3 %>% mutate(SNP=1:79)
SNPSdf3<-SNPSdf3 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf3<-SNPSdf3 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf4<-cbind(MRInputObject4$betaX,MRInputObject4$betaXse,MRInputObject4$betaY,MRInputObject4$betaYse)
SNPSdf4<-data.frame(SNPSdf4)
colnames(SNPSdf4)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf4<-SNPSdf4 %>% mutate(SNP=1:79)
SNPSdf4<-SNPSdf4 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf4<-SNPSdf4 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf5<-cbind(MRInputObject5$betaX,MRInputObject5$betaXse,MRInputObject5$betaY,MRInputObject5$betaYse)
SNPSdf5<-data.frame(SNPSdf5)
colnames(SNPSdf5)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf5<-SNPSdf5 %>% mutate(SNP=1:79)
SNPSdf5<-SNPSdf5 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf5<-SNPSdf5 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf6<-cbind(MRInputObject6$betaX,MRInputObject6$betaXse,MRInputObject6$betaY,MRInputObject6$betaYse)
SNPSdf6<-data.frame(SNPSdf6)
colnames(SNPSdf6)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf6<-SNPSdf6 %>% mutate(SNP=1:79)
SNPSdf6<-SNPSdf6 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf6<-SNPSdf6 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf7<-cbind(MRInputObject7$betaX,MRInputObject7$betaXse,MRInputObject7$betaY,MRInputObject7$betaYse)
SNPSdf7<-data.frame(SNPSdf7)
colnames(SNPSdf7)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf7<-SNPSdf7 %>% mutate(SNP=1:79)
SNPSdf7<-SNPSdf7 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf7<-SNPSdf7 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf8<-cbind(MRInputObject8$betaX,MRInputObject8$betaXse,MRInputObject8$betaY,MRInputObject8$betaYse)
SNPSdf8<-data.frame(SNPSdf8)
colnames(SNPSdf8)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf8<-SNPSdf8 %>% mutate(SNP=1:79)
SNPSdf8<-SNPSdf8 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf8<-SNPSdf8 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf9<-cbind(MRInputObject9$betaX,MRInputObject9$betaXse,MRInputObject9$betaY,MRInputObject9$betaYse)
SNPSdf9<-data.frame(SNPSdf9)
colnames(SNPSdf9)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf9<-SNPSdf9 %>% mutate(SNP=1:79)
SNPSdf9<-SNPSdf9 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf9<-SNPSdf9 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf10<-cbind(MRInputObject10$betaX,MRInputObject10$betaXse,MRInputObject10$betaY,MRInputObject10$betaYse)
SNPSdf10<-data.frame(SNPSdf10)
colnames(SNPSdf10)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf10<-SNPSdf10 %>% mutate(SNP=1:79)
SNPSdf10<-SNPSdf10 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf10<-SNPSdf10 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf<-list(SNPSdf1,SNPSdf2,SNPSdf3,SNPSdf4,SNPSdf5,SNPSdf6,SNPSdf7,SNPSdf8,SNPSdf9,SNPSdf10)

#weighted mode
my_lms <- lapply(SNPSdf, function(x) mr_weighted_mode(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$b-(1.96*x$se);x$upperCI<-x$b+(1.96*x$se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
modeRES<-as.data.frame(do.call(rbind,add_CIs))
modeRES<-modeRES %>% select(b,se,lowerCI,upperCI,pval) #DONE!
class(modeRES)
class(modeRES$b)
modeRES2<- unnest(modeRES,b) %>% unnest(modeRES,se) %>% unnest(modeRES,lowerCI) %>% unnest(modeRES,upperCI) %>% unnest(modeRES,pval) #none are now sig once incorp covariates
class(modeRES2$se)

#raps
my_lms <- lapply(SNPSdf, function(x) mr.raps::mr.raps(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome, diagnosis=TRUE)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$beta.hat-(1.96*x$beta.se);x$upperCI<-x$beta.hat+(1.96*x$beta.se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
rapsRES<-as.data.frame(do.call(rbind,add_CIs))
rapsRES<-rapsRES %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value) #DONE!
rapsRES2<- unnest(rapsRES,beta.hat) %>% unnest(rapsRES,beta.se) %>% unnest(rapsRES,lowerCI) %>% unnest(rapsRES,upperCI) %>% unnest(rapsRES,beta.p.value) 
class(rapsRES2$beta.se)

#finally presso
my_lms <- lapply(SNPSdf, function(x) run_mr_presso(x, NbDistribution = 2500, SignifThreshold = 0.05)) 
#all 10 global tests >.05, therefore no outlier corrected estmates produced
#24.05 same for when added covariates; 25.05 same for females; same for males EXCEPT stratum 9, but then no sig outliers could be found
#25.05 THERE ARE OUTLIER CORRECTED RESULTS FOR HBAIC main results (except for starat 2 and 10 where no sig outliers were detected) -> so need to pull outlier corrected estimtes for the other 8 strata and make mr presso results
presso_hba1c_results_1<-c(my_lms[[1]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[1]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[1]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_2<-c(my_lms[[2]][[1]][["Main MR results"]][["Causal Estimate"]][[1]], my_lms[[2]][[1]][["Main MR results"]][["Sd"]][[1]], my_lms[[2]][[1]][["Main MR results"]][["P-value"]][[1]]) #note dif
presso_hba1c_results_3<-c(my_lms[[3]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[3]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[3]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_4<-c(my_lms[[4]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[4]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[4]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_5<-c(my_lms[[5]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[5]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[5]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_6<-c(my_lms[[6]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[6]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[6]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_7<-c(my_lms[[7]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[7]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[7]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_8<-c(my_lms[[8]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[8]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[8]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_9<-c(my_lms[[9]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[9]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[9]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_10<-c(my_lms[[10]][[1]][["Main MR results"]][["Causal Estimate"]][[1]], my_lms[[10]][[1]][["Main MR results"]][["Sd"]][[1]], my_lms[[10]][[1]][["Main MR results"]][["P-value"]][[1]]) #note dif

pressoRES<-data.frame(rbind(presso_hba1c_results_1,presso_hba1c_results_2,presso_hba1c_results_3,presso_hba1c_results_4,presso_hba1c_results_5,presso_hba1c_results_6,presso_hba1c_results_7,presso_hba1c_results_8,presso_hba1c_results_9,presso_hba1c_results_10))
pressoRES2<-pressoRES %>% mutate(lowerCI=X1-(1.96*X2)) %>% mutate(upperCI=X1+(1.96*X2))
pressoRES2<-pressoRES2 %>% select(X1,X2,lowerCI,upperCI,X3) #rearrange col order


HBA1C_FOURxsensresultsCOV<-list(ivwRES,medRES,modeRES2,rapsRES2,pressoRES2)
saveRDS(HBA1C_FOURxsensresultsCOV, file="HBA1C_FOURxsensresultsCOV.rds")
saveRDS(HBA1C_FOURxsensresultsCOV, file="HBA1C_FOURxsensresultsCOV.RData")
HBA1C_FOURxsensresultsCOV<-readRDS("HBA1C_FOURxsensresultsCOV.rds") 

HBA1C_FOURxsensresultsCOV[[3]]<-HBA1C_FOURxsensresultsCOV[[3]] %>% select(b,se,lowerCI,upperCI,pval)
HBA1C_FOURxsensresultsCOV[[4]]<-HBA1C_FOURxsensresultsCOV[[4]] %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value)
#so now have LACEs in there with variance/CIs, need to add the mean x for each stratum now so that can figure out how to do fractional polynomial
#actually can just calculate by hand
mean1<-mean(X[[1]]$weekly_units_B_R)
mean2<-mean(X[[2]]$weekly_units_B_R)
mean3<-mean(X[[3]]$weekly_units_B_R)
mean4<-mean(X[[4]]$weekly_units_B_R)
mean5<-mean(X[[5]]$weekly_units_B_R)
mean6<-mean(X[[6]]$weekly_units_B_R)
mean7<-mean(X[[7]]$weekly_units_B_R)
mean8<-mean(X[[8]]$weekly_units_B_R)
mean9<-mean(X[[9]]$weekly_units_B_R)
mean10<-mean(X[[10]]$weekly_units_B_R)
Xmeans<-c(mean1,mean2,mean3,mean4,mean5,mean6,mean7,mean8,mean9,mean10)#now attach these back to sensitivity results
HBA1C_FOURxsensresultsCOV2<-lapply(HBA1C_FOURxsensresultsCOV, function(x) cbind(x, Xmeans)) #EXCELLENT! now see if can feed into the NLMR package to generate plots
devtools::install_github("jrs95/nlmr")
library(nlmr)
ls("package:nlmr") #so that fracpoly_best function IS here, need to see what's in it
View(nlmr::fracpoly_best) #excellent -> this opens the function in a separate tab, and unlike the sumNLMR equivalent only needs the values for LACE, se and xmeans rather than the individual bx by stats (which force the function to use ratio method) -> want to use argument d="both"
```


```{r}
 ##### Best-fitting fractional polynomial #####
  fracpb <- nlmr::fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[1]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[1]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[1]]$Xmeans, d="both", pd=.05, method="FE")
  #so p1_ML is best fitting of degree 1, p2_ML is best fitting of degree 2; fp_p is p value for a first degree fp over linear; fp_d12_p is for degree 2 over degree 1, not sure what p_ML is though??? (eg for first one - IVW - p_ML is -2 whereas p1_ML is -1 and p2_ML is -.5)->>>> AHHHH this is wrong! p_ML is degree 1, p1_ML and p2_ML relate to the best fitting second degree (ie the two fractions that compose best fitting second degree polynomial) -> not significant in this case anyway
#GOOD news is tht didn't use bootstrapped CIs/ses for main nlmr analyses fracpoly (only for piecewise), so don't need to calclate here (which for some reason requires the x and y and g stats)
model <- fracpb$model; p_ML <- fracpb$p_ML; p1_ML <- fracpb$p1_ML; p2_ML <- fracpb$p2_ML; fp_p <- fracpb$fp_p; fp_d12_p <- fracpb$fp_d12_p
  d <- fracpb$d
    ##### Non-linearity tests #####
  #library(metafor)
  p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[1]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[1]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[1]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[1]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[1]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
  #and to make figure
  
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
  

     #View(nlmr::fracpoly_figure)
     
     ###AHHHH ok below need to supply mean of lowest stratum as xmin and mean of highest stratum as xmax, not the literal highest and lowest x values! for hba1c: 1.33 and 53.74 for overall;  for women;  for men
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1.5, p1_ML=-1, p2_ML=1, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional polynoial degrees from the actual data, apart from that the shape is just generic! so what I'll do is simply generate the polynomial tests and list of LACEs, and won't make the plots!!!
   #ohhhh my GOD I GOT THE GFIGURE WORKING!!! -well the CIs are still a little weird on the left hand side; have edited the function foior now to remove CIs s can see line better -> weird that doesn't properly align with the Xmean for lowest caeory -> I think the nlmr package must plot in a sep way
  
   #do for sensitivity 2-4 (median,mode,RAPS) -> one above is IVW
    library(nlmr)
    fracpbMEDIAN <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[2]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[2]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[2]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbMEDIAN$model; p_ML <- fracpbMEDIAN$p_ML; p1_ML <- fracpbMEDIAN$p1_ML; p2_ML <- fracpbMEDIAN$p2_ML; fp_p <- fracpbMEDIAN$fp_p; fp_d12_p <- fracpbMEDIAN$fp_d12_p
  d <- fracpbMEDIAN$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[2]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[2]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[2]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[2]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[2]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=1, p_ML=-1.5, p1_ML=NULL, p2_ML=-NULL, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  
    fracpbmode <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[3]][["b"]], coef_se=HBA1C_FOURxsensresultsCOV2[[3]][["se"]], xmean=HBA1C_FOURxsensresultsCOV2[[3]]$Xmeans, d="both", pd=.05, method="FE")
        model <- fracpbmode$model; p_ML <- fracpbmode$p_ML; p1_ML <- fracpbmode$p1_ML; p2_ML <- fracpbmode$p2_ML; fp_p <- fracpbmode$fp_p; fp_d12_p <- fracpbmode$fp_d12_p
  d <- fracpbmode$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[3]][["b"]] ~ HBA1C_FOURxsensresultsCOV2[[3]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[3]][["se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[3]][["b"]], vi=(HBA1C_FOURxsensresultsCOV2[[3]][["se"]])^2)$QE, df=(10-1))
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=1, p_ML=-1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
    
    
     fracpbraps <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]], coef_se=HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]], xmean=HBA1C_FOURxsensresultsCOV2[[4]]$Xmeans, d="both", pd=.05, method="FE")
      model <- fracpbraps$model; p_ML <- fracpbraps$p_ML; p1_ML <- fracpbraps$p1_ML; p2_ML <- fracpbraps$p2_ML; fp_p <- fracpbraps$fp_p; fp_d12_p <- fracpbraps$fp_d12_p
  d <- fracpbraps$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]] ~ HBA1C_FOURxsensresultsCOV2[[4]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]], vi=(HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]])^2)$QE, df=(10-1))
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1.5, p1_ML=-1, p2_ML=1, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional 
     
    
     fracpbPRESSO <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[5]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[5]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[5]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbPRESSO$model; p_ML <- fracpbPRESSO$p_ML; p1_ML <- fracpbPRESSO$p1_ML; p2_ML <- fracpbPRESSO$p2_ML; fp_p <- fracpbPRESSO$fp_p; fp_d12_p <- fracpbPRESSO$fp_d12_p
  d <- fracpbPRESSO$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[5]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[5]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[5]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[5]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[5]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1, p1_ML=-1, p2_ML=2, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  

```




Upload RStudio project onto RAP storage.

```{r}
#system("dx-backup-folder -d /.Backups/rstudio_webinar.tar.gz")

#RV editing
system("dx-backup-folder")
```

  #for hba1c it's -0.0341956; CIs: -0.0417091676 -0.026681996
  #for T2D it's 0.001348; CIs: -0.005400848  0.008096246 > need to exponentiate these
  TSLS_main_T2D<-exp(c(0.001111 , -0.005760410,  0.007982028))
TSLS_main_HbA1C<-c(-0.018520,-0.0285250004, -0.008514135)


  

  #and excluding ex-drinkers (not really that appropriate since the 2 sample can't do that)
 df_LA_DR_noD<-df_noD %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=df_LA_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=df_LA_DR) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA_DR)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
    #LIU SENSITIVITY version including covariates
   fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS2+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX 
  confint(fitIV_ts) 

 df_LA_DR_noD<-update_pp679 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, family="gaussian",data=df_LA_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS2+ Sex_F+ array_type+ Age.at.recruitment + Genetic.principal.components...Array.1+Genetic.principal.components...Array.2+Genetic.principal.components...Array.3+Genetic.principal.components...Array.4+Genetic.principal.components...Array.5+Genetic.principal.components...Array.6+Genetic.principal.components...Array.7+Genetic.principal.components...Array.8+Genetic.principal.components...Array.9+Genetic.principal.components...Array.10, data=df_LA_DR_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA_DR)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  
  #let's see what happens when do separately in drinkers, non-drinkers etc
  #first: never drinkers -> DOESN'T WORK! as predicted
  df_LA_noD<-df_noD %>% filter(BL_drinker_status=="Never")
   fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=df_LA) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_LA_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  #now, drinkers -> this does work (makes sense), again, a non-sig relationship when restrict to linear
  df_DR_noD<-df_noD %>% filter(BL_drinker_status=="Current")
   fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=df_DR) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_DR_noD) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=df_LA)
  summary(fitIV_ts) 
  confint(fitIV_ts)
  
  #now HbA1c
  fitY.LX <- glm(formula=HbA1c_BL_winsor~weekly_units_B_R,data=update_pp679) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=update_pp679) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679)
  summary(fitIV_ts) ###as when using ivreg package, the estimate is -.036 (very significant)
  confint(fitIV_ts)
 
#using Haodong's code (from MendelianRandomization package)
#see if can repllicate PlosOne paper results for HBA1C and T2D (using both IVW and 2SLS methods); use Haodong IVW code/MendelianRandomization package R
#theirs is on the WHOLE sample
#I think Haodong's approahc to use GRS in IVW instead of idnidivusla variants is acceptable
#-> NO ACTUALLY I THINK NEED TO ENTER THEM SEPARATELY (but see notes that it's ok for 2SLS/other 2 stage)
#do fitGX in controls only >UPDATE HAODONG SAYS IVW/2SLS basically interchangeable here, can just use GRS
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) 
update_pp679 %>% count(T2dX_at_BL)

summary(fitGX)
fitGX<-lm(    df_noD$weekly_units_B_R~  df_noD$GRS_79 +df_noD$Sex_F+df_noD$array_type+ df_noD$Age.at.recruitment +  df_noD$Genetic.principal.components...Array.1+df_noD$Genetic.principal.components...Array.2+df_noD$Genetic.principal.components...Array.3+df_noD$Genetic.principal.components...Array.4+df_noD$Genetic.principal.components...Array.5+df_noD$Genetic.principal.components...Array.6+df_noD$Genetic.principal.components...Array.7+df_noD$Genetic.principal.components...Array.8+df_noD$Genetic.principal.components...Array.9+df_noD$Genetic.principal.components...Array.10);bGX<-summary(fitGX)$coef[2,1] ;seGX<- summary(fitGX)$coef[2,2] ; bx<-as.numeric( bGX  ); bxse<-as.numeric(  seGX)
summary(fitGY)
fitGY<-glm( update_pp679$T2dX_at_BL~  update_pp679$GRS +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10,family="binomial" );bGY<-summary(fitGY)$coef[2,1] ;seGY<-summary(fitGY)$coef[2,2] ; by<-as.numeric( bGY  ); byse<-as.numeric(  seGY)
#hmm so the above shows a neg relationship which is why the IVW estimates aren't as expected
# below I'm going to run the above in higher strata and see what happens

library(MendelianRandomization)
IVW_res<-mr_ivw(mr_input(bx, bxse, by, byse))
#now redoing for hba1c, then run above line again
fitGX<-lm(    update_pp679$weekly_units_B_R~  update_pp679$GRS_79 +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10);bGX<-summary(fitGX)$coef[2,1] ;seGX<- summary(fitGX)$coef[2,2] ; bx<-as.numeric( bGX  ); bxse<-as.numeric(  seGX)
fitGY<-lm( update_pp679$HbA1c_BL_winsor~  update_pp679$GRS +update_pp679$Sex_F+update_pp679$array_type+ update_pp679$Age.at.recruitment +  update_pp679$Genetic.principal.components...Array.1+update_pp679$Genetic.principal.components...Array.2+update_pp679$Genetic.principal.components...Array.3+update_pp679$Genetic.principal.components...Array.4+update_pp679$Genetic.principal.components...Array.5+update_pp679$Genetic.principal.components...Array.6+update_pp679$Genetic.principal.components...Array.7+update_pp679$Genetic.principal.components...Array.8+update_pp679$Genetic.principal.components...Array.9+update_pp679$Genetic.principal.components...Array.10 );bGY<-summary(fitGY)$coef[2,1];seGY<-summary(fitGY)$coef[2,2] ; by<-as.numeric( bGY  ); byse<-as.numeric(  seGY) #differs only slightly from the 2SLS method

IVW_main_T2D<-exp(c(IVW_res@Estimate, IVW_res@CILower, IVW_res@CIUpper))
IVW_main_HbA1C<-c(IVW_res@Estimate, IVW_res@CILower, IVW_res@CIUpper)

#10.05 SNP-based one sample linear -> NO EGGER!
#update 19.05 so that G-X is only calculated in controls!
str_sort(names(update_pp679))
df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) 
#ok first make MR input object
colnames<-grep("^VV[0-9]+",names(update_pp679))
my_lms <- lapply(df_noD[colnames], function(x) lm(df_noD$weekly_units_B_R ~ x)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but not just in controls!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679[colnames], function(x) glm(update_pp679$T2dX_at_BL ~ x, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()

#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")
library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_T2D_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
#presso_T2D_results<-c( "MR PRESSO",  res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#ahh ok presso detected no outliers, tehrefore did not conduct outlier corrected estimate test (still true when changed g-x to calc in controls only; in fact then the global test wasn't sig p=.58) https://github.com/rondolab/MR-PRESSO/issues/9

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS)
res2_T2D<-data.frame(res2)
class(res2_T2D$b)
res2_T2D[] <- lapply(res2_T2D, unlist)
res2_T2D<-generate_odds_ratios(res2_T2D) #ExCELLENT!!! all worked
```


```{r}
#now repeat above but split by sex (won't be able to join on to two sample results since can't split those by sex); but will need to repeat the GRS-based TSLS estimate split by sex -> START HERE 18.05
library(tidyverse)

update_pp679<-update_pp679 %>% dplyr::mutate(Sex_F=as.factor(Sex))
  update_pp679 <-update_pp679 %>% mutate(array_type=case_when(grepl("UKBiLEVEAX", Genotype.measurement.batch)~"UKBiLEVEAX", TRUE ~"Affy"))
update_pp679_F<-update_pp679 %>% filter(Sex_F=="Female")
update_pp679_M<-update_pp679 %>% filter(Sex_F=="Male")

#19.05 fix below so only calculating G-X in controls
df_noD_F<-update_pp679_F %>% filter(T2dX_at_BL==0)
df_noD_M<-update_pp679_M %>% filter(T2dX_at_BL==0)

colnames<-grep("^VV[0-9]+",names(update_pp679_M))
my_lms <- lapply(df_noD_M[colnames], function(x) lm(df_noD_M$weekly_units_B_R ~ x)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (not just in controls though!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679_M[colnames], function(x) glm(update_pp679_M$T2dX_at_BL ~ x, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()

#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")
#library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_T2D_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
#presso_T2D_results<-c( "MR PRESSO",  res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#ahh ok FOR COMBINED SAMPLE presso detected no outliers, tehrefore did not conduct outlier corrected estimate test https://github.com/rondolab/MR-PRESSO/issues/9
#within women the MR presso global test wasn't even significant p=.62 (g-x in controls)
#within men the global test was sig, but no sig outliers


#and TSLS estimate
library(ivtools)

 fitY.LX <- glm(formula=T2dX_at_BL~weekly_units_B_R, family="binomial",data=update_pp679_F) #second stage model
 fitX.LZ <- glm(formula=weekly_units_B_R~GRS, data=df_noD_F) #first stage model
  fitIV_ts <- ivglm(estmethod="ts", fitX.LZ=fitX.LZ, fitY.LX=fitY.LX, data=update_pp679_F)
  summary(fitIV_ts) ###AHHH VERY INTERSTING, it's a non-sig relationship when linear! for T2DX not much there at all really
  confint(fitIV_ts)

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS)
res2_T2D<-data.frame(res2)
class(res2_T2D$b)
res2_T2D[] <- lapply(res2_T2D, unlist)
res2_T2D<-generate_odds_ratios(res2_T2D)


```

###then do the same for Hba1c
```{r}
#10.05 SNP-based one sample linear -> NO EGGER!

#str_sort(names(update_pp679))
#df_noD<-update_pp679 %>% filter(T2dX_at_BL==0) 
#ok first make MR input object
colnames<-grep("^VV[0-9]+",names(update_pp679))
my_lms <- lapply(update_pp679[colnames], function(x) lm(update_pp679$weekly_units_B_R ~ x)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but not just in controls!)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(update_pp679[colnames], function(x) glm(update_pp679$HbA1c_BL_winsor ~ x, family="gaussian")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()

#hmm actally want to use the 2 sample MR package instead since I already have code
#library(MendelianRandomization)
#MRInputObject <- mr_input(bx = dfbx$Estimate,
#bxse = dfbx$Std..Error,
#by = dfby$Estimate,
#byse = dfby$Std..Error)
SNPSdf<-cbind(dfbx$Estimate,dfbx$Std..Error,dfby$Estimate,dfby$Std..Error)
SNPSdf<-data.frame(SNPSdf)
colnames(SNPSdf)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf<-SNPSdf %>% mutate(SNP=1:79)
SNPSdf<-SNPSdf %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="HbA1C") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf<-SNPSdf %>% mutate(exposure="alcohol") %>% mutate(outcome="HbA1C")
#library(TwoSampleMR)
#res<-mr(SNPSdf, method_list = c("mr_ivw", "mr_weighted_median", "mr_weighted_mode")) #argh not working, ok just run each method individually
resIVW<-mr_ivw(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resIVW<-generate_odds_ratios(resIVW) #as expected!
#continue from here 10.05
#18.05
resWEIGHTMODE<-mr_weighted_mode(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMODE<-generate_odds_ratios(resWEIGHTMODE)
resWEIGHTMEDIAN<-mr_weighted_median(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome)
#resWEIGHTMEDIAN<-generate_odds_ratios(resWEIGHTMEDIAN)
#now raps and presso
resRAPS<-mr.raps::mr.raps(SNPSdf$beta.exposure, SNPSdf$beta.outcome, SNPSdf$se.exposure,SNPSdf$se.outcome, diagnosis=TRUE) 
raps_HbA1C_results<-c("MR Raps", resRAPS[["beta.hat"]], resRAPS[["beta.se"]], resRAPS[["beta.p.value"]])
res_presso_wrapper<-run_mr_presso(SNPSdf, NbDistribution = 2500, SignifThreshold = 0.05)
presso_HbA1C_results<-c( res_presso_wrapper[[1]][["Main MR results"]][["Causal Estimate"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]], res_presso_wrapper[[1]][["Main MR results"]][["P-value"]][[2]])
#pressoSE<-res_presso_wrapper[[1]][["Main MR results"]][["Sd"]][[2]]/sqrt(79)
#presso_HbA1C_results[2]=pressoSE -> no, it DOES produce SE not Sd: https://github.com/rondolab/MR-PRESSO/issues/15

res2<-rbind(resIVW,resWEIGHTMEDIAN,resWEIGHTMODE, resRAPS, presso_HbA1C_results)
res2_HbA1C<-data.frame(res2)
class(res2_HbA1C$b)
res2_HbA1C[] <- lapply(res2_HbA1C, unlist)
#res2_T2D<-generate_odds_ratios(res2_T2D) #ExCELLENT!!! all worked
res2_HbA1C<-res2_HbA1C %>% mutate(lowerCI=b-(1.96*se))
res2_HbA1C<-res2_HbA1C %>% mutate(upperCI=b+(1.96*se))
```


#now try NLMR code but first recalculating GRSs by subbing in betas from Liu
```{r}
system('dx download "DrinksPerWeek.WithoutUKB.txt.gz"')
Liu_reduced = read.table(gzfile("DrinksPerWeek.WithoutUKB.txt.gz"),sep="\t")
#install.packages("janitor")
#library(tidyverse)
Liu_reduced<-Liu_reduced %>% janitor::row_to_names(row_number=1)
Liu_reduced<-Liu_reduced %>% mutate(PVALUE=as.numeric(PVALUE)) %>% mutate(BETA=as.numeric(BETA)) %>% mutate(SE=as.numeric(SE))
SNPs363<-read.csv("newGSCAN_finalSNPs_1SAMPLE.csv")
The_363<-SNPs363$SNP
Liu_reduced_matching_363SNPS<-Liu_reduced %>% filter(RSID %in% The_363)

#now save this reduced matching dataset so don't have to read that huge table in everytime
saveRDS(Liu_reduced_matching_363SNPS, file="Liu_reduced_matching_363SNPS.rds")
Liu_reduced_matching_363SNPS<-readRDS(file='Liu_reduced_matching_363SNPS.rds')
update_pp6<-readRDS(file='update_pp6.rds')
#now remove larger file from enviro
rm(Liu_reduced)

#can see that Liu is missing 38 of the sig SNPs from the 2022 GSCAN, but that will have to do
#now to recalculate the GRS - UP TO HERE 17.03

tocompare<-head(update_pp6)
Liu_reduced_matching_363SNPS<-Liu_reduced_matching_363SNPS %>% mutate(SNP=RSID)
mergedLiu<-left_join(SNPs363,Liu_reduced_matching_363SNPS,by="SNP")
mergedLiu_F<-mergedLiu %>% filter(!is.na(EFFECTIVE_N))

betas<-mergedLiu_F$BETA
X<-mergedLiu_F$X
df<-data.frame(X, betas)
class(df$X)
df<-df %>% mutate(X=as.character(X))
df$X <- sub("^", "V", df$X )
#names(rds)
X<-df$X
#https://stackoverflow.com/questions/70856361/how-to-create-a-weighted-sum-score-based-on-a-second-dataset-for-specific-variab
df2<-df[1:2,]

#library(tidyverse)
mergedLiu_df<-update_pp6 %>%
  mutate(GRS2 = rowSums(across(all_of(df$X), ~ .x * deframe(df)[[cur_column()]])))
#mergedLiu_df2<-mergedLiu_df 
#hmm this keeps quitting on me before finishing running!
#let's try the base R version of this and see if it runs instead
update_pp6$GRS2 <- as.vector(as.matrix(update_pp6[df$X]) %*% #this is telling it to cross-product the matrices
       with(df, setNames(betas, X)))
head(update_pp6$GRS2)
temp<-update_pp6 %>% select(GRS,GRS2)#YAY THIS WORKED! 
corr<-cor(update_pp6$GRS,update_pp6$GRS2)
summary(corr) #so the correlation is pretty strong! .87 -> check results anyway
#resave 19.03
saveRDS(update_pp6, file="update_pp6.rds")
#now go back and rerun all the nlmr
```

#31.03 neeed to rerun filtering code made earlier so suitable for Cox models
#also need to make a time-to-event/censoring/time-in-study variable
#01.04 -> making this into a separate file (after reading in update_pp6 above and then running the lines of code needed after re-resding in related to the sex and affy variables)

```{r}
#time to event first
#caclualte as censored according to date lost to follow up, date of death, also find date data acually goes up to (need to put censoring date as 31 May 2016 if people have not been lost to follow up/died/developed T2D before then)
#so need to make a status variable (0=does not develop T2D; 1=does develop T2D) and then a censoring date variable (equal to date of death or date lost to FU or date developed T2D, or else 31.05.16 -> use a case_when with pmin function > note that the date variables don't have true NAs but just blank text entry so need to fix this firs); then make a 'time' variable which is censoring date - date of attending assessment centre

grep("death", names(update_pp6), value = TRUE)
library(tidyverse)
library(dplyr)
temp<-update_pp6 %>% dplyr::select(ID_1,Death_date,Date.of.death...Instance.0,Date.lost.to.follow.up,first_rep_date_diab, Cohort_censor, earliest_diab, dX_at_BL,anyDmeds_BL)
update_pp6 %>% dplyr::count(T2D_by_firstocc)
update_pp6<-update_pp6 %>% dplyr::mutate(STATUS=dplyr::case_when(T2D_by_firstocc==1~1, TRUE~0))
update_pp6 %>% dplyr::count(STATUS)
update_pp6<-update_pp6 %>% dplyr::mutate(Death_date=lubridate::as_date(Date.of.death...Instance.0))
update_pp6<-update_pp6 %>% dplyr::mutate(Lost_date=lubridate::as_date(Date.lost.to.follow.up))
update_pp6<-update_pp6 %>% dplyr::mutate(Cohort_censor=as.Date("2016-05-31"))

#actually need to remove those with baseline diabetes FIRST! so that we don't have any diabetes dates before date of baseline assessment:

#now exclude those people with any kind of diabetes at baseline (except gestational)
update_pp6<-update_pp6%>% dplyr::filter(dX_at_BL==0)
#now remove anyone diagnosed with T1D after baseline (because it's likely that that is simply a misdiagnosis of T2D, including people first diagnosed with T2D and then T1D, because this probably reflects simply an earlier misdiagnosis of T1D)
update_pp6<-update_pp6 %>% dplyr::filter(T1D_by_firstocc==0) #31.03 think had already run this over update_pp6 accidentally, but makes sense to run for the non-Cox analyes too
#similarly, had already filtered out those taking insulin at BL
update_pp6 <-update_pp6 %>% filter(insulin_BL==0)

update_pp6 %>% dplyr::count(T2D_by_firstocc) #ok so still >10,000 incident cases to work with here
#filter out those reporting diabetes meds at BL who don't seld report diabetes/have records of diabetes
toMatch <- c("insulin", "amaryl" , "chlorpropamide" , "glimepiride", "glipizide" , "minodiab", "tolazamide", "tolbutamide", "glibenclamide", "diamicron", "gliclazide "  , "acarbose", "glucobay", "glucotard"  , "repaglinide", "nateglinide", "starlix" , "pioglitazone", "rosiglitazone", "avandia", "actos")
update_pp6<-update_pp6 %>% dplyr::mutate(anyDmeds_BL =(grepl(paste(toMatch,collapse="|"), Treatment.medication.code...Instance.0 )))
update_pp6 %>% count(anyDmeds_BL) #only 15 people (makes sense given we've already filtered out people self-reporting diabetes at bl/records indicate diagnosed with diabetes before bl/taking insulin at bl)
#now filter these people out
update_pp6<-update_pp6 %>% dplyr::filter(anyDmeds_BL==FALSE)
#final step is to remove those with elevated hba1c/glucose at BL (using Steven code; for incidence eastwood uses the same hba1c threshold and also glucose omore than or equal to 11.1)
update_pp6<-update_pp6%>% dplyr::filter (is.na(Glycated.haemoglobin..HbA1c....Instance.0) | Glycated.haemoglobin..HbA1c....Instance.0<48) # wow that removed almost 2,000 people
update_pp6<-update_pp6 %>% dplyr::filter (is.na(Glucose...Instance.0) | Glucose...Instance.0<11.1) #only removed a few extra people



update_pp6<-update_pp6 %>% dplyr::mutate(CENSDATE=pmin(Death_date, Lost_date, first_rep_date_diab, Cohort_censor , na.rm=TRUE))
temp<-update_pp6 %>% dplyr::select(ID_1,Death_date,Date.of.death...Instance.0,Date.lost.to.follow.up,first_rep_date_diab, Cohort_censor, earliest_diab, dX_at_BL,anyDmeds_BL, CENSDATE, BL_DATE, TIS) #GREAT, this worked

#now a time in study var
update_pp6<-update_pp6 %>% dplyr::mutate(BL_DATE=as.Date(Date.of.attending.assessment.centre...Instance.0))
update_pp6<-update_pp6 %>% dplyr::mutate(TIS=CENSDATE - BL_DATE)
class(update_pp6$TIS)

#now name as a new file and save
COX_update<-update_pp6
saveRDS(COX_update, file="COX_update.rds")
COX_update<-readRDS("COX_update.rds")
```

#AWESOME! ok now run a Cox model -> try observational first before MR version
#realised can't just run a regular COX model, needs to be a spline term -> which can do with either the pspline within coxph function (survival package), or what seems more common now is rcs within cph function (rms package) -> the latter is what Louise did
https://stats.stackexchange.com/questions/427436/pspline-or-rms-in-a-cox-model
```{r}
#09.05 figuring out additional covariates to add
COX_update79 %>% count(Past.tobacco.smoking...Instance.0) #weirdly 21,780 have a blank entry -> must just be NA
#COX_update79 %>% count(Age.completed.full.time.education...Instance.0) #hmm way too much missing data here
#COX_update79 %>% count(Qualifications...Instance.0) #going to split into those with tertiary degree vs those without
COX_update79 <-COX_update79 %>% mutate (tert_deg= case_when (grepl("College or University degree", Qualifications...Instance.0)~"Yes", TRUE ~"No"))
COX_update79 %>% count(tert_deg)
COX_update79 %>% count(Townsend.deprivation.index.at.recruitment)
class(COX_update79$Townsend.deprivation.index.at.recruitment)
COX_update79 %>% count(Summed.MET.minutes.per.week.for.all.activity...Instance.0)
class(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0)




library(survival)
#devtools::install_github("harrelfe/rms")
install.packages("rms")
library(rms)
#coxmod<-coxph(formula = Surv(TIS, STATUS) ~ weekly_units_B+ Sex_F+ Age.at.recruitment , data = COX_update)

#these lines are essential for predict and plot.Predict functions
detach(COX_update79_noEx)
attach(COX_update79)
dd <- datadist(weekly_units_B_R, Sex_F, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Sex_F+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79) #using 3 knots


p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp) #ok this hasn't worked, need to revisit...
lsf.str("package:rms") #ok for some reason the plot.Predict function didn't come in with this, so have to define it myself using the github code

acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 
#AWESOME! get a very nice J-shape for observational survival analysis #update 24.04 great this now works to have reference at 0 drinks per week

#by sex
COX_update79_F<-COX_update79 %>% filter(Sex=="Female")
detach(COX_update79)
attach(COX_update79_F)
dd <- datadist(weekly_units_B_R, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_F, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_F) #using 3 knots

p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp)
acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 

COX_update79_M<-COX_update79 %>% filter(Sex=="Male")
detach(COX_update79_F)
attach(COX_update79_M)
dd <- datadist(weekly_units_B_R, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_M, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_M) #using 3 knots

p <- Predict(coxmod, weekly_units_B_R (),ref.zero=TRUE, 
              fun=exp)
acttualplot<-plot.Predict(p, ~ weekly_units_B_R,
             col="black",
             col.fill=gray(seq(.8, .75, length=5)), xlab="Drinks per week", ylab="Hazard ratio of T2D", abline=list(h=1,lty=2)) 

#and removing former drinkers > very similar results
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
detach(COX_update79_M)
attach(COX_update79_noEx)
dd <- datadist(weekly_units_B_R, Sex_F, Age.at.recruitment, Past.tobacco.smoking...Instance.0,tert_deg,Townsend.deprivation.index.at.recruitment, Summed.MET.minutes.per.week.for.all.activity...Instance.0)
options(datadist='dd')
dd$limits["Adjust to","weekly_units_B_R"] <- 0 

survobj <- with(COX_update79_noEx, Surv(TIS,STATUS))
coxmod<-cph(survobj ~ rcs(weekly_units_B_R,3 )+ Sex_F+ Age.at.recruitment + Past.tobacco.smoking...Instance.0 +tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0, data = COX_update79_noEx) #using 3 knots


#09.05 with current drinkers only -> results don't really change from above because only removing less than 20,000 people
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")
detach(COX_update79_noEx)

```
#now run nlmr Cox models (vary data set below between COX_update and COX_update_noEx and also whether use GRS/GRS2) ->16.04 should be GRS_79
#09.05 vary running noEx based on the current drinker only version
```{r}
detach(package:SUMnlmr, unload = TRUE)
devtools::install_github("amymariemason/SUMnlmr") #reinstalling so can get latest version with cox option
library(SUMnlmr)
#COX_update_noEx<-COX_update_noEx %>% mutate(survobj=Surv(TIS,STATUS))
#COX_update<-COX_update %>% mutate(survobj=Surv(TIS,STATUS))
#COX_update79<-COX_update79%>% mutate(survobj=Surv(TIS,STATUS))
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
#09.05 and with current drinkers only
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")

#sum(is.na(COX_update_noEx$weekly_units_B))
dummies_2<-model.matrix(~Sex, data=COX_update79)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79)[,2] 

summ_covar_FULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79$survobj,
                                 x = COX_update79$weekly_units_B_R, 
                                 g = COX_update79$GRS_79,
                                 covar=cbind(dummies_2,dummies_3,matrix(data=c(COX_update79$Age.at.recruitment, COX_update79$Genetic.principal.components...Array.1,COX_update79$Genetic.principal.components...Array.2,COX_update79$Genetic.principal.components...Array.3,COX_update79$Genetic.principal.components...Array.4,COX_update79$Genetic.principal.components...Array.5,COX_update79$Genetic.principal.components...Array.6,COX_update79$Genetic.principal.components...Array.7,COX_update79$Genetic.principal.components...Array.8,COX_update79$Genetic.principal.components...Array.9,COX_update79$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)

#NOTE BELOW THERE IS NO coxph family > if you write it t won't throw an error but will return result as if familyt had been gaussian
#19.04 updating to ref=0 -> ok this doesn't work because it's actually before the graph starts on X axis -> must take mean X of bottom strata and use that as the reference (1.34 in the case of full sample; 1.98 excl former drinkers; 2.85 for current drinkers only)
#RV adapted the function to remove red referene point -> update family=function because now it will plot with 'hazard ratio on y axis (Amy recent fix)
library(metafor)
library(stats)
library(matrixStats)
  model_DR_COX<- with(summ_covar_FULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=1.34,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE)
)
summary(model_DR_COX)
#ok now to extract the NDE value
xvals<-model_DR_COX[["figure"]][["data"]][["x"]]
yvals<-model_DR_COX[["figure"]][["data"]][["yest"]]
uci<-model_DR_COX[["figure"]][["data"]][["uci"]]
xyvals<-data.frame(xvals,yvals,uci) #once ordered these, can see NDE is 31.31 drinks per week; but this is only sig up to 11.45 drinks per week
#for nadir index
which.min(xyvals$yvals)
xyvals[6358,]

#here can actually set ref to 0! but need to try to figure out how to reduce y axis
model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, SUMnlmr::piecewise_summ_mr(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)
LACESUM<-summary(model_DR_COX)
#zoomed in version -> I adapted the function setting own y limits -> no SCRAPPED this! but have changed it so that has more meaningful axis labels and x axis breaks

####IMPORTANT NOTE, when using current drinkers only MUST update the ref value to minimum, otherwise will get an error saying object ref_pos not found -> not sure how to work out what this number is because it's less than the mean for the bottom stratum... ->>> ahh it's the MIN for the bootom stratum
#min(COX_update79_noEx$weekly_units_B_R)
model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=1,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX) #hmm this is actually too misleading without the confidence intervals


#update 07.04 also going to vary between male and female to see if any difference
#library(tidyverse)
library(tidyverse)
COX_update79 %>% count(Sex)
library(survival) 
#COX_update79<-COX_update79%>% mutate(survobj=Surv(TIS,STATUS))
#COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Never"|BL_drinker_status=="Current")
COX_update79_noEx<-COX_update79 %>% filter(BL_drinker_status=="Current")
COX_update79_M<-COX_update79 %>% filter(Sex=="Male")
COX_update79_F<-COX_update79 %>% filter(Sex=="Female")
COX_update79_noEx_M<-COX_update79_noEx %>% filter(Sex=="Male")
COX_update79_noEx_F<-COX_update79_noEx %>% filter(Sex=="Female")
#dummies_2<-model.matrix(~Sex, data=COX_update79_noEx)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79_noEx_M)[,2] 

summ_covar_noEx_MULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79_noEx_M$survobj,
                                 x = COX_update79_noEx_M$weekly_units_B_R, 
                                 g = COX_update79_noEx_M$GRS_79,
                                 covar=cbind(dummies_3,matrix(data=c(COX_update79_noEx_M$Age.at.recruitment, COX_update79_noEx_M$Genetic.principal.components...Array.1,COX_update79_noEx_M$Genetic.principal.components...Array.2,COX_update79_noEx_M$Genetic.principal.components...Array.3,COX_update79_noEx_M$Genetic.principal.components...Array.4,COX_update79_noEx_M$Genetic.principal.components...Array.5,COX_update79_noEx_M$Genetic.principal.components...Array.6,COX_update79_noEx_M$Genetic.principal.components...Array.7,COX_update79_noEx_M$Genetic.principal.components...Array.8,COX_update79_noEx_M$Genetic.principal.components...Array.9,COX_update79_noEx_M$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)

#NOTE BELOW THERE IS NO coxph family > if you write it t won't throw an error but will return result as if familyt had been gaussian #yes has since been updated
#for females the ref should be: ; for males: -> for current drinkers only F is 2.00 M is 4.51
  model_DR_COX<- with(summ_covar_noEx_MULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=4.51,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE)
)
summary(model_DR_COX)
####IMPORTANT NOTE, when using current drinkers only MUST update the ref value to minimum, otherwise will get an error saying object ref_pos not found -> not sure how to work out what this number is because it's less than the mean for the bottom stratum... ->>> ahh it's the MIN for the bootom stratum
model_DR_COX <-with(summ_covar_noEx_MULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=1.0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)


#15.05 running Amy suggestion to remove primary care diagnoses and see new results
str_sort(names(COX_update79)) #"Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus." 
temp<-COX_update79 %>% select(ID_1,"Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus." )
COX_update79<-COX_update79 %>% mutate(source_T2D=Source.of.report.of.E11..non.insulin.dependent.diabetes.mellitus.)
COX_update79 %>% dplyr::count(source_T2D) #ohhh interesting -> vast majority of T2D diags are from hospital admissions
#confirmed that this is the number of incident cases used in the main Cox analysis (must have already removed people who had other kinds of diabetes first etc -> yes this makes sense!)
36+273+8437+542+660+137+126

#now remove those diagnosed through primary care only and primary care and other source(s)
COX_update79<-COX_update79 %>% filter(source_T2D!="Primary care only")
COX_update79<-COX_update79 %>% filter(source_T2D!="Primary care and other source(s)")
#now re-run main Cox 
dummies_2<-model.matrix(~Sex, data=COX_update79)[,2] 
  dummies_3<-model.matrix(~array_type, data=COX_update79)[,2] 

summ_covar_FULL_T2D_COX<-SUMnlmr::create_nlmr_summary(
                                         y=COX_update79$survobj,
                                 x = COX_update79$weekly_units_B_R, 
                                 g = COX_update79$GRS_79,
                                 covar=cbind(dummies_2,dummies_3,matrix(data=c(COX_update79$Age.at.recruitment, COX_update79$Genetic.principal.components...Array.1,COX_update79$Genetic.principal.components...Array.2,COX_update79$Genetic.principal.components...Array.3,COX_update79$Genetic.principal.components...Array.4,COX_update79$Genetic.principal.components...Array.5,COX_update79$Genetic.principal.components...Array.6,COX_update79$Genetic.principal.components...Array.7,COX_update79$Genetic.principal.components...Array.8,COX_update79$Genetic.principal.components...Array.9,COX_update79$Genetic.principal.components...Array.10),ncol=11)),
                                 family = "coxph",
                                 q = 10, strata_method="ranked", controlsonly = FALSE) #can't use controlsonly for Cox (and wouldn't make sense to)


  model_DR_COX<- with(summ_covar_FULL_T2D_COX$summary, frac_poly_summ_mrRV(bx=bx,
                  by=by, 
                  bxse=bxse, 
                  byse=byse,
                  ref=1.36,
                  xmean=xmean,
                  family="cox",
                  fig=TRUE)
)
summary(model_DR_COX)
#ok now to extract the NDE value
xvals<-model_DR_COX[["figure"]][["data"]][["x"]]
yvals<-model_DR_COX[["figure"]][["data"]][["yest"]]
uci<-model_DR_COX[["figure"]][["data"]][["uci"]]
xyvals<-data.frame(xvals,yvals,uci) #once ordered these, can see NDE is 50.68 drinks per week; but this is only sig up to 22.16 drinks per week
#for nadir index
which.min(xyvals$yvals)
xyvals[6766,]

model_DR_COX <-with(summ_covar_FULL_T2D_COX$summary, piecewise_summ_mrRV(by, bx, byse, bxse, xmean, xmin,xmax, 
                  ci="bootstrap_se",
                  nboot=1000, 
                  fig=TRUE,
                  ref=0,
                  family="cox",
                  ci_fig="ribbon")
)
summary(model_DR_COX)
#haven't run male/female split for now
```

#07.04 regressing exposure on GRS to get F statistic
#also other descriptive stats
```{r}
Fstatcheck<-lm(update_pp679$weekly_units_B_R~update_pp679$GRS_79)
summary(Fstatcheck)

#actual formul 16.04
Fstat<-((nrow(update_pp679)-79-1)/79)*(.005769/(1-.005769))

update_pp6 %>% count(T2dX_at_BL)
COX_update %>% filter(T2dX_at_BL==0) %>% count(STATUS)

install.packages("table1")
library(table1)
#to answer Amy's suggestion about swapping Sex to column and drining group to row for supplementary, instead going to nest sex within drining group
TABBY1<-table1(~ weekly_units_B_R + STATUS_F + HbA1c_BL_winsor + Age.at.recruitment  +  Past.tobacco.smoking...Instance.0_F + tert_deg +Townsend.deprivation.index.at.recruitment + Summed.MET.minutes.per.week.for.all.activity...Instance.0 + array_type_F  | BL_drinker_status_F*Sex_F, data=COX_update79) #addin extra covariates as well as incident diabetes status variable

COX_update79 <-COX_update79 %>% mutate (tert_deg= case_when (grepl("College or University degree", Qualifications...Instance.0)~"Yes", TRUE ~"No"))
COX_update79%>% dplyr::count(tert_deg)
COX_update79$tert_deg<-factor(COX_update79$tert_deg, levels=c("No","Yes"),
         labels=c("No", 
                  "Yes"))
COX_update79%>% dplyr::count(Past.tobacco.smoking...Instance.0_F)
 COX_update79$Past.tobacco.smoking...Instance.0_F<-factor(COX_update79$Past.tobacco.smoking...Instance.0, levels=c("","I have never smoked","Just tried once or twice","Prefer not to answer","Smoked occasionally","Smoked on most or all days"),
         labels=c("N/A", 
                  "Never", "Once or twice", "Prefer not to answer", "Occasionally", "Most or all days"))
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_relevel(COX_update79$Past.tobacco.smoking...Instance.0_F, "N/A", "Prefer not to answer", "Never", "Once or twice", "Occasionally", "Most or all days")
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_collapse(COX_update79$Past.tobacco.smoking...Instance.0_F, Missing= c("N/A", "Prefer not to answer"))
COX_update79$Past.tobacco.smoking...Instance.0_F<-fct_relevel(COX_update79$Past.tobacco.smoking...Instance.0_F, "Never", "Once or twice", "Occasionally", "Most or all days", "Missing")
COX_update79%>% dplyr::count(array_type_F)
COX_update79$array_type_F<-factor(COX_update79$array_type, levels=c("Affy","UKBiLEVEAX"),
         labels=c("UK Biobank Axiom array", 
                  "UKBiLEVE Axiom array"))
COX_update79%>% dplyr::count(STATUS_F)
COX_update79$STATUS_F<-factor(COX_update79$STATUS, levels=c("0","1"),
         labels=c("Did not develop incident T2D", 
                  "Developed incident T2D"))
COX_update79%>% dplyr::count(BL_drinker_status)
COX_update79$BL_drinker_status_F<-factor(COX_update79$BL_drinker_status, levels=c("Current","Former","Never"),
         labels=c("Current Drinker", 
                  "Former Drinker", "Never Drinker"))

label(COX_update79$Sex_F)       <- "Sex"
label(COX_update79$Age.at.recruitment)       <- "Age"
label(COX_update79$weekly_units_B_R)     <- "Drinks per week"
label(COX_update79$HbA1c_BL_winsor) <- "HbA1C (winsorised)"
label(COX_update79$Past.tobacco.smoking...Instance.0_F)       <- "Smoking history"
label(COX_update79$tert_deg)<- "Tertiary degree"
label(COX_update79$Townsend.deprivation.index.at.recruitment)     <- "Townsend deprivation index"
label(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0) <- "MET minutes per week"
label(COX_update79$array_type_F)     <- "Genotyping array"
label(COX_update79$STATUS_F) <- "Incident diabetes status"


#get new sample size for observational analyses
nrow(COX_update79) #305,614 -> what I had written in the paper good
sum((!COX_update79$Past.tobacco.smoking...Instance.0_F=="Missing")&!is.na(COX_update79$Townsend.deprivation.index.at.recruitment)&!is.na(COX_update79$Summed.MET.minutes.per.week.for.all.activity...Instance.0)) #down to 233,568

```



old code for trying to deal with relatedness
```{r}


temp<-temp %>% filter(Genetic.relatedness.factor...Array.0>.0|Genetic.relatedness.factor...Array.1>.0|Genetic.relatedness.factor...Array.2>.0|Genetic.relatedness.factor...Array.3>.0|Genetic.relatedness.factor...Array.4>.0)
temp1<-temp %>% pivot_longer(cols=starts_with("Genetic.relatedness.pairing"),names_to="array",values_to="UNID")
temp1<-temp1 %>% relocate(UNID, .after=ID_1)
temp1<-temp1 %>% sort("UNID")
temp2<-temp1 %>% pivot_wider(values_from="ID_1",names_from="UNID") #values_from


class(temp2$"8542")
#first make a kinship coefficient variable for each row (UNID) based on which array is mention in "array"
temp3<-temp2 %>% mutate(KINSHIP_co=case_when(array=="Genetic.relatedness.pairing...Array.0" ~ Genetic.relatedness.factor...Array.0, array=="Genetic.relatedness.pairing...Array.1" ~ Genetic.relatedness.factor...Array.1, array=="Genetic.relatedness.pairing...Array.2"~ Genetic.relatedness.factor...Array.2, array=="Genetic.relatedness.pairing...Array.3" ~ Genetic.relatedness.factor...Array.3, array=="Genetic.relatedness.pairing...Array.4" ~ Genetic.relatedness.factor...Array.4, TRUE~NA_real_))
#now combine all the pairing columns into 1 column, removing the 'NULL' values so left with just a 'c(ID1,ID2)' for each row
#first remove the 'NA' col (formed as a result of the original pivot_longer from those pairing cells that were NA)
temp4<-temp3 %>% select(-c("NA"))
#find index positions of columns
grep("7289",colnames(temp4)) #8
grep("6316",colnames(temp4)) #3940
temp4<-temp4 %>% unite("PAIRING", 8:3940, remove=TRUE,na.rm=TRUE) #from the first pairing ID variable to the last, as listed in the df; remove = TRUE removes input columns from output data frame; automatically uses underscore as the separator
#ahh bugger I can see this isn't the right approach because 

#now remove all "NULL_" from this new value, so should just be left with the two IDs we're interested in
temp4$PAIRING2<- gsub("NULL_","",temp4$PAIRING)

```


#22.04 testing for pleiotropy using MR-egger within strata
using the code Haodong shared with me to make the strata
hang on have to use update_pp6 instad of COX_update because interested in baseline logistic rather than incident
mmm for now just use incident
#update 20.05 -> using this code but with COX_update79 to try to do nlmr with sensitivity methods
```{r}
N<-310440  ;No<-31044     #10 ests #RV not perfectly fitting into 10 strata...
N/No


#ok for these purposes, going to remove the people with the 8 highest drinks per week values


set.seed(1123)



##fitting
library(tidyverse)
dat_Hao_order<-update_pp679[ order(update_pp679$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<235)

#residual exposure #RV says add column calculated by subtracting genetically predicted drinks per week from actual drinks per week 
#dat_Hao_order<-cbind(  dat_Hao_order   ,  dat_Hao_order$weekly_units_B_R -lm(  dat_Hao_order$weekly_units_B_R~dat_Hao_order$GRS )$fitted)
#old LACE stratums #RV says add a column with ranks based on residual method only (ie the column created above)
#'No' is defined above to be 10% of the sample -> floor gives the lowest residual value for each of the 10 strata
#so actually this produces a new column with the strata for each person based on residuals
#dat_Hao_order<-cbind(  dat_Hao_order   ,  
#                   floor( (rank( dat_Hao_order[610] ,ties.method = "first"  )/(No+0.000000001) ) )+1  )  #RV the column above is now the 610th variable 
#temp<-dat_Hao_order %>% select(weekly_units_B_R,GRS,611) 

##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 385000

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y
class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) glm(X[[10]]$T2dX_at_BL ~ x, family="binomial")) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #yay!
dfby<-data.frame(by_terms) %>% t() %>% data.frame()


#library(MendelianRandomization)
MRInputObject <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)

IVW10<-mr_ivw(MRInputObject)
IVW10
exp(.03)

#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

Egg1<-mr_egger(MRInputObject)
Egg1 #this is really the only strata with a real effect going on
Egg2<-mr_egger(MRInputObject)
Egg2
Egg3<-mr_egger(MRInputObject)
Egg3
IVW3<-mr_ivw(MRInputObject)
IVW3 #hmm the effect sizes are just really tiny here compared to the LACEs, makes me think I might have done something wrong here in setting up the MRInputObject 
Egg4<-mr_egger(MRInputObject)
Egg4 #now approaching significance (although teeny tiny estimate size)
Egg5<-mr_egger(MRInputObject)
Egg5
Egg6<-mr_egger(MRInputObject)
Egg6
Egg7<-mr_egger(MRInputObject)
Egg7
Egg8<-mr_egger(MRInputObject)
Egg8 #ahh ok this is now a significant intercept! (although still a really tiny, but significant, positive estimate)
Egg9<-mr_egger(MRInputObject)
Egg9 #again now a significant intercept
Egg10<-mr_egger(MRInputObject)
Egg10 #and now not significant...



#20.05
#updating 25.05 with male and female stratified versions as well 
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79[ order(COX_update79$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<270) #get rid of the top 4 so nicely divides by 10
N<-305610  ;No<-30561     #10 ests #RV not perfectly fitting into 10 strata...


#female - get rid of top 4 so nicely divides by 10
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79_F[ order(COX_update79_F$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-160150 ;No<-16015  


#male already divides neatly by 10
set.seed(1123)
##fitting
dat_Hao_order<-COX_update79_M[ order(COX_update79_M$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
#dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-145460 ;No<-14546


N/No
##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 305610

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
#for sex stratified grey out sex covariate
#library(survival)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x + #X[[10]]$Sex_F+ 
                                                    X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using survobj 
#library (survival)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) coxph(X[[10]]$survobj ~ x + # X[[10]]$Sex_F+ 
                                                        X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[1, c(1,3)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
names(dfby)

library(MendelianRandomization)
MRInputObject1 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.) #ok so this worked for the first strata; but before continuing check whether want to exponentiate first -> ok so can see from AMY sumnlmr create summary code that they take the se as the unexponentiated, unclear exactly where the beta itself comes from... in any case, confirmed by looking in summ_covar_FULL_T2D_COX that at that stage the Y-G betas are STILL unexponentiated because some of them are negative  by[j] <- model$coef[1] byse[j] <- summary(model)$coef[1, 3]

MRInputObject2 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject3 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject4 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject5 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject6 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject7 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject8 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject9 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
MRInputObject10 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$coef,
byse = dfby$se.coef.)
#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

#and then once run below for a given sens test (just sub out med for IVW etc), add columns to LACESUM[["coefficients"]] which are from the main results (or make a list of them instead?) -> actually only works for median and IVW, for RAPS PRESSO and weighted mode will have to use other packages because Mendelian Randomisation package doesn't include them


ivw1<-MendelianRandomization::mr_ivw(MRInputObject1)
ivw1 #interesting much smaller/non-sig decrease
ivw2<-MendelianRandomization::mr_ivw(MRInputObject2)
ivw2
ivw3<-MendelianRandomization::mr_ivw(MRInputObject3)
ivw3
ivw4<-MendelianRandomization::mr_ivw(MRInputObject4)
ivw4 
ivw5<-MendelianRandomization::mr_ivw(MRInputObject5)
ivw5
ivw6<-MendelianRandomization::mr_ivw(MRInputObject6)
ivw6
ivw7<-MendelianRandomization::mr_ivw(MRInputObject7)
ivw7
ivw8<-MendelianRandomization::mr_ivw(MRInputObject8)
ivw8 
ivw9<-MendelianRandomization::mr_ivw(MRInputObject9)
ivw9 
ivw10<-MendelianRandomization::mr_ivw(MRInputObject10)
ivw10 #this one is sig positive
summary(ivw10)

ivwres1<-c(ivw1@Estimate,ivw1@StdError,ivw1@CILower,ivw1@CIUpper,ivw1@Pvalue)
ivwres2<-c(ivw2@Estimate,ivw2@StdError,ivw2@CILower,ivw2@CIUpper,ivw2@Pvalue)
ivwres3<-c(ivw3@Estimate,ivw3@StdError,ivw3@CILower,ivw3@CIUpper,ivw3@Pvalue)
ivwres4<-c(ivw4@Estimate,ivw4@StdError,ivw4@CILower,ivw4@CIUpper,ivw4@Pvalue)
ivwres5<-c(ivw5@Estimate,ivw5@StdError,ivw5@CILower,ivw5@CIUpper,ivw5@Pvalue)
ivwres6<-c(ivw6@Estimate,ivw6@StdError,ivw6@CILower,ivw6@CIUpper,ivw6@Pvalue)
ivwres7<-c(ivw7@Estimate,ivw7@StdError,ivw7@CILower,ivw7@CIUpper,ivw7@Pvalue)
ivwres8<-c(ivw8@Estimate,ivw8@StdError,ivw8@CILower,ivw8@CIUpper,ivw8@Pvalue)
ivwres9<-c(ivw9@Estimate,ivw9@StdError,ivw9@CILower,ivw9@CIUpper,ivw9@Pvalue)
ivwres10<-c(ivw10@Estimate,ivw10@StdError,ivw10@CILower,ivw10@CIUpper,ivw10@Pvalue)

ivwRES<-t(data.frame(ivwres1,ivwres2,ivwres3,ivwres4,ivwres5,ivwres6,ivwres7,ivwres8,ivwres9,ivwres10))
ivwRES<-data.frame(ivwRES) #24.05 adding covariates seems to have attenuated results for both ivw and ivwian, only slightly

#ok now to do the other methods using the twosampleMR package
library(TwoSampleMR)
SNPSdf1<-cbind(MRInputObject1$betaX,MRInputObject1$betaXse,MRInputObject1$betaY,MRInputObject1$betaYse)
SNPSdf1<-data.frame(SNPSdf1)
colnames(SNPSdf1)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf1<-SNPSdf1 %>% mutate(SNP=1:79)
SNPSdf1<-SNPSdf1 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf1<-SNPSdf1 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf2<-cbind(MRInputObject2$betaX,MRInputObject2$betaXse,MRInputObject2$betaY,MRInputObject2$betaYse)
SNPSdf2<-data.frame(SNPSdf2)
colnames(SNPSdf2)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf2<-SNPSdf2 %>% mutate(SNP=1:79)
SNPSdf2<-SNPSdf2 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf2<-SNPSdf2 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf3<-cbind(MRInputObject3$betaX,MRInputObject3$betaXse,MRInputObject3$betaY,MRInputObject3$betaYse)
SNPSdf3<-data.frame(SNPSdf3)
colnames(SNPSdf3)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf3<-SNPSdf3 %>% mutate(SNP=1:79)
SNPSdf3<-SNPSdf3 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf3<-SNPSdf3 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf4<-cbind(MRInputObject4$betaX,MRInputObject4$betaXse,MRInputObject4$betaY,MRInputObject4$betaYse)
SNPSdf4<-data.frame(SNPSdf4)
colnames(SNPSdf4)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf4<-SNPSdf4 %>% mutate(SNP=1:79)
SNPSdf4<-SNPSdf4 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf4<-SNPSdf4 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf5<-cbind(MRInputObject5$betaX,MRInputObject5$betaXse,MRInputObject5$betaY,MRInputObject5$betaYse)
SNPSdf5<-data.frame(SNPSdf5)
colnames(SNPSdf5)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf5<-SNPSdf5 %>% mutate(SNP=1:79)
SNPSdf5<-SNPSdf5 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf5<-SNPSdf5 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf6<-cbind(MRInputObject6$betaX,MRInputObject6$betaXse,MRInputObject6$betaY,MRInputObject6$betaYse)
SNPSdf6<-data.frame(SNPSdf6)
colnames(SNPSdf6)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf6<-SNPSdf6 %>% mutate(SNP=1:79)
SNPSdf6<-SNPSdf6 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf6<-SNPSdf6 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf7<-cbind(MRInputObject7$betaX,MRInputObject7$betaXse,MRInputObject7$betaY,MRInputObject7$betaYse)
SNPSdf7<-data.frame(SNPSdf7)
colnames(SNPSdf7)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf7<-SNPSdf7 %>% mutate(SNP=1:79)
SNPSdf7<-SNPSdf7 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf7<-SNPSdf7 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf8<-cbind(MRInputObject8$betaX,MRInputObject8$betaXse,MRInputObject8$betaY,MRInputObject8$betaYse)
SNPSdf8<-data.frame(SNPSdf8)
colnames(SNPSdf8)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf8<-SNPSdf8 %>% mutate(SNP=1:79)
SNPSdf8<-SNPSdf8 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf8<-SNPSdf8 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf9<-cbind(MRInputObject9$betaX,MRInputObject9$betaXse,MRInputObject9$betaY,MRInputObject9$betaYse)
SNPSdf9<-data.frame(SNPSdf9)
colnames(SNPSdf9)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf9<-SNPSdf9 %>% mutate(SNP=1:79)
SNPSdf9<-SNPSdf9 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf9<-SNPSdf9 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf10<-cbind(MRInputObject10$betaX,MRInputObject10$betaXse,MRInputObject10$betaY,MRInputObject10$betaYse)
SNPSdf10<-data.frame(SNPSdf10)
colnames(SNPSdf10)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf10<-SNPSdf10 %>% mutate(SNP=1:79)
SNPSdf10<-SNPSdf10 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf10<-SNPSdf10 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf<-list(SNPSdf1,SNPSdf2,SNPSdf3,SNPSdf4,SNPSdf5,SNPSdf6,SNPSdf7,SNPSdf8,SNPSdf9,SNPSdf10)

#weighted mode
my_lms <- lapply(SNPSdf, function(x) mr_weighted_mode(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$b-(1.96*x$se);x$upperCI<-x$b+(1.96*x$se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
modeRES<-as.data.frame(do.call(rbind,add_CIs))
modeRES<-modeRES %>% select(b,se,lowerCI,upperCI,pval) #DONE!
class(modeRES)
class(modeRES$b)
modeRES2<- unnest(modeRES,b) %>% unnest(modeRES,se) %>% unnest(modeRES,lowerCI) %>% unnest(modeRES,upperCI) %>% unnest(modeRES,pval) #none are now sig once incorp covariates
class(modeRES2$se)

#raps
my_lms <- lapply(SNPSdf, function(x) mr.raps::mr.raps(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome, diagnosis=TRUE)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$beta.hat-(1.96*x$beta.se);x$upperCI<-x$beta.hat+(1.96*x$beta.se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
rapsRES<-as.data.frame(do.call(rbind,add_CIs))
rapsRES<-rapsRES %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value) #DONE!
rapsRES2<- unnest(rapsRES,beta.hat) %>% unnest(rapsRES,beta.se) %>% unnest(rapsRES,lowerCI) %>% unnest(rapsRES,upperCI) %>% unnest(rapsRES,beta.p.value) 
class(rapsRES2$beta.se)

#finally presso
my_lms <- lapply(SNPSdf, function(x) run_mr_presso(x, NbDistribution = 2500, SignifThreshold = 0.05)) 
#all 10 global tests >.05, therefore no outlier corrected estmates produced
#24.05 same for when added covariates; 25.05 same for females; same for males EXCEPT stratum 9, but then no sig outliers could be found

M_FOURxsensresultsCOV<-list(ivwRES,medRES,modeRES2,rapsRES2)
saveRDS(M_FOURxsensresultsCOV, file="M_FOURxsensresultsCOV.rds")
saveRDS(M_FOURxsensresultsCOV, file="M_FOURxsensresultsCOV.RData")
M_FOURxsensresultsCOV<-readRDS("M_FOURxsensresultsCOV.rds") 

M_FOURxsensresultsCOV[[3]]<-M_FOURxsensresultsCOV[[3]] %>% select(b,se,lowerCI,upperCI,pval)
M_FOURxsensresultsCOV[[4]]<-M_FOURxsensresultsCOV[[4]] %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value)
#so now have LACEs in there with variance/CIs, need to add the mean x for each stratum now so that can figure out how to do fractional polynomial
#actually can just calculate by hand
mean1<-mean(X[[1]]$weekly_units_B_R)
mean2<-mean(X[[2]]$weekly_units_B_R)
mean3<-mean(X[[3]]$weekly_units_B_R)
mean4<-mean(X[[4]]$weekly_units_B_R)
mean5<-mean(X[[5]]$weekly_units_B_R)
mean6<-mean(X[[6]]$weekly_units_B_R)
mean7<-mean(X[[7]]$weekly_units_B_R)
mean8<-mean(X[[8]]$weekly_units_B_R)
mean9<-mean(X[[9]]$weekly_units_B_R)
mean10<-mean(X[[10]]$weekly_units_B_R)
Xmeans<-c(mean1,mean2,mean3,mean4,mean5,mean6,mean7,mean8,mean9,mean10)#now attach these back to sensitivity results
M_FOURxsensresultsCOV2<-lapply(M_FOURxsensresultsCOV, function(x) cbind(x, Xmeans)) #EXCELLENT! now see if can feed into the NLMR package to generate plots
devtools::install_github("jrs95/nlmr")
library(nlmr)
ls("package:nlmr") #so that fracpoly_best function IS here, need to see what's in it
View(nlmr::fracpoly_best) #excellent -> this opens the function in a separate tab, and unlike the sumNLMR equivalent only needs the values for LACE, se and xmeans rather than the individual bx by stats (which force the function to use ratio method) -> want to use argument d="both"
```

```{r}
 ##### Best-fitting fractional polynomial #####
  fracpb <- nlmr::fracpoly_best(coef=M_FOURxsensresultsCOV2[[1]][["X1"]], coef_se=M_FOURxsensresultsCOV2[[1]][["X2"]], xmean=M_FOURxsensresultsCOV2[[1]]$Xmeans, d="both", pd=.05, method="FE")
  #so p1_ML is best fitting of degree 1, p2_ML is best fitting of degree 2; fp_p is p value for a first degree fp over linear; fp_d12_p is for degree 2 over degree 1, not sure what p_ML is though??? (eg for first one - IVW - p_ML is -2 whereas p1_ML is -1 and p2_ML is -.5)->>>> AHHHH this is wrong! p_ML is degree 1, p1_ML and p2_ML relate to the best fitting second degree (ie the two fractions that compose best fitting second degree polynomial) -> not significant in this case anyway
#GOOD news is tht didn't use bootstrapped CIs/ses for main nlmr analyses fracpoly (only for piecewise), so don't need to calclate here (which for some reason requires the x and y and g stats)
model <- fracpb$model; p_ML <- fracpb$p_ML; p1_ML <- fracpb$p1_ML; p2_ML <- fracpb$p2_ML; fp_p <- fracpb$fp_p; fp_d12_p <- fracpb$fp_d12_p
  d <- fracpb$d
    ##### Non-linearity tests #####
  #library(metafor)
  p_quadratic <- rma(M_FOURxsensresultsCOV2[[1]][["X1"]] ~ M_FOURxsensresultsCOV2[[1]]$Xmeans, M_FOURxsensresultsCOV2[[1]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[1]][["X1"]], vi=(M_FOURxsensresultsCOV2[[1]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
  #and to make figure
  
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
  

     #View(nlmr::fracpoly_figure)
     
     ###AHHHH ok below need to supply mean of lowest stratum as xmin and mean of highest stratum as xmax, not the literal highest and lowest x values! 1.34 and 53.78 for overall; .77 and 40.53 for women; 2.65 and 63.53 for men
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=2, p_ML=-1, p1_ML=-1, p2_ML=-.5, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional polynoial degrees from the actual data, apart from that the shape is just generic! so what I'll do is simply generate the polynomial tests and list of LACEs, and won't make the plots!!!
   #ohhhh my GOD I GOT THE GFIGURE WORKING!!! -well the CIs are still a little weird on the left hand side; have edited the function foior now to remove CIs s can see line better -> weird that doesn't properly align with the Xmean for lowest caeory -> I think the nlmr package must plot in a sep way
  
   #do for sensitivity 2-4 (median,mode,RAPS) -> one above is IVW
    fracpbMEDIAN <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[2]][["X1"]], coef_se=M_FOURxsensresultsCOV2[[2]][["X2"]], xmean=M_FOURxsensresultsCOV2[[2]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbMEDIAN$model; p_ML <- fracpbMEDIAN$p_ML; p1_ML <- fracpbMEDIAN$p1_ML; p2_ML <- fracpbMEDIAN$p2_ML; fp_p <- fracpbMEDIAN$fp_p; fp_d12_p <- fracpbMEDIAN$fp_d12_p
  d <- fracpbMEDIAN$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(M_FOURxsensresultsCOV2[[2]][["X1"]] ~ M_FOURxsensresultsCOV2[[2]]$Xmeans, M_FOURxsensresultsCOV2[[2]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[2]][["X1"]], vi=(M_FOURxsensresultsCOV2[[2]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=2, p_ML=-3, p1_ML=-1, p2_ML=-.5, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  
    fracpbmode <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[3]][["b"]], coef_se=M_FOURxsensresultsCOV2[[3]][["se"]], xmean=M_FOURxsensresultsCOV2[[3]]$Xmeans, d="both", pd=.05, method="FE")
        model <- fracpbmode$model; p_ML <- fracpbmode$p_ML; p1_ML <- fracpbmode$p1_ML; p2_ML <- fracpbmode$p2_ML; fp_p <- fracpbmode$fp_p; fp_d12_p <- fracpbmode$fp_d12_p
  d <- fracpbmode$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(M_FOURxsensresultsCOV2[[3]][["b"]] ~ M_FOURxsensresultsCOV2[[3]]$Xmeans, M_FOURxsensresultsCOV2[[3]][["se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[3]][["b"]], vi=(M_FOURxsensresultsCOV2[[3]][["se"]])^2)$QE, df=(10-1))
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=1, p_ML=1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
    
    
     fracpbraps <- fracpoly_best(coef=M_FOURxsensresultsCOV2[[4]][["beta.hat"]], coef_se=M_FOURxsensresultsCOV2[[4]][["beta.se"]], xmean=M_FOURxsensresultsCOV2[[4]]$Xmeans, d="both", pd=.05, method="FE")
      model <- fracpbraps$model; p_ML <- fracpbraps$p_ML; p1_ML <- fracpbraps$p1_ML; p2_ML <- fracpbraps$p2_ML; fp_p <- fracpbraps$fp_p; fp_d12_p <- fracpbraps$fp_d12_p
  d <- fracpbraps$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(M_FOURxsensresultsCOV2[[4]][["beta.hat"]] ~ M_FOURxsensresultsCOV2[[4]]$Xmeans, M_FOURxsensresultsCOV2[[4]][["beta.se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(M_FOURxsensresultsCOV2[[4]][["beta.hat"]], vi=(M_FOURxsensresultsCOV2[[4]][["beta.se"]])^2)$QE, df=(10-1))
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 2.65, 63.53, family="binomial", d=1, p_ML=1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=2.65, pref_x="Drinks per week", pref_x_ref="x", pref_y="Incident T2D risk", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional 
     
     #23.03 OK NEED TO REDO ALL OF THIS AFTER INCORPORATING COVARIATES -> 24th done!, 
     #ALSO THEN DO BELOW WITH MALES AND FEMALES SEPARATELY
```

#ok now for HBA1C

```{r}
#first remove those without hba1c values
 full_HbA1c<-update_pp679 %>% filter(!is.na(HbA1c_BL_winsor))
  #women only

#20.05
#updating 25.05 with male and female stratified versions as well 
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c[ order(full_HbA1c$GRS_79),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<275) #get rid of the top 2 so nicely divides by 10
N<-295710  ;No<-29571     #10 ests #RV not perfectly fitting into 10 strata...


#female - get rid of top 4 so nicely divides by 10
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c_M[ order(full_HbA1c_F$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-160150 ;No<-16015  


#male already divides neatly by 10
set.seed(1123)
##fitting
dat_Hao_order<-full_HbA1c_M[ order(full_HbA1c_M$GRS_79  ),  ]  #ordered by Z  (RV increasing values of GRS) 
temp<-dat_Hao_order %>% select(weekly_units_B_R)
#dat_Hao_order<-dat_Hao_order %>% filter(weekly_units_B_R<209) #get rid of the top 4 so nicely divides by 10
N<-145460 ;No<-14546


N/No
##NLACE---
#Z stratums #RV this makes the (38,500) pre-strata based on G alone
dat_Hao_order<-cbind(  dat_Hao_order   ,  
                   sort(rep( 1:No, N/No  )) )
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,"sort(rep(1:No, N/No))")
dim( dat_Hao_order )  #387000      6= Z_order  X Y resX Strata1 Zstrata #RV should be 305610

#dat_Hao_order<-as.data.frame( dat_Hao_order ) ; names(dat_Hao_order)<-paste0('V',1:ncol(dat_Hao_order))
temp<-arrange(  dat_Hao_order, weekly_units_B_R )  #doubly-ranked #RV arranging by level of observed consumption
temp2<-temp %>% select(GRS_79,weekly_units_B_R,602)
#temp3<-temp2 %>% arrange(3) #not working
#ordered_df <- temp2[order(temp2$"sort(rep(1:No, N/No))"), ] #ahhhh ok, now this works!
#dat_Hao_order<-arrange(  temp ,"sort(rep(1:No, N/No))" ) #and now arranging that by strata based on G -> this isn't actually working!
dat_Hao_order<-temp[order(temp$"sort(rep(1:No, N/No))"), ] 
temp<-dat_Hao_order %>% select(GRS,weekly_units_B_R,602) #excllent this finally works!
dat_Hao_order$FINSTRATA<- rep( 1:(N/No), No  ) #so this now ranks all ten people within each strata of G based on 
#observed alcohol consumption
#this is the final variable required -> LACE 1 is comprised of all people with column V7=1, LACE 2 V7=2 etc
temp<-dat_Hao_order %>% select(GRS_79,weekly_units_B_R,"sort(rep(1:No, N/No))",FINSTRATA)


#ok now to make ten sep dfs based on FINSTRATA, to then run MR Egger in each
X<-split(dat_Hao_order, dat_Hao_order$FINSTRATA)
#the above dfs are named X[["1"]] etc

#ok so in order to do MR egger, need to calculate the bxs, bys, bxses, and byses in each df
#replace [[1]] with all numbers to 10
#head(X[[1]]$V1)
#for sex stratified grey out sex covariate
#library(survival)
colnames<-grep("^VV[0-9]+",names(X[[1]]))
my_lms <- lapply(X[[1]][colnames], function(x) lm(X[[1]]$weekly_units_B_R ~ x + X[[1]]$Sex_F+ 
                                                    X[[1]]$array_type+ X[[1]]$Age.at.recruitment + X[[1]]$Genetic.principal.components...Array.1+ X[[1]]$Genetic.principal.components...Array.2+ X[[1]]$Genetic.principal.components...Array.3+ X[[1]]$Genetic.principal.components...Array.4+ X[[1]]$Genetic.principal.components...Array.5+ X[[1]]$Genetic.principal.components...Array.6+ X[[1]]$Genetic.principal.components...Array.7+ X[[1]]$Genetic.principal.components...Array.8+ X[[1]]$Genetic.principal.components...Array.9+ X[[1]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[1]]$T2dX_at_BL)
my_lms2 <- lapply(X[[1]][colnames], function(x) lm(X[[1]]$HbA1c_BL_winsor ~ x + X[[1]]$Sex_F+ 
                                                        X[[1]]$array_type+ X[[1]]$Age.at.recruitment + X[[1]]$Genetic.principal.components...Array.1+ X[[1]]$Genetic.principal.components...Array.2+ X[[1]]$Genetic.principal.components...Array.3+ X[[1]]$Genetic.principal.components...Array.4+ X[[1]]$Genetic.principal.components...Array.5+ X[[1]]$Genetic.principal.components...Array.6+ X[[1]]$Genetic.principal.components...Array.7+ X[[1]]$Genetic.principal.components...Array.8+ X[[1]]$Genetic.principal.components...Array.9+ X[[1]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
names(dfby)

library(MendelianRandomization)
MRInputObject1 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error) #ok so this worked for the first strata; but before continuing check whether want to exponentiate first -> ok so can see from AMY sumnlmr create summary code that they take the se as the unexponentiated, unclear exactly where the beta itself comes from... in any case, confirmed by looking in summ_covar_FULL_T2D_COX that at that stage the Y-G betas are STILL unexponentiated because some of them are negative  by[j] <- model$coef[1] byse[j] <- summary(model)$coef[1, 3]
colnames<-grep("^VV[0-9]+",names(X[[2]]))
my_lms <- lapply(X[[2]][colnames], function(x) lm(X[[2]]$weekly_units_B_R ~ x + X[[2]]$Sex_F+ 
                                                    X[[2]]$array_type+ X[[2]]$Age.at.recruitment + X[[2]]$Genetic.principal.components...Array.1+ X[[2]]$Genetic.principal.components...Array.2+ X[[2]]$Genetic.principal.components...Array.3+ X[[2]]$Genetic.principal.components...Array.4+ X[[2]]$Genetic.principal.components...Array.5+ X[[2]]$Genetic.principal.components...Array.6+ X[[2]]$Genetic.principal.components...Array.7+ X[[2]]$Genetic.principal.components...Array.8+ X[[2]]$Genetic.principal.components...Array.9+ X[[2]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[2]]$T2dX_at_BL)
my_lms2 <- lapply(X[[2]][colnames], function(x) lm(X[[2]]$HbA1c_BL_winsor ~ x + X[[2]]$Sex_F+ 
                                                        X[[2]]$array_type+ X[[2]]$Age.at.recruitment + X[[2]]$Genetic.principal.components...Array.1+ X[[2]]$Genetic.principal.components...Array.2+ X[[2]]$Genetic.principal.components...Array.3+ X[[2]]$Genetic.principal.components...Array.4+ X[[2]]$Genetic.principal.components...Array.5+ X[[2]]$Genetic.principal.components...Array.6+ X[[2]]$Genetic.principal.components...Array.7+ X[[2]]$Genetic.principal.components...Array.8+ X[[2]]$Genetic.principal.components...Array.9+ X[[2]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject2 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[3]]))
my_lms <- lapply(X[[3]][colnames], function(x) lm(X[[3]]$weekly_units_B_R ~ x + X[[3]]$Sex_F+ 
                                                    X[[3]]$array_type+ X[[3]]$Age.at.recruitment + X[[3]]$Genetic.principal.components...Array.1+ X[[3]]$Genetic.principal.components...Array.2+ X[[3]]$Genetic.principal.components...Array.3+ X[[3]]$Genetic.principal.components...Array.4+ X[[3]]$Genetic.principal.components...Array.5+ X[[3]]$Genetic.principal.components...Array.6+ X[[3]]$Genetic.principal.components...Array.7+ X[[3]]$Genetic.principal.components...Array.8+ X[[3]]$Genetic.principal.components...Array.9+ X[[3]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[3]]$T2dX_at_BL)
my_lms2 <- lapply(X[[3]][colnames], function(x) lm(X[[3]]$HbA1c_BL_winsor ~ x + X[[3]]$Sex_F+ 
                                                        X[[3]]$array_type+ X[[3]]$Age.at.recruitment + X[[3]]$Genetic.principal.components...Array.1+ X[[3]]$Genetic.principal.components...Array.2+ X[[3]]$Genetic.principal.components...Array.3+ X[[3]]$Genetic.principal.components...Array.4+ X[[3]]$Genetic.principal.components...Array.5+ X[[3]]$Genetic.principal.components...Array.6+ X[[3]]$Genetic.principal.components...Array.7+ X[[3]]$Genetic.principal.components...Array.8+ X[[3]]$Genetic.principal.components...Array.9+ X[[3]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject3 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[1]]))
my_lms <- lapply(X[[4]][colnames], function(x) lm(X[[4]]$weekly_units_B_R ~ x + X[[4]]$Sex_F+ 
                                                    X[[4]]$array_type+ X[[4]]$Age.at.recruitment + X[[4]]$Genetic.principal.components...Array.1+ X[[4]]$Genetic.principal.components...Array.2+ X[[4]]$Genetic.principal.components...Array.3+ X[[4]]$Genetic.principal.components...Array.4+ X[[4]]$Genetic.principal.components...Array.5+ X[[4]]$Genetic.principal.components...Array.6+ X[[4]]$Genetic.principal.components...Array.7+ X[[4]]$Genetic.principal.components...Array.8+ X[[4]]$Genetic.principal.components...Array.9+ X[[4]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[4]]$T2dX_at_BL)
my_lms2 <- lapply(X[[4]][colnames], function(x) lm(X[[4]]$HbA1c_BL_winsor ~ x + X[[4]]$Sex_F+ 
                                                        X[[4]]$array_type+ X[[4]]$Age.at.recruitment + X[[4]]$Genetic.principal.components...Array.1+ X[[4]]$Genetic.principal.components...Array.2+ X[[4]]$Genetic.principal.components...Array.3+ X[[4]]$Genetic.principal.components...Array.4+ X[[4]]$Genetic.principal.components...Array.5+ X[[4]]$Genetic.principal.components...Array.6+ X[[4]]$Genetic.principal.components...Array.7+ X[[4]]$Genetic.principal.components...Array.8+ X[[4]]$Genetic.principal.components...Array.9+ X[[4]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject4 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[5]]))
my_lms <- lapply(X[[5]][colnames], function(x) lm(X[[5]]$weekly_units_B_R ~ x + X[[5]]$Sex_F+ 
                                                    X[[5]]$array_type+ X[[5]]$Age.at.recruitment + X[[5]]$Genetic.principal.components...Array.1+ X[[5]]$Genetic.principal.components...Array.2+ X[[5]]$Genetic.principal.components...Array.3+ X[[5]]$Genetic.principal.components...Array.4+ X[[5]]$Genetic.principal.components...Array.5+ X[[5]]$Genetic.principal.components...Array.6+ X[[5]]$Genetic.principal.components...Array.7+ X[[5]]$Genetic.principal.components...Array.8+ X[[5]]$Genetic.principal.components...Array.9+ X[[5]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[5]]$T2dX_at_BL)
my_lms2 <- lapply(X[[5]][colnames], function(x) lm(X[[5]]$HbA1c_BL_winsor ~ x + X[[5]]$Sex_F+ 
                                                        X[[5]]$array_type+ X[[5]]$Age.at.recruitment + X[[5]]$Genetic.principal.components...Array.1+ X[[5]]$Genetic.principal.components...Array.2+ X[[5]]$Genetic.principal.components...Array.3+ X[[5]]$Genetic.principal.components...Array.4+ X[[5]]$Genetic.principal.components...Array.5+ X[[5]]$Genetic.principal.components...Array.6+ X[[5]]$Genetic.principal.components...Array.7+ X[[5]]$Genetic.principal.components...Array.8+ X[[5]]$Genetic.principal.components...Array.9+ X[[5]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject5 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[6]]))
my_lms <- lapply(X[[6]][colnames], function(x) lm(X[[6]]$weekly_units_B_R ~ x + X[[6]]$Sex_F+ 
                                                    X[[6]]$array_type+ X[[6]]$Age.at.recruitment + X[[6]]$Genetic.principal.components...Array.1+ X[[6]]$Genetic.principal.components...Array.2+ X[[6]]$Genetic.principal.components...Array.3+ X[[6]]$Genetic.principal.components...Array.4+ X[[6]]$Genetic.principal.components...Array.5+ X[[6]]$Genetic.principal.components...Array.6+ X[[6]]$Genetic.principal.components...Array.7+ X[[6]]$Genetic.principal.components...Array.8+ X[[6]]$Genetic.principal.components...Array.9+ X[[6]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[6]]$T2dX_at_BL)
my_lms2 <- lapply(X[[6]][colnames], function(x) lm(X[[6]]$HbA1c_BL_winsor ~ x + X[[6]]$Sex_F+ 
                                                        X[[6]]$array_type+ X[[6]]$Age.at.recruitment + X[[6]]$Genetic.principal.components...Array.1+ X[[6]]$Genetic.principal.components...Array.2+ X[[6]]$Genetic.principal.components...Array.3+ X[[6]]$Genetic.principal.components...Array.4+ X[[6]]$Genetic.principal.components...Array.5+ X[[6]]$Genetic.principal.components...Array.6+ X[[6]]$Genetic.principal.components...Array.7+ X[[6]]$Genetic.principal.components...Array.8+ X[[6]]$Genetic.principal.components...Array.9+ X[[6]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject6 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[7]]))
my_lms <- lapply(X[[7]][colnames], function(x) lm(X[[7]]$weekly_units_B_R ~ x + X[[7]]$Sex_F+ 
                                                    X[[7]]$array_type+ X[[7]]$Age.at.recruitment + X[[7]]$Genetic.principal.components...Array.1+ X[[7]]$Genetic.principal.components...Array.2+ X[[7]]$Genetic.principal.components...Array.3+ X[[7]]$Genetic.principal.components...Array.4+ X[[7]]$Genetic.principal.components...Array.5+ X[[7]]$Genetic.principal.components...Array.6+ X[[7]]$Genetic.principal.components...Array.7+ X[[7]]$Genetic.principal.components...Array.8+ X[[7]]$Genetic.principal.components...Array.9+ X[[7]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[7]]$T2dX_at_BL)
my_lms2 <- lapply(X[[7]][colnames], function(x) lm(X[[7]]$HbA1c_BL_winsor ~ x + X[[7]]$Sex_F+ 
                                                        X[[7]]$array_type+ X[[7]]$Age.at.recruitment + X[[7]]$Genetic.principal.components...Array.1+ X[[7]]$Genetic.principal.components...Array.2+ X[[7]]$Genetic.principal.components...Array.3+ X[[7]]$Genetic.principal.components...Array.4+ X[[7]]$Genetic.principal.components...Array.5+ X[[7]]$Genetic.principal.components...Array.6+ X[[7]]$Genetic.principal.components...Array.7+ X[[7]]$Genetic.principal.components...Array.8+ X[[7]]$Genetic.principal.components...Array.9+ X[[7]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject7 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[8]]))
my_lms <- lapply(X[[8]][colnames], function(x) lm(X[[8]]$weekly_units_B_R ~ x + X[[8]]$Sex_F+ 
                                                    X[[8]]$array_type+ X[[8]]$Age.at.recruitment + X[[8]]$Genetic.principal.components...Array.1+ X[[8]]$Genetic.principal.components...Array.2+ X[[8]]$Genetic.principal.components...Array.3+ X[[8]]$Genetic.principal.components...Array.4+ X[[8]]$Genetic.principal.components...Array.5+ X[[8]]$Genetic.principal.components...Array.6+ X[[8]]$Genetic.principal.components...Array.7+ X[[8]]$Genetic.principal.components...Array.8+ X[[8]]$Genetic.principal.components...Array.9+ X[[8]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[8]]$T2dX_at_BL)
my_lms2 <- lapply(X[[8]][colnames], function(x) lm(X[[8]]$HbA1c_BL_winsor ~ x + X[[8]]$Sex_F+ 
                                                        X[[8]]$array_type+ X[[8]]$Age.at.recruitment + X[[8]]$Genetic.principal.components...Array.1+ X[[8]]$Genetic.principal.components...Array.2+ X[[8]]$Genetic.principal.components...Array.3+ X[[8]]$Genetic.principal.components...Array.4+ X[[8]]$Genetic.principal.components...Array.5+ X[[8]]$Genetic.principal.components...Array.6+ X[[8]]$Genetic.principal.components...Array.7+ X[[8]]$Genetic.principal.components...Array.8+ X[[8]]$Genetic.principal.components...Array.9+ X[[8]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject8 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[9]]))
my_lms <- lapply(X[[9]][colnames], function(x) lm(X[[9]]$weekly_units_B_R ~ x + X[[9]]$Sex_F+ 
                                                    X[[9]]$array_type+ X[[9]]$Age.at.recruitment + X[[9]]$Genetic.principal.components...Array.1+ X[[9]]$Genetic.principal.components...Array.2+ X[[9]]$Genetic.principal.components...Array.3+ X[[9]]$Genetic.principal.components...Array.4+ X[[9]]$Genetic.principal.components...Array.5+ X[[9]]$Genetic.principal.components...Array.6+ X[[9]]$Genetic.principal.components...Array.7+ X[[9]]$Genetic.principal.components...Array.8+ X[[9]]$Genetic.principal.components...Array.9+ X[[9]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[9]]$T2dX_at_BL)
my_lms2 <- lapply(X[[9]][colnames], function(x) lm(X[[9]]$HbA1c_BL_winsor ~ x + X[[9]]$Sex_F+ 
                                                        X[[9]]$array_type+ X[[9]]$Age.at.recruitment + X[[9]]$Genetic.principal.components...Array.1+ X[[9]]$Genetic.principal.components...Array.2+ X[[9]]$Genetic.principal.components...Array.3+ X[[9]]$Genetic.principal.components...Array.4+ X[[9]]$Genetic.principal.components...Array.5+ X[[9]]$Genetic.principal.components...Array.6+ X[[9]]$Genetic.principal.components...Array.7+ X[[9]]$Genetic.principal.components...Array.8+ X[[9]]$Genetic.principal.components...Array.9+ X[[9]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject9 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
colnames<-grep("^VV[0-9]+",names(X[[10]]))
my_lms <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$weekly_units_B_R ~ x + X[[10]]$Sex_F+ 
                                                    X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries <- lapply(my_lms, summary) #so want coefficients from here for bx and bxse
bx_terms<-lapply(summaries, function(x) x$coefficients[2, c(1,2)]) #yay!
dfbx<-data.frame(bx_terms) %>% t() %>% data.frame()
names(dfbx)
#now repeat for b-y (but needs to be survival analysis) using HbA1c_BL_winsor 
#library (survival)
#class(X[[10]]$T2dX_at_BL)
my_lms2 <- lapply(X[[10]][colnames], function(x) lm(X[[10]]$HbA1c_BL_winsor ~ x + X[[10]]$Sex_F+ 
                                                        X[[10]]$array_type+ X[[10]]$Age.at.recruitment + X[[10]]$Genetic.principal.components...Array.1+ X[[10]]$Genetic.principal.components...Array.2+ X[[10]]$Genetic.principal.components...Array.3+ X[[10]]$Genetic.principal.components...Array.4+ X[[10]]$Genetic.principal.components...Array.5+ X[[10]]$Genetic.principal.components...Array.6+ X[[10]]$Genetic.principal.components...Array.7+ X[[10]]$Genetic.principal.components...Array.8+ X[[10]]$Genetic.principal.components...Array.9+ X[[10]]$Genetic.principal.components...Array.10)) #huzzah!
summaries2 <- lapply(my_lms2, summary) #so want coefficients from here for bx and bxse
by_terms<-lapply(summaries2, function(x) x$coefficients[2, c(1,2)]) #so this is taking the UNexponentiated coef and its se
dfby<-data.frame(by_terms) %>% t() %>% data.frame()
MRInputObject10 <- mr_input(bx = dfbx$Estimate,
bxse = dfbx$Std..Error,
by = dfby$Estimate,
byse = dfby$Std..Error)
#for now do IVW just to see what's going on in the strata (the egger below may not be valid anyway unless all the variants are in terms of positive effects?)

#and then once run below for a given sens test (just sub out med for IVW etc), add columns to LACESUM[["coefficients"]] which are from the main results (or make a list of them instead?) -> actually only works for median and IVW, for RAPS PRESSO and weighted mode will have to use other packages because Mendelian Randomisation package doesn't include them


med1<-MendelianRandomization::mr_median(MRInputObject1)
med1 #interesting much smaller/non-sig decrease
med2<-MendelianRandomization::mr_median(MRInputObject2)
med2
med3<-MendelianRandomization::mr_median(MRInputObject3)
med3
med4<-MendelianRandomization::mr_median(MRInputObject4)
med4 
med5<-MendelianRandomization::mr_median(MRInputObject5)
med5
med6<-MendelianRandomization::mr_median(MRInputObject6)
med6
med7<-MendelianRandomization::mr_median(MRInputObject7)
med7
med8<-MendelianRandomization::mr_median(MRInputObject8)
med8 
med9<-MendelianRandomization::mr_median(MRInputObject9)
med9 
med10<-MendelianRandomization::mr_median(MRInputObject10)
med10 #this one is sig positive
summary(med10)

medres1<-c(med1@Estimate,med1@StdError,med1@CILower,med1@CIUpper,med1@Pvalue)
medres2<-c(med2@Estimate,med2@StdError,med2@CILower,med2@CIUpper,med2@Pvalue)
medres3<-c(med3@Estimate,med3@StdError,med3@CILower,med3@CIUpper,med3@Pvalue)
medres4<-c(med4@Estimate,med4@StdError,med4@CILower,med4@CIUpper,med4@Pvalue)
medres5<-c(med5@Estimate,med5@StdError,med5@CILower,med5@CIUpper,med5@Pvalue)
medres6<-c(med6@Estimate,med6@StdError,med6@CILower,med6@CIUpper,med6@Pvalue)
medres7<-c(med7@Estimate,med7@StdError,med7@CILower,med7@CIUpper,med7@Pvalue)
medres8<-c(med8@Estimate,med8@StdError,med8@CILower,med8@CIUpper,med8@Pvalue)
medres9<-c(med9@Estimate,med9@StdError,med9@CILower,med9@CIUpper,med9@Pvalue)
medres10<-c(med10@Estimate,med10@StdError,med10@CILower,med10@CIUpper,med10@Pvalue)

medRES<-t(data.frame(medres1,medres2,medres3,medres4,medres5,medres6,medres7,medres8,medres9,medres10))
medRES<-data.frame(medRES) #24.05 adding covariates seems to have attenuated results for both med and median, only slightly

#ok now to do the other methods using the twosampleMR package
library(TwoSampleMR)
SNPSdf1<-cbind(MRInputObject1$betaX,MRInputObject1$betaXse,MRInputObject1$betaY,MRInputObject1$betaYse)
SNPSdf1<-data.frame(SNPSdf1)
colnames(SNPSdf1)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf1<-SNPSdf1 %>% mutate(SNP=1:79)
SNPSdf1<-SNPSdf1 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf1<-SNPSdf1 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf2<-cbind(MRInputObject2$betaX,MRInputObject2$betaXse,MRInputObject2$betaY,MRInputObject2$betaYse)
SNPSdf2<-data.frame(SNPSdf2)
colnames(SNPSdf2)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf2<-SNPSdf2 %>% mutate(SNP=1:79)
SNPSdf2<-SNPSdf2 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf2<-SNPSdf2 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf3<-cbind(MRInputObject3$betaX,MRInputObject3$betaXse,MRInputObject3$betaY,MRInputObject3$betaYse)
SNPSdf3<-data.frame(SNPSdf3)
colnames(SNPSdf3)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf3<-SNPSdf3 %>% mutate(SNP=1:79)
SNPSdf3<-SNPSdf3 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf3<-SNPSdf3 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf4<-cbind(MRInputObject4$betaX,MRInputObject4$betaXse,MRInputObject4$betaY,MRInputObject4$betaYse)
SNPSdf4<-data.frame(SNPSdf4)
colnames(SNPSdf4)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf4<-SNPSdf4 %>% mutate(SNP=1:79)
SNPSdf4<-SNPSdf4 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf4<-SNPSdf4 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf5<-cbind(MRInputObject5$betaX,MRInputObject5$betaXse,MRInputObject5$betaY,MRInputObject5$betaYse)
SNPSdf5<-data.frame(SNPSdf5)
colnames(SNPSdf5)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf5<-SNPSdf5 %>% mutate(SNP=1:79)
SNPSdf5<-SNPSdf5 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf5<-SNPSdf5 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf6<-cbind(MRInputObject6$betaX,MRInputObject6$betaXse,MRInputObject6$betaY,MRInputObject6$betaYse)
SNPSdf6<-data.frame(SNPSdf6)
colnames(SNPSdf6)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf6<-SNPSdf6 %>% mutate(SNP=1:79)
SNPSdf6<-SNPSdf6 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf6<-SNPSdf6 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf7<-cbind(MRInputObject7$betaX,MRInputObject7$betaXse,MRInputObject7$betaY,MRInputObject7$betaYse)
SNPSdf7<-data.frame(SNPSdf7)
colnames(SNPSdf7)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf7<-SNPSdf7 %>% mutate(SNP=1:79)
SNPSdf7<-SNPSdf7 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf7<-SNPSdf7 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf8<-cbind(MRInputObject8$betaX,MRInputObject8$betaXse,MRInputObject8$betaY,MRInputObject8$betaYse)
SNPSdf8<-data.frame(SNPSdf8)
colnames(SNPSdf8)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf8<-SNPSdf8 %>% mutate(SNP=1:79)
SNPSdf8<-SNPSdf8 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf8<-SNPSdf8 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf9<-cbind(MRInputObject9$betaX,MRInputObject9$betaXse,MRInputObject9$betaY,MRInputObject9$betaYse)
SNPSdf9<-data.frame(SNPSdf9)
colnames(SNPSdf9)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf9<-SNPSdf9 %>% mutate(SNP=1:79)
SNPSdf9<-SNPSdf9 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf9<-SNPSdf9 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf10<-cbind(MRInputObject10$betaX,MRInputObject10$betaXse,MRInputObject10$betaY,MRInputObject10$betaYse)
SNPSdf10<-data.frame(SNPSdf10)
colnames(SNPSdf10)<-c("beta.exposure","se.exposure","beta.outcome","se.outcome")
SNPSdf10<-SNPSdf10 %>% mutate(SNP=1:79)
SNPSdf10<-SNPSdf10 %>% mutate(id.exposure="alcohol") %>% mutate(id.outcome="T2D") %>% mutate(mr_keep=as.logical("TRUE"))
#remotes::install_github("MRCIEU/TwoSampleMR")
SNPSdf10<-SNPSdf10 %>% mutate(exposure="alcohol") %>% mutate(outcome="T2D")

SNPSdf<-list(SNPSdf1,SNPSdf2,SNPSdf3,SNPSdf4,SNPSdf5,SNPSdf6,SNPSdf7,SNPSdf8,SNPSdf9,SNPSdf10)

#weighted mode
my_lms <- lapply(SNPSdf, function(x) mr_weighted_mode(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$b-(1.96*x$se);x$upperCI<-x$b+(1.96*x$se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
modeRES<-as.data.frame(do.call(rbind,add_CIs))
modeRES<-modeRES %>% select(b,se,lowerCI,upperCI,pval) #DONE!
class(modeRES)
class(modeRES$b)
modeRES2<- unnest(modeRES,b) %>% unnest(modeRES,se) %>% unnest(modeRES,lowerCI) %>% unnest(modeRES,upperCI) %>% unnest(modeRES,pval) #none are now sig once incorp covariates
class(modeRES2$se)

#raps
my_lms <- lapply(SNPSdf, function(x) mr.raps::mr.raps(x$beta.exposure, x$beta.outcome, x$se.exposure,x$se.outcome, diagnosis=TRUE)) #huzzah! ->  no CIs provided here, so need to make them
add_CIs<- lapply(my_lms, function(x) {x$lowerCI<-x$beta.hat-(1.96*x$beta.se);x$upperCI<-x$beta.hat+(1.96*x$beta.se);return(x)}) #WOOOH WORKS 23.05
#convert this to a data frame with columns in correct order to match ivw and median (estimate,se,cil,ciu,p)
rapsRES<-as.data.frame(do.call(rbind,add_CIs))
rapsRES<-rapsRES %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value) #DONE!
rapsRES2<- unnest(rapsRES,beta.hat) %>% unnest(rapsRES,beta.se) %>% unnest(rapsRES,lowerCI) %>% unnest(rapsRES,upperCI) %>% unnest(rapsRES,beta.p.value) 
class(rapsRES2$beta.se)

#finally presso
my_lms <- lapply(SNPSdf, function(x) run_mr_presso(x, NbDistribution = 2500, SignifThreshold = 0.05)) 
#all 10 global tests >.05, therefore no outlier corrected estmates produced
#24.05 same for when added covariates; 25.05 same for females; same for males EXCEPT stratum 9, but then no sig outliers could be found
#25.05 THERE ARE OUTLIER CORRECTED RESULTS FOR HBAIC main results (except for starat 2 and 10 where no sig outliers were detected) -> so need to pull outlier corrected estimtes for the other 8 strata and make mr presso results
presso_hba1c_results_1<-c(my_lms[[1]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[1]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[1]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_2<-c(my_lms[[2]][[1]][["Main MR results"]][["Causal Estimate"]][[1]], my_lms[[2]][[1]][["Main MR results"]][["Sd"]][[1]], my_lms[[2]][[1]][["Main MR results"]][["P-value"]][[1]]) #note dif
presso_hba1c_results_3<-c(my_lms[[3]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[3]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[3]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_4<-c(my_lms[[4]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[4]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[4]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_5<-c(my_lms[[5]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[5]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[5]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_6<-c(my_lms[[6]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[6]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[6]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_7<-c(my_lms[[7]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[7]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[7]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_8<-c(my_lms[[8]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[8]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[8]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_9<-c(my_lms[[9]][[1]][["Main MR results"]][["Causal Estimate"]][[2]], my_lms[[9]][[1]][["Main MR results"]][["Sd"]][[2]], my_lms[[9]][[1]][["Main MR results"]][["P-value"]][[2]])
presso_hba1c_results_10<-c(my_lms[[10]][[1]][["Main MR results"]][["Causal Estimate"]][[1]], my_lms[[10]][[1]][["Main MR results"]][["Sd"]][[1]], my_lms[[10]][[1]][["Main MR results"]][["P-value"]][[1]]) #note dif

pressoRES<-data.frame(rbind(presso_hba1c_results_1,presso_hba1c_results_2,presso_hba1c_results_3,presso_hba1c_results_4,presso_hba1c_results_5,presso_hba1c_results_6,presso_hba1c_results_7,presso_hba1c_results_8,presso_hba1c_results_9,presso_hba1c_results_10))
pressoRES2<-pressoRES %>% mutate(lowerCI=X1-(1.96*X2)) %>% mutate(upperCI=X1+(1.96*X2))
pressoRES2<-pressoRES2 %>% select(X1,X2,lowerCI,upperCI,X3) #rearrange col order


HBA1C_FOURxsensresultsCOV<-list(ivwRES,medRES,modeRES2,rapsRES2,pressoRES2)
saveRDS(HBA1C_FOURxsensresultsCOV, file="HBA1C_FOURxsensresultsCOV.rds")
saveRDS(HBA1C_FOURxsensresultsCOV, file="HBA1C_FOURxsensresultsCOV.RData")
HBA1C_FOURxsensresultsCOV<-readRDS("HBA1C_FOURxsensresultsCOV.rds") 

HBA1C_FOURxsensresultsCOV[[3]]<-HBA1C_FOURxsensresultsCOV[[3]] %>% select(b,se,lowerCI,upperCI,pval)
HBA1C_FOURxsensresultsCOV[[4]]<-HBA1C_FOURxsensresultsCOV[[4]] %>% select(beta.hat,beta.se,lowerCI,upperCI,beta.p.value)
#so now have LACEs in there with variance/CIs, need to add the mean x for each stratum now so that can figure out how to do fractional polynomial
#actually can just calculate by hand
mean1<-mean(X[[1]]$weekly_units_B_R)
mean2<-mean(X[[2]]$weekly_units_B_R)
mean3<-mean(X[[3]]$weekly_units_B_R)
mean4<-mean(X[[4]]$weekly_units_B_R)
mean5<-mean(X[[5]]$weekly_units_B_R)
mean6<-mean(X[[6]]$weekly_units_B_R)
mean7<-mean(X[[7]]$weekly_units_B_R)
mean8<-mean(X[[8]]$weekly_units_B_R)
mean9<-mean(X[[9]]$weekly_units_B_R)
mean10<-mean(X[[10]]$weekly_units_B_R)
Xmeans<-c(mean1,mean2,mean3,mean4,mean5,mean6,mean7,mean8,mean9,mean10)#now attach these back to sensitivity results
HBA1C_FOURxsensresultsCOV2<-lapply(HBA1C_FOURxsensresultsCOV, function(x) cbind(x, Xmeans)) #EXCELLENT! now see if can feed into the NLMR package to generate plots
devtools::install_github("jrs95/nlmr")
library(nlmr)
ls("package:nlmr") #so that fracpoly_best function IS here, need to see what's in it
View(nlmr::fracpoly_best) #excellent -> this opens the function in a separate tab, and unlike the sumNLMR equivalent only needs the values for LACE, se and xmeans rather than the individual bx by stats (which force the function to use ratio method) -> want to use argument d="both"
```


```{r}
 ##### Best-fitting fractional polynomial #####
  fracpb <- nlmr::fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[1]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[1]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[1]]$Xmeans, d="both", pd=.05, method="FE")
  #so p1_ML is best fitting of degree 1, p2_ML is best fitting of degree 2; fp_p is p value for a first degree fp over linear; fp_d12_p is for degree 2 over degree 1, not sure what p_ML is though??? (eg for first one - IVW - p_ML is -2 whereas p1_ML is -1 and p2_ML is -.5)->>>> AHHHH this is wrong! p_ML is degree 1, p1_ML and p2_ML relate to the best fitting second degree (ie the two fractions that compose best fitting second degree polynomial) -> not significant in this case anyway
#GOOD news is tht didn't use bootstrapped CIs/ses for main nlmr analyses fracpoly (only for piecewise), so don't need to calclate here (which for some reason requires the x and y and g stats)
model <- fracpb$model; p_ML <- fracpb$p_ML; p1_ML <- fracpb$p1_ML; p2_ML <- fracpb$p2_ML; fp_p <- fracpb$fp_p; fp_d12_p <- fracpb$fp_d12_p
  d <- fracpb$d
    ##### Non-linearity tests #####
  #library(metafor)
  p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[1]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[1]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[1]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[1]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[1]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
  #and to make figure
  
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
  

     #View(nlmr::fracpoly_figure)
     
     ###AHHHH ok below need to supply mean of lowest stratum as xmin and mean of highest stratum as xmax, not the literal highest and lowest x values! for hba1c: 1.33 and 53.74 for overall;  for women;  for men
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1.5, p1_ML=-1, p2_ML=1, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional polynoial degrees from the actual data, apart from that the shape is just generic! so what I'll do is simply generate the polynomial tests and list of LACEs, and won't make the plots!!!
   #ohhhh my GOD I GOT THE GFIGURE WORKING!!! -well the CIs are still a little weird on the left hand side; have edited the function foior now to remove CIs s can see line better -> weird that doesn't properly align with the Xmean for lowest caeory -> I think the nlmr package must plot in a sep way
  
   #do for sensitivity 2-4 (median,mode,RAPS) -> one above is IVW
    library(nlmr)
    fracpbMEDIAN <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[2]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[2]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[2]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbMEDIAN$model; p_ML <- fracpbMEDIAN$p_ML; p1_ML <- fracpbMEDIAN$p1_ML; p2_ML <- fracpbMEDIAN$p2_ML; fp_p <- fracpbMEDIAN$fp_p; fp_d12_p <- fracpbMEDIAN$fp_d12_p
  d <- fracpbMEDIAN$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[2]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[2]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[2]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[2]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[2]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=1, p_ML=-1.5, p1_ML=NULL, p2_ML=-NULL, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  
    fracpbmode <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[3]][["b"]], coef_se=HBA1C_FOURxsensresultsCOV2[[3]][["se"]], xmean=HBA1C_FOURxsensresultsCOV2[[3]]$Xmeans, d="both", pd=.05, method="FE")
        model <- fracpbmode$model; p_ML <- fracpbmode$p_ML; p1_ML <- fracpbmode$p1_ML; p2_ML <- fracpbmode$p2_ML; fp_p <- fracpbmode$fp_p; fp_d12_p <- fracpbmode$fp_d12_p
  d <- fracpbmode$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[3]][["b"]] ~ HBA1C_FOURxsensresultsCOV2[[3]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[3]][["se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[3]][["b"]], vi=(HBA1C_FOURxsensresultsCOV2[[3]][["se"]])^2)$QE, df=(10-1))
   figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=1, p_ML=-1, p1_ML=NULL, p2_ML=NULL, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
    
    
     fracpbraps <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]], coef_se=HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]], xmean=HBA1C_FOURxsensresultsCOV2[[4]]$Xmeans, d="both", pd=.05, method="FE")
      model <- fracpbraps$model; p_ML <- fracpbraps$p_ML; p1_ML <- fracpbraps$p1_ML; p2_ML <- fracpbraps$p2_ML; fp_p <- fracpbraps$fp_p; fp_d12_p <- fracpbraps$fp_d12_p
  d <- fracpbraps$d
  cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
    p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]] ~ HBA1C_FOURxsensresultsCOV2[[4]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[4]][["beta.hat"]], vi=(HBA1C_FOURxsensresultsCOV2[[4]][["beta.se"]])^2)$QE, df=(10-1))
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1.5, p1_ML=-1, p2_ML=1, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#hmmm this is a weird shape -> you know what, I can see that the figures only use the xmin and max, plus fractional 
     
    
     fracpbPRESSO <- fracpoly_best(coef=HBA1C_FOURxsensresultsCOV2[[5]][["X1"]], coef_se=HBA1C_FOURxsensresultsCOV2[[5]][["X2"]], xmean=HBA1C_FOURxsensresultsCOV2[[5]]$Xmeans, d="both", pd=.05, method="FE")
    model <- fracpbPRESSO$model; p_ML <- fracpbPRESSO$p_ML; p1_ML <- fracpbPRESSO$p1_ML; p2_ML <- fracpbPRESSO$p2_ML; fp_p <- fracpbPRESSO$fp_p; fp_d12_p <- fracpbPRESSO$fp_d12_p
  d <- fracpbPRESSO$d
   cov <- model$vb
    se <- model$se
    lci <- as.numeric(model$b) - 1.96*se
    uci <- as.numeric(model$b) + 1.96*se
    pval <- 2*pnorm(-abs(as.numeric(model$b)/se))
     p_quadratic <- rma(HBA1C_FOURxsensresultsCOV2[[5]][["X1"]] ~ HBA1C_FOURxsensresultsCOV2[[5]]$Xmeans, HBA1C_FOURxsensresultsCOV2[[5]][["X2"]]^2, method="FE")$pval[2]
  p_Q <- 1 - pchisq(rma(HBA1C_FOURxsensresultsCOV2[[5]][["X1"]], vi=(HBA1C_FOURxsensresultsCOV2[[5]][["X2"]])^2)$QE, df=(10-1)) #I entered 10 here as that is number of quantiles
     figure <- fracpoly_figureRV(as.numeric(model$b), cov, 1.33, 53.74, family="gaussian", d=2, p_ML=-1, p1_ML=-1, p2_ML=2, ci="model_se", frac_coef_boot=NULL, ref=1.33, pref_x="Drinks per week", pref_x_ref="x", pref_y="Relative HbA1C, mmol/mol", ci_type="overall", ci_quantile=10, breaks=NULL)
    figure#
  

```




Upload RStudio project onto RAP storage.

```{r}
#system("dx-backup-folder -d /.Backups/rstudio_webinar.tar.gz")

#RV editing
system("dx-backup-folder")
```

